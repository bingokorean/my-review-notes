{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. How to Develop Encoder-Decoder LSTMs (Seq2seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Machine Translation\n",
    "* Learning to Execute\n",
    "* Image Captioning\n",
    "* Conversational Modeling\n",
    "* Movement Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../assets/encoder-decoder.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Office\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from math import ceil\n",
    "from math import log10\n",
    "from numpy import argmax\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate lists of random integers and their sum\n",
    "def random_sum_pairs(n_examples, n_numbers, largest):\n",
    "    X, y = list(), list()\n",
    "    for _ in range(n_examples):\n",
    "        in_pattern = [randint(1,largest) for _ in range(n_numbers)]\n",
    "        out_pattern = sum(in_pattern)\n",
    "        X.append(in_pattern)\n",
    "        y.append(out_pattern)\n",
    "    return X, y\n",
    "    # return [[3, 10]], [13]\n",
    "\n",
    "# convert data to strings\n",
    "def to_string(X, y, n_numbers, largest):\n",
    "    max_length = int(n_numbers * ceil(log10(largest+1)) + n_numbers - 1)\n",
    "    Xstr = list()\n",
    "    for pattern in X:\n",
    "        strp = '+'.join([str(n) for n in pattern])\n",
    "        strp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
    "        Xstr.append(strp)\n",
    "    max_length = int(ceil(log10(n_numbers * (largest+1))))\n",
    "    ystr = list()\n",
    "    for pattern in y:\n",
    "        strp = str(pattern)\n",
    "        strp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
    "        ystr.append(strp)\n",
    "    return Xstr, ystr\n",
    "    # [' 3+10'], ['13']\n",
    "\n",
    "# integer encode strings\n",
    "def integer_encode(X, y, alphabet):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    Xenc = list()\n",
    "    for pattern in X:\n",
    "        integer_encoded = [char_to_int[char] for char in pattern]\n",
    "        Xenc.append(integer_encoded)\n",
    "    yenc = list()\n",
    "    for pattern in y:\n",
    "        integer_encoded = [char_to_int[char] for char in pattern]\n",
    "        yenc.append(integer_encoded)\n",
    "    return Xenc, yenc\n",
    "    # [[11, 3, 10, 1, 0]] [[1, 3]]\n",
    "\n",
    "# one hot encode\n",
    "def one_hot_encode(X, y, max_int):\n",
    "    Xenc = list()\n",
    "    for seq in X:\n",
    "        pattern = list()\n",
    "        for index in seq:\n",
    "            vector = [0 for _ in range(max_int)]\n",
    "            vector[index] = 1\n",
    "            pattern.append(vector)\n",
    "        Xenc.append(pattern)\n",
    "    yenc = list()\n",
    "    for seq in y:\n",
    "        pattern = list()\n",
    "        for index in seq:\n",
    "            vector = [0 for _ in range(max_int)]\n",
    "            vector[index] = 1\n",
    "            pattern.append(vector)\n",
    "        yenc.append(pattern)\n",
    "    return Xenc, yenc\n",
    "    # [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "    # [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    # [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "    # [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    # [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]\n",
    "    # [[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    # [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]]]\n",
    "\n",
    "\n",
    "# generate an encoded dataset\n",
    "def generate_data(n_samples, n_numbers, largest, alphabet):\n",
    "    # generate pairs\n",
    "    X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "    # convert to strings\n",
    "    X, y = to_string(X, y, n_numbers, largest)\n",
    "    # integer encode\n",
    "    X, y = integer_encode(X, y, alphabet)\n",
    "    # one hot encode\n",
    "    X, y = one_hot_encode(X, y, len(alphabet))\n",
    "    # return as numpy arrays\n",
    "    X, y = array(X), array(y)\n",
    "    return X, y\n",
    "\n",
    "# invert encoding\n",
    "def invert(seq, alphabet):\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    strings = list()\n",
    "    for pattern in seq:\n",
    "        string = int_to_char[argmax(pattern)]\n",
    "        strings.append(string)\n",
    "    return ''.join(strings)\n",
    "\n",
    "# configure problem\n",
    "# number of math terms\n",
    "n_terms = 3\n",
    "# largest value for any single input digit\n",
    "largest = 10\n",
    "# scope of possible symbols for each input or output time step\n",
    "alphabet = [str(x) for x in range(10)] + ['+', ' ']\n",
    "# size of alphabet: (12 for 0-9, + and ' ')\n",
    "n_chars = len(alphabet)\n",
    "# length of encoded input sequence (8 for '10+10+10)\n",
    "n_in_seq_length = int(n_terms * ceil(log10(largest+1)) + n_terms - 1)\n",
    "# length of encoded output sequence (2 for '30')\n",
    "n_out_seq_length = int(ceil(log10(n_terms * (largest+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 75)                26400     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 2, 75)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 2, 50)             25200     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 2, 12)             612       \n",
      "=================================================================\n",
      "Total params: 52,212\n",
      "Trainable params: 52,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(75, input_shape=(n_in_seq_length, n_chars)))\n",
    "model.add(RepeatVector(n_out_seq_length))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_chars, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "75000/75000 [==============================] - 14s 190us/step - loss: 0.0806 - acc: 0.9892\n",
      "Epoch 2/5\n",
      "75000/75000 [==============================] - 14s 187us/step - loss: 0.0429 - acc: 0.9896\n",
      "Epoch 3/5\n",
      "75000/75000 [==============================] - 14s 190us/step - loss: 0.0558 - acc: 0.9877\n",
      "Epoch 4/5\n",
      "75000/75000 [==============================] - 14s 189us/step - loss: 0.0043 - acc: 0.9995\n",
      "Epoch 5/5\n",
      "75000/75000 [==============================] - 14s 191us/step - loss: 0.0444 - acc: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x255e306f908>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit LSTM\n",
    "X, y = generate_data(75000, n_terms, largest, alphabet)\n",
    "model.fit(X, y, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.002771, Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# evaluate LSTM\n",
    "X, y = generate_data(100, n_terms, largest, alphabet)\n",
    "loss, acc = model.evaluate(X, y, verbose=0)\n",
    "print('Loss: %f, Accuracy: %f' % (loss, acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1+5+6 = 12 (expect 12)\n",
      "   6+6+5 = 17 (expect 17)\n",
      "   9+3+3 = 15 (expect 15)\n",
      "  10+7+4 = 21 (expect 21)\n",
      "   3+7+8 = 18 (expect 18)\n",
      "   5+4+8 = 17 (expect 17)\n",
      "   9+3+1 = 13 (expect 13)\n",
      "  5+1+10 = 16 (expect 16)\n",
      " 10+10+1 = 21 (expect 21)\n",
      "   4+1+4 =  9 (expect  9)\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "for _ in range(10):\n",
    "    # generate an input-output pair\n",
    "    X, y = generate_data(1, n_terms, largest, alphabet)\n",
    "    # make prediction\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    # decode input, expected and predicted\n",
    "    in_seq = invert(X[0], alphabet)\n",
    "    out_seq = invert(y[0], alphabet)\n",
    "    predicted = invert(yhat[0], alphabet)\n",
    "    print('%s = %s (expect %s)' % (in_seq, predicted, out_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
