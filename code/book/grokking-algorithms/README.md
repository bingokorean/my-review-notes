# Grokking Algorithms

Aditya Y. Bhargava <br>
한국어판 - Hello Coding 알고리즘 <br>

## Contents

* [1. 알고리즘의 소개](#1.)
   * 1.2. 이진 탐색
   * 1.3. 빅오 표기법
* [2. 선택 정렬](#2.)
   * 2.2. 배열과 연결 리스트
   * 2.3. 선택 정렬
* [3. 재귀](#3.)
   * 3.2. 재귀
   * 3.3. 기본 단계와 재귀 단계
   * 3.4. 스택
* [4. 퀵 정렬](#4.)
    * 4.1. 분할 정복 
	* 4.2. 퀵 정렬
* [5. 해시 테이블](#5.)




<br>


<div id='1.'/>

## 1. 알고리즘의 소개

### 1.2. 이진 탐색

이진 탐색은 단계마다 절반의 숫자를 없앨 수 있다. 단, 정렬된 리스트를 입력으로 받는다. 만약 n개의 원소를 가진 리스트에서 이진 탐색을 사용하면 최대 log(n)번(logarithmic time) 만에 답을 찾을 수 있다. 이 책에서 log는 항상 log_2와 같다. 단순 탐색은 최대 n번(linear time)이 필요할 수도 있다. 로그를 거듭제곱의 반대인 점을 생각하면 그 크기를 짐작할 수 있다. 

```python
def bineary_search(list, item):
    low = 0
	high = len(list) - 1
	
	while low <= high:
	    mid = (low + high) / 2
		guess = list[mid]
		if guess == item:
		    return mid
		if guess > item:
		    high = mid - 1
		else:
		    low = mid + 1
	return None
	
my_list = [1, 3, 5, 7, 9]
print(bineary_search(my_list, 3)) 	# => 1
print(bineary_search(my_list, -1))	# => None
```

| 단순 탐색          | 이진 탐색          |
| :---------------:| :--------------:|
| centered column  | centered column |
| linear time      | logarithmic time|



### 1.3. 빅오 표기법

빅오 표기법으로 알고리즘이 얼마나 빠른지 설명해준다. 그런데 한 가지 주의 사항이 있다.

|                  | 단순 탐색          | 이진 탐색          |
| :---------------:| :---------------:| :--------------:|
| centered column  | centered column | centered column |
| 100개      		| 100밀리 초 | 7밀리 초 |
| 10,000개      		| 10초 | 14밀리 초 |
| 1000,000,000개      | 11일 | 32밀리 초 |

단순히 100개인 데이터만 생각해서 단순 탐색과 이진 탐색의 실행 시간이 별 차이가 없다고 판단할 수 있다. 아무래도 버그가 생길 가능성이 적은 단순 탐색을 최종으로 선택할 수 있는데 이는 큰 오산이다. 항상 데이터가 100개면 상관없으나 데이터가 증가하는 경우에 결과가 확연히 달라진다.

따라서, 알고리즘의 실행 시간이 얼마나 걸리는지만 고려할 것이 아니라, 리스트 크기가 증가할 때 어떻게 증가하는지를 파악할 필요가 있다. 이 점이 빅오 표기법을 사용하는 이유이다.

빅오 표기법은 속도를 시간 단위로 세지 않는다. 빅오 표기법은 **연산 횟수를 비교**하기 위한 것이다. 빅오 표기법을 사용하면 수행해야 할 일이 많아질 때 알고리즘에 걸리는 시간이 어떤 식으로 증가하는지를 알 수 있다.

`O(n)` 에서 O는 빅(Big)오할 때 O이고, n은 연산 횟수를 뜻한다. `O(n)`의 의미는 n개의 데이터를 처리하기 위해 n번의 연산이 필요하다와 같다. `O(log(n))`은 n개의 데이터를 처리하기 위해 log(n)번의 연산이 필요하다는 의미와 같다. 즉, 빅오 표기법에는 실질적인 실행 시간의 정보가 포함되어 있지 않다. 하지만, 연산 횟수를 통해 실행 시간을 가늠할 수 있다. 예를 들어, 1초에 100번의 연산을 할 수 있다고 가정하면 실행 시간을 구할 수 있다.

알고리즘은 동일해도 주어진 문제에 따라 연산 횟수가 달라질 수 있다. 최선의 경우(단순 검색에서 첫 번째 인덱스에서 찾고자하는 값이 있는 경우), 최악의 경우(단순 검색에서 마지막 인덱스에서 찾고자하는 값이 있는 경우)로 구분될 수 있다. 빅오 표기법은 (보통) **최악의 경우**에 대한 것이다. 즉, 단순 검색은 절대로 O(n) 시간보다 느려지지 않는다는 보장을 할 수 있다.

최악의 경우에 대한 실행 시간 이외에도 **평균 실행 시간**을 설펴보는 것도 중요하다. 최악의 경우와 평균에 대한 비교는 4장 퀵 정렬에서 살펴보자.


#### 많이 사용하는 빅오 실행 시간의 예

* O(log(n)), 로그 시간:	예) 이진 탐색
* O(n), 선형 시간:		예) 단순 탐색
* O(nlog(n)):		예) 퀵 정렬과 같은 빠른 정렬 알고리즘
* O(n^2):		예) 선택 정렬과 같이 느린 정렬 알고리즘
* O(n!):		예) 외판원 문제와 같이 정말 느린 알고리즘

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/1_1.PNG" width="60%" height="60%"></p>

#### 빅오 표기법 정리

* 알고리즘의 속도는 시간이 아니라 연산 횟수가 어떻게 증가하는지로 측정한다.
* 이렇게 하면 입력 데이터의 크기가 늘어날 때 알고리즘의 실행 속도가 얼마나 증가하는지 알 수 있다.
* 알고리즘의 실행 시간은 빅오 표기법으로 나타낸다.
* O(log(n))은 O(n)보다 빠르고, 찾으려는 리스트의 원소의 개수가 증가하면 상대적으로 더 빨라진다.

#### (참고) 외판원 문제 (traveling salesperson problem)

모든 도시를 방문해서 물건을 팔아야되는 외판원이 있다. 주어진 도시에서 이동 거리가 가장 짧은 경로는 어떻게 구할 수 있을까? 이 문제를 푸는 한 가지 방법은 도시를 방문하는 모든 경로를 살펴보는 것이다. 그 다음 전체 거리를 더해서 가장 짧은 경로를 택하면 된다. 문제는 연산의 수가 무시무시하게 증가한다.

| 도시          | 연산          |
| :---------------:| :--------------:|
| centered column  | centered column |
| 6      | 720 |
| 7      | 5040 |
| 8     | 40320 |
| ...     | ... |
| 15    | 1307674368000 |
| ...     | ... |
| 30    | 265252859812191058636308480000000 |

만약 n개의 도시가 있다면 n!번의 연산이 필요하다. 즉, O(n!)이다. 아주 안 좋은 방법인데, 다른 알고리즘이 없다. 이 문제는 컴퓨터 과학에서 아직 풀지 못한 문제 중 하나이다. 우리가 할 수 있는 방법은 대략적인 답을 얻는 것밖에 없다(10장 참고. 이진 탐색 트리 참고).

### 1장 정리

* 이진 탐색은 단순 탐색보다 아주 빠르다.
* O(log(n))은 O(n)보다 빠르다. 리스트의 원소의 개수가 증가하면 상대적으로 더 빨라진다.
* 알고리즘의 속도는 시간으로 측정하지 않는다.
* 알고리즘의 시간은 어떻게 증가하는가로 측정한다.
* 알고리즘의 시간은 빅오 표기법으로 나타낸다. 

### 1장 연습문제

알파벳 A로 시작하는 사람들의 전화번호를 탐색하는 실행 시간의 빅오 표기법은? O(n/26)이 아니라 O(n)이 된다. 4장 빅오 표기법 상수 참조.




<div id='2.'/>

## 2. 선택 정렬

### 2.2. 배열과 연결 리스트

여러 개의 항목을 목록으로 메모리에 저장하고 싶다고 하자. 메모리 공간의 특징은 할당 가능한 영역이 듬성듬성 구멍이 뚫린 것처럼 흩어져 있다는 점이다. 배열은 항상 **연이은 공간**이 필요하므로 해당 리스트 크기만큼 비어있는 자리를 찾아야 한다. 찾는 시간을 줄이기 위해 큰 영역을 미리 할당해놓는 방법이 있는데, 만약 추가할 일이 생기지 않는다면 메모리를 쓸데없이 낭비한 셈이 된다. 

연결 리스트(Linked List)를 사용하면 원소를 메모리의 **어느 곳에나** 둘 수 있다. 연결 리스트를 사용하면 원소를 추가하는 일이 쉽다. 그냥 메모리의 아무 곳에나 원소를 넣고, 그 주소를 바로 앞의 원소에 저장해 놓으면 된다. 즉, 연결 리스트를 사용하면 원소를 옮길 일이 없다. 

연결 리스트의 문제는.. 리스트에서 마지막 원소를 보고 싶다면 바로 읽을 수 없다. 왜냐하면 주소를 바로 알 수 없기 때문이다(연결 리스트에서는 원소가 이웃하고 있지 않아서 몇 번째 원소가 어디에 있는지 바로 계산할 수 없다). 만약 모든 원소의 값을 한 번에 읽어야 한다면 연결 리스트가 좋지만, 특정한 원소만 알고 싶다면 연결 리스트는 최악이다.

배열(array)은 모든 원소의 주소를 다 알고 있다. 따라서 배열 안의 어떤 원소든 바로 찾을 수 있기 때문에 임의의 원소의 값을 읽는데 최고다.

|                  | 배열          | 리스트          |
| :---------------:| :---------------:| :--------------:|
| centered column  | centered column | centered column |
| 읽기      		| O(1) | O(n) |
| 쓰기      		| O(n) | O(1) |

왜 배열에 원소를 삽입하는데 O(n) 시간이 들까? 빅오 표기법의 기준은 최악의 경우다. 배열의 가장 앞부분에 원소를 삽입했을 때를 생각해보자. 리스트는 왜 O(1)일까? 가운데까지 찾아가는데 걸리는 시간이 O(n)이 아닌가? 여기서는 이미 찾아갔다고 가정한다. 순수하게 쓰기(삽입) 연산만 보면 O(1)이 맞다. 삭제도 똑같다. (cf. [stackoverflow](https://stackoverflow.com/questions/840648/why-is-inserting-in-the-middle-of-a-linked-list-o1))

#### 리스트의 가운데에 삽입하기

원소를 배열이나 리스트의 중앙에 삽입한다면 배열과 리스트 중 어느 것이 나을까? 리스트는 이전 원소가 무엇을 가리키느지 바꾸기만 하면 되므로 리스트에 삽입하는 것이 훨씬 쉽다. 하지만 배열에서는 다음에 오는 모든 원소의 위치를 바꾸어야 한다. 만약 공간이 부족하면 모든 원소를 새로운 장소로 복사해야 한다. 

#### 삭제하기

삭제의 경우에도 이전 원소가 가리키는 위치만 바꾸면 되기에 리스트가 더 낫다. 배열에서는 원소 하나만 삭제하고 싶을 때도 모든 것을 다 옮겨야 한다. 삽입할 때와 달리 삭제할 때는 실패하는 경우가 없다(삽입할 때는 가끔 메모리에 남아 있는 공간이 없어서 실패할 수도 있다). 하지만 원소를 삭제하는 것은 언제나 할 수 있다. 

|                  | 배열          | 리스트          |
| :---------------:| :---------------:| :--------------:|
| centered column  | centered column | centered column |
| 읽기      		| O(1) | O(n) |
| 쓰기      		| O(n) | O(1) |
| 삭제      		| O(n) | O(1) |

경우에 따라 다르지만, 임의의 원소에 접근하는 것이 가능하기 때문에 배열이 리스트보다 더 많이 쓰인다. 자료에 접근하는 방식에는 임의 접근(random access)과 순차 접근(sequential access)이라는 두 가지 방식이 있다. 배열에서는 임의 접근이 가능하기에 배열의 읽기 속도가 빠르다.

### 2.3. 선택 정렬 (Selection Sort)

나의 뮤직 플레이어 목록에서 가장 많이 들은 노래부터 가장 적게 들은 노래 순서로 정렬하여 가장 좋아하는 노래의 순위를 알고 싶다면 어떻게 해야 할까?

한 가지 (심플한) 방법은 리스트의 모든 항목을 살펴보고 가장 많이 연주된 가수를 찾아 새로운 리스트에 기록하는 것이다. 이런식으로 반복하면 정렬된 목록을 얻을 수 있다.

매번 실행할 때마다 n, n-1, n-2, ... 2, 1개의 항목을 점검해야 한다. 평균적으로 1/2 x n개의 항목을 점검해야 한다. 이러한 실행을 n번 해야 한다. 그렇다면 빅오는 O(n x 1/2 x n)이지만 상수항은 무시하여 O(n x n)이 된다.

선택 정렬은 깔끔한 알고리즘이지만 빠르지 않다. 퀵 정렬은 O(n x log(n)) 시간밖에 걸리지 않는 더 빠른 알고리즘이다.

```python
def findSmallest(arr):
    smallest = arr[0]
	smallest_index = 0
	for i in range(1, len(arr)):
	    if arr[i] < smallest:
		    smallest = arr[i]
			smallest_index = i
	return smallest_index
	
def selectionSort(arr):
    newArr = []
	for i in range(len(arr)):
	    smallest = findSmallest(arr)
		newArr.append(arr.pop(smallest))
	return newArr
	
print(selectionSort([5, 3, 6, 2, 10]))
```

### 2.4. 2장 정리

* 배열을 쓰면 모든 항목은 이웃하는 위치에 저장된다.
* 리스트를 쓰면 모든 항목이 흩어지지만, 각 항목은 다음 항목의 주소를 저장하고 있다.
* 배열은 읽기가 빠르다.
* 연결 리스트는 삽입과 삭제가 빠르다.
* 배열의 모든 원소는 같은 자료형이어야 한다.

### 2장 연습문제

큐를 구현하는 데 배열보다 연결 리스트를 사용하는 것이 좋다. 큐는 임의의 위치를 읽거나 검색할 필요가 없으므로 배열보다 연결 리스트가 훨씬 더 좋다.

페이스북이 사용자 이름 목록을 가지고 있다고 하자. 특정 사용자 이름을 검색하기 위해 이진 탐색을 사용한다고 가정하자. 이진 탐색을 하기 위해서는 임의 접근이 가능해야 한다. 이 경우에는 연결리스트보다 배열이 좋다. 이진 탐색을 하기 떄문에 리스트는 정렬되어 있어야 함을 잊지 말자.

페이스북에는 새로운 사용자 등록도 자주 발생한다. 이 경우에서는 배열이 좋지 않다. 

페이스북은 실제로 사용자 정보를 저장하기 위해 배열이나 연결 리스트를 사용하지 않는다. 다음과 같은 복합 자료구조를 생각해보자. 알파벳 하나하나를 지칭하는 26개의 칸이 있는 배열이 있다. 각각의 칸은 각자 다른 연결 리스트를 가리키고 있다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/2_1.PNG" width="60%" height="60%"></p>

이러한 복합 자료구조는 검색의 경우에는 배열보다 느리고 연결 리스트보다는 빠르다. 삽입의 경우에는 배열보다는 빠르고 연결 리스트와는 같은 시간이 걸린다. 즉, 배열보다는 검색 시간 측면에서만 느리고 연결 리스트보다는 모든 면에서 좋거나 최소한 같다.

이 책의 뒷부분에서는 해시 테이블이라고 하는 또 다른 복합 자료구조를 이야기할 것이다. 이 자료구조는 간단한 자료구조로부터 어떻게 복잡한 형태의 자료구조를 만들어 나가는지에 대한 아이디어를 줄 수 있다.

페이스북은 실제로 여러 가지 다른 데이터베이스를 사용하고, 각각의 데이터베이스 내부에서는 해시 테이블이나 B-트리와 같은 다양한 자료구조를 쓸 것이다. 배열과 연결 리스트는 이러한 복잡한 자료구조를 만드는 기초가 된다.



<div id='3.'/>

## 3. 재귀

재귀(recursion)는 여러 가지 알고리즘에 쓰이는 코딩 테크닉으로 이 책의 나머지 장을 이해하기 위한 기초가 된다. 하나의 문제를 기본 단계와 재귀 단계로 나누는 방법을 배운다. 분할 정복(divide-and-conquer) 전략은 이런 간단한 개념을 사용하여 어려운 문제를 푸는 방법이다.

### 3.2. 재귀

큰 상자 속에 작은 상자들이 있고, 그 작은 상들 안에는 더 작은 상자들이 있다. 열쇠는 그 상자 속 어딘가에 있다. 열쇠를 찾기 위한 알고리즘은 무엇일까?

```python
# 방법 1 - while 반복문
def look_for_key(main_box):
    pile = main_box.make_a_pile_to_look_through()
	while pile is not empty:
	    box = pile.grab_a_box():
		for item in box:
		    if item.is_a_box():
			    pile.append(item)
			elif item.is_a_key():
			    print("열쇠를 찾았어요!")

# 방법 2 - 재귀
def look_for_key(box):
    for item in box:
	    if item.is_a_box():
		    look_for_key(item)
		elif item.is_a_key():
		    print("열쇠를 찾았어요!")
```

두 가지 방법 모두 같은 일을 하지만, 두 번째 방법이 더 명확하다. 재귀는 풀이를 더 명확하게 만들어 준다. 재귀를 쓴다고 성능이 더 나아지지는 않는다. 사실 반복문이 더 성능이 좋은 경우가 많다. 

"프로그램에 반복문을 사용하면 프로그램의 성능을 향상시킬 수 있지만, 재귀를 사용하면 프로그래머의 능력을 향상시킬 수 있다." - 스택 오버플로우: 레이 캐드웰

상황에 따라 적절한 방법을 골라 사용하자. 대부분의 중요한 알고리즘들이 재귀를 사용하므로 개념을 잘 이해하는 것이 중요하다.

### 3.3. 기본 단계와 재귀 단계

재귀 함수는 자기 자신을 호출하기 때문에 실수로 무한 반복을 하는 함수를 만들기 쉽다. 재귀 함수를 만들 때는 언제 재귀를 멈출지 알려줘야 한다. 그래서 모든 재귀 함수는 기본 단계(base case)와 재귀 단계(recursive case)라는 두 부분으로 나누어져 있다. 

재귀 단계는 함수가 자기 자신을 호출하는 부분이다. 기본 단계는 함수가 자기 자신을 다시 호출하지 않는 경우, 즉 무한 반복으로 빠져들지 않게 하는 부분이다. 

```python
def countdown(i):
    print(i)
	if i <= 1:	# 기본 단계
	    return
	else:	# 재귀 단계
	    countdown(i-1)
```

### 3.4. 스택

호출 스택은 프로그램에서 중요한 개념이지만 재귀를 사용할 때 더욱 중요하다. 컴퓨터는 호출 스택이라고 불리는 스택(stack)을 사용한다. 여러 개의 함수를 호출하면서 함수에 사용되는 변수를 저장하는 스택을 호출 스택(call stack)이라고 한다. 

스택을 사용하면 확인해야 할 상자 더미를 여러분이 일일이 추적하지 않아도 되므로 편리하다. 그렇지만 편리한만큼 대가를 치러야 한다. 모든 정보를 저장해야 하므로 메모리를 많이 소비한다. 함수 호출을 할 때마다 메모리를 사용하게 된다.

많은 메모리 소비를 방지하기 위한 방법으로
* 재귀 대신 반복문을 써서 코드를 다시 작성한다.
* 꼬리 재귀(tail recursion)라는 방법을 사용한다. 이는 고급 재귀 방법으로 모든 프로그래밍 언어에서 지원하는 것은 아니다.


### 3장 정리

* 재귀는 함수가 스스로를 호출하는 것이다.
* 모든 재귀 함수는 기본 단계와 재귀 단계라는 두 부분으로 나누어져 있다.
* 스택에는 푸시(push)와 팝(pop)이라는 두 가지 연산이 있다.
* 모든 함수 호출은 호출 스택을 사용한다.
* 호출 스택은 너무 커져서 메모리를 엄청나게 소비할 수도 있다.

### 3장 연습문제

재귀 함수가 무한 실행하면 스택에는 어떤 일이 발생할까? 스택에 할당할 수 있는 공간이 제한되어 있기 때문에 이 공간을 모두 사용하면 스택 오버플로우 오류가 발생하며 종료된다. 



<div id='4.'/>

## 4. 퀵 정렬

분할 정복(divide-and-conquer) 전략에 대해 알아보자. 가끔씩 여러분이 공부한 어떤 알고리즘으로도 풀 수 없는 문제를 만날 수 있다. 이런 문제를 풀기 위해서는 다양한 기술을 통해 해결 방법을 알아내야 한다. 분할 정복 전략은 여러분이 배우게 될 첫 번째 범용 기술(general technique)이다. 분할 정복 전략은 문제에 바로 적용할 수 있는 단순한 알고리즘이 아니고 문제를 풀기 위한 방법론에 가깝다.

퀵 정렬은 실무에 자주 사용되는 명쾌한 정렬 알고리즘 중 하나이다. 퀵 정렬은 분할 정복 전략을 사용한다.

### 4.1. 분할 정복

문제 해결 방법 중에서 가장 유명한 재귀적 기술인 분할 정복(divide-and-conquer) 전략에 대해 살펴보자.

한 가지 유형의 문제만 풀 수 있다면 그 알고리즘은 유용하다고 할 수 없다. 분할 정복 전략은 문제를 푸는 새로운 사고 방식을 제시한다. 여러분의 문제 해결 도구 상자에 새로운 도구를 넣게 되는거다. 새로운 문제에 부딪혀도 당황하지 말고 분할 정복 전략으로 문제를 풀 수 있는지 고민하자.

**토지 분할 문제**
여러분이 농부이고 1680m x 640m 크기의 농장을 가지고 있다하자. 이 농장을 똑같이 생긴 정사각형 토지들로 나누고 싶다. 어떻게 똑같은 크기의 가장 큰 정사각형으로 나눌 수 있을까? 재귀적 알고리즘인 분할 정복 전략을 활용하자. 다음과 같은 두 단계를 가진다.

1. 기본 단계를 해결한다. 이 부분은 가능한 한 간단한 문제이어야만 한다. (기본 단계)
2. 문제가 기본 단계가 될 때까지 나누거나 작게 만든다. (재귀 단계)

재귀 단계에서 분할 정복 전략이 활약할 타이밍이다. 분할 정복 전략에 따르면 재귀 함수 호출을 할 때마다 문제를 작게 나누어야 한다. 여기에서는 문제를 어떻게 나눌까? 조건에 맞는 가장 큰 상자를 알아내는 것부터 시작한다. 

한 변의 길이가 640m인 두 개의 정사각형 토지를 만들 수 있지만, 아직 나누지 못한 토지가 남게 된다. 이제 이 문제를 푸는 핵심 아이디어가 등장한다. 남은 토지를 나눌 때도 똑같은 방법을 사용하면 된다. 즉, 원래는 1680m x 640m 크기를 가진 농장의 토지를 나누는 문제로 시작했지만, 이제 더 작은 640m x 400m 크기의 농장의 토지를 나누는 새로운 문제를 푸는 것이다.

문제가 1680m x 640m -> 640m x 400m -> 400m x 240m -> 240m x 160m -> 160m x 80m 으로 바뀐다. 원래의 농장을 나눌 수 있는 가장 큰 정사각형의 크기는 80m x 80m이 된다.

**숫자들의 합 문제**

주어진 배열에 있는 숫자들을 모두 더하여 합계를 구하는 문제를 반복문을 사용하지 않고 재귀 함수를 사용해서 합계를 구해보자.

* 기본 단계를 찾는다. 가장 간단한 배열은 무엇일까?
* 재귀 함수 호출을 할 때마다 호출 대상이 되는 배열의 크기가 점점 감소해야 한다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/4_1.PNG" width="60%" height="60%"></p>

재귀에서는 상태를 추적한다는 점을 명심하자. 

배열을 포함하는 재귀 함수를 만들 떄, 기본 단계는 보통 빈 배열이나 원소가 하나뿐인 배열이 된다. 만약 문제를 풀다 막히면 이 방법을 사용하자.


**(TIP)함수형 프로그래밍**

반복문으로 풀 수 있는데 왜 재귀적으로 해야 하나? 함수형 프로그래밍을 살짝 맛본 것이다. 하스켈과 같은 함수형 프로그래밍 언어에는 반복문이란 것이 없다. 그러니 무조건 이렇게 재귀 함수를 사용해야 한다. 예를 들어, 하스켈 언어로 합계 함수는 다음과 같다.

```
sum [] = 0 					# 기본 단계
sum (x:xs) = x + (sum xs)	# 재귀 단계
```

### 4.2. 퀵 정렬

퀵 정렬(quicksort)은 선택 정렬보다 훨씬 빠르고 실제로도 자주 사용된다. 퀵 정렬은 분할 정복 전략을 가진다. 

기본 단계로는 정렬할 필요가 없는 배열, 즉 비어있거나 원소가 하나인 배열인 상태다. 주어진 배열을 기본 단계가 될 때까지 나눠야 한다. 퀵 정렬에서는 기준 원소(pivot)를 고르고, 모든 원소를 기준 원소보다 작은 원소와 큰 원소로 분류한다. 이것을 분할(partitioning)이라고 한다. 분할된 하위 배열(sub-array)에 대해서도 퀵 정렬을 호출한다. 이렇게 재귀적으로 호출하면 된다. 각 하위 배열들이 정렬되면 합쳐서 전체 배열을 정렬한다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/4_2.PNG" width="60%" height="60%"></p>

```python
def quicksort(array):
    if len(array) < 2:	# 기본 단계: 원소의 개수가 0이나 1이면 이미 정렬되어 있는 상태
	    return array
	else:	# 재귀 단계
	    pivot = array[0]	# 첫 번째 원소를 임의로 pivot이라 설정
		less = [i for i in array[1:] if i <= pivot]
		greater = [i for i in array[1:] if i > pivot]
		return quicksort(less) + [pivot] + quicksort(greater)
		
print(quicksort([10, 5, 2, 3]))
```

**(TIP)귀납적 증명**

방금 귀납적 증명을 살짝 맛보았다. 귀납적 증명은 알고리즘이 제대로 동작하는지 증명하는 방법 중 하나이다. 귀납적 증명에도 기본 단계(base case)와 귀납 단계(inductive case)라는 두 가지 단계가 필요하다.

기본 단계에서는 알고리즘이 가장 기본적인 경우, 즉 배열의 크기가 0이나 1인 경우에 대해 알고리즘이 동작한다는 것을 보여준다. 귀납 단계에서는 퀵 정렬이 크기가 1인 배열에 대해 동작하면 크기가 2인 배열에 대해서도 동작한다는 것을 보여준다. 3인 배열도 마찬가지로 보여준다. 이렇게 모든 크기의 배열에 대해 퀵 정렬이 동작한다고 말할 수 있다.

귀납적 증명은 흥미로운 주제일 뿐 아니라 분할 정복 전략과 함께 사용되기도 한다.


### 4.3. 빅오 표기법 복습

퀵 정렬은 여러분이 선택한 기준 원소에 따라 처리 속도가 달라진다는 특징이 있다. 먼저 일반적인 빅오 실행 시간 유형을 다시 보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/4_3.PNG" width="60%" height="60%"></p>

위의 추정치는 1초에 10회의 연산을 할 수 있는 느린 컴퓨터를 기준으로 하였다.

퀵 정렬의 실행 시간은 최악의 경우에는 O(n^2)이 될 수도 있다. 선택 정렬만큼 느린 것이다. 하지만 이것은 어디까지나 최악의 경우를 말한 것이고, 평균적인 경우에는 O(nlog(n)) 실행 시간을 가진다.

* 여기에서 최악의 경우와 일반적인 경우란 무엇을 뜻하나?
* 만약 퀵 정렬이 평균적으로 O(nlog(n))이라면 병합 정렬은 항상 O(nlog(n))인가? 그럼 왜 병합 정렬이 훨씬 빠른데 왜 쓰지 않는 것일까?

**병합 정렬과 퀵 정렬 비교**

리스트에 있는 모든 원소를 출력하는 간단한 함수가 있다고 하자.

```python

def print_items(list):
    for item in list:
	    print(item)
		
from time import sleep
def print_item2(list):
    for item in list:
	    sleep(1)
		print(item)
```

두 함수 모두 리스트를 한 번만 훑어보기 때문에 똑같이 O(n) 실행 시간을 가진다. 실제로는 print_items가 1초 동안 기다리지 않으므로 훨씬 빠르다. 

```
c x n
```

c는 알고리즘이 소비하는 어떤 특정한 시간으로 이를 상수(constant)라고 부른다. 

이진 탐색과 단숨 탐색을 예를 들어보자. 두 알고리즘 모두 다음과 같은 상수를 가진다고 하자. 

* 단순 탐색 - 10밀리초 x n
* 이진 탐색 - 1초 x log(n)

얼핏보면 단순 탐색이 훨씬 빠르게 보일수도 있다. 하지만, 40억 개의 원소를 가진 리스트를 탐색한다고 하자.

* 단순 탐색 - 10밀리초 x 40억 개 = 463초
* 이진 탐색 - 1초 x 32 = 32초

이진 탐색이 훨씬 빠르다. 즉, 상수는 전혀 문제가 되지 않는다.

가끔은 상수 때문에 차이가 발생하기도 한다. 퀵 정렬과 병합 정령이 그 예이다. 퀵 정렬이 병합 정렬보다 더 작은 상수를 가진다. 그래서 실행 시간이 O(nlog(n))으로 동일하다면 퀵 정렬이 더 빠르다. 그리고 퀵 정렬을 사용할 때 최악의 경우보다는 일반적인 경우가 훨씬 많이 발생하기 때문에 현실에서는 퀵 정렬이 더 빠르다.

**평균적인 경우와 최악의 경우 비교**

퀵 정렬의 성능은 여러분이 선택한 기준 원소에 크게 의존한다. 

만약 첫 번째 원소를 항상 기준 원소로 선택한다고 하고, 이미 정렬되어 있는 배열에 퀵 정렬을 호출해보자. 배열을 절반으로 나누지 않고 진행한다. 두 개의 하위 배열 중 하나는 항상 빈 배열이다. 그래서 호출 스택이 아주 길어진다. (배열 길이가 1024이라면 호출 스택의 전체 높이도 1024이다) 이 경우는 퀵 정렬의 최악의 경우를 나타내는 시나리오이다. 스택의 크기가 O(n)이다. (기준 원소를 임의로 첫 번째 원소로 정하지 않는 이상 이러한 시나리오는 발생하지 않지 않나?)

이번에는 정 가운데 있는 원소를 항상 기준 원소로 선택한다고 가정하자. 매번 배열을 절반으로 나누기 때문에 재귀적 호출을 많이 할 필요가 없다. 기본 단계에 더 빨리 도달하기 때문에 호출 스택이 짧아진다. (배열 길이가 1024이라면 호출 스택의 전체 높이는 10이다) 이 경우는 퀵 정렬의 최선의 경우를 나타내는 시나리오이다. 스택의 크기가 O(log(n))이다.

이제 스택의 각 단계를 살펴보자. 기준 원소로 원소 하나를 선택하면 나머지 원소들은 두 개의 하위 배열로 나누어진다. 이렇게 나누기 위해서는 1024개의 원소를 모두 기준 원소와 비교해야 한다. 이 작업에는 O(n) 실행 시간이 걸린다. 배열을 다르게 분할한다고 해도 여전히 매번 O(n)개의 원소를 모두 비교해야 하는 것은 마찬가지이다.

최악의 경우 호출 스택의 높이는 O(n)이고, 각각의 단계는 O(n) 시간이 걸리기 때문에 전체 알고리즘은 O(n) x O(n) = O(n^2) 시간이 걸린다. 최선의 경우는 O(log(n)) x O(n) = O(n x log(n)) 시간이 걸린다.

퀵 정렬에서는 일반적인 경우에도 최선의 경우와 같은 실행 속도를 가진다. 만약 기준 원소를 전체 배열에서 무작위로 선택한다면 퀵 정렬은 평균적으로 O(nlog(n)) 실행 시간을 가진다. 퀵 정렬은 가장 빠른 정렬 방법 중의 하나이고, 분할 정복의 좋은 예이다.

### 4장 정리

* 분할 정복은 문제를 더 작은 조각으로 나누어 푼다. 만약 리스트에 분할 정복을 적용한다면 기본 단계는 원소가 없는 빈 배열이거나 하나의 원소만 가진 배열이 된다.
* 퀵 정렬을 구현하려면 기준 원소를 무작위로 선택한다. 퀵 정렬의 평균적인 실행 시간은 O(log(n))이다.
* 빅오 표기법에서 가끔씩 상수가 중요해질 때도 있다. 퀵 정렬이 병합 정렬보다 빠른 이유도 상수 때문이다.
* 단순 탐색과 이진 탐색을 비교할 때는 상수항이 전혀 문제가 되지 않는다. 왜냐하면 리스트가 길어지면 O(log(n))이 O(n)보다 훨씬 빨라진다.

### 4장 연습문제

재귀 함수에 익숙해지기.

```python
# 리스트의 sum을 하는 재귀 함수
def sum(list):
    if list == []:
	    return 0
	return list[0] + sum(list[1:])

# 리스트에 포함된 원소의 숫자를 세는 재귀 함수
def count(list):
    if list == []:
	    return 0
	return 1 + count(list[1:])
	
# 리스트에서 가장 큰 수를 찾는 재귀 함수
def max(list):
    if len(list) == 2:
	    return list[0] if list[0] > list[1] else list[1]
	sub_max = max(list[1:])
	return list[0] if list[0] > sub_max else sub_max
```

이진 탐색 역시 분할 정복 전략이다. 이진 탐색의 기본 단계는 원소가 하나뿐인 배열이다. 만약 이 배열에서 원소를 찾으려면 바로 찾을 수 있다. 그렇지 않으면 배열에 없는 것이다. 이진 탐색의 재귀 단계에서는 배열을 2등분하고 하나씩 이진 탐색을 실행한다.

빅오 표기법의 중요한 포인트는 특정 연산 실행 시간이 아니라 접근하는 데이터 개수이다. 어떤 연산에 대해 신경을 쓸 것이 아니라 데이터가 증가할 때 연산은 어떻게 될 지를 신경써야 한다.


<div id='5.'/>

## 5. 해시 테이블

분할






