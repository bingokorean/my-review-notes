# Grokking Algorithms

Aditya Y. Bhargava <br>
한국어판 - Hello Coding 알고리즘 <br>

## Contents

* [1. 알고리즘의 소개](#1.)
* [2. 선택 정렬 (Selection Sort)](#2.)
* [3. 재귀 (Recursion)](#3.)
* [4. 퀵 정렬 (Quicksort)](#4.)
* [5. 해시 테이블 (Hash Tables)](#5.)
* [6. 너비 우선 탐색 (Breadth-first Search)](#6.)
* [7. 다익스트라 알고리즘 (Dijkstra’s algorithm)](#7.)
* [8. 탐욕 알고리즘 (Greedy algorithms)](#8.)
* [9. 동적 프로그래밍 (Dynmaic programming)](#9.)
* [10. KNN 알고리즘 (K-nearest neighbors)](#10.)
* [11. 더 공부해야 할 것](#11.)


<br>
<div id='1.'/>

## 1. 알고리즘의 소개

### 1.2. 이진 탐색

이진 탐색은 단계마다 절반의 숫자를 없앨 수 있다. 단, 정렬된 리스트를 입력으로 받는다. 만약 n개의 원소를 가진 리스트에서 이진 탐색을 사용하면 최대 log(n)번(logarithmic time) 만에 답을 찾을 수 있다. 이 책에서 log는 항상 log_2와 같다. 단순 탐색은 최대 n번(linear time)이 필요할 수도 있다. 로그를 거듭제곱의 반대인 점을 생각하면 그 크기를 짐작할 수 있다. 

```python
def bineary_search(list, item):
    low = 0
	high = len(list) - 1
	
	while low <= high:
	    mid = (low + high) / 2
		guess = list[mid]
		if guess == item:
		    return mid
		if guess > item:
		    high = mid - 1
		else:
		    low = mid + 1
	return None
	
my_list = [1, 3, 5, 7, 9]
print(bineary_search(my_list, 3)) 	# => 1
print(bineary_search(my_list, -1))	# => None
```

| 단순 탐색          | 이진 탐색          |
| :---------------:| :--------------:|
| centered column  | centered column |
| linear time      | logarithmic time|



### 1.3. 빅오 표기법

빅오 표기법으로 알고리즘이 얼마나 빠른지 설명해준다. 그런데 한 가지 주의 사항이 있다.

|                  | 단순 탐색          | 이진 탐색          |
| :---------------:| :---------------:| :--------------:|
| centered column  | centered column | centered column |
| 100개      		| 100밀리 초 | 7밀리 초 |
| 10,000개      		| 10초 | 14밀리 초 |
| 1000,000,000개      | 11일 | 32밀리 초 |

단순히 100개인 데이터만 생각해서 단순 탐색과 이진 탐색의 실행 시간이 별 차이가 없다고 판단할 수 있다. 아무래도 버그가 생길 가능성이 적은 단순 탐색을 최종으로 선택할 수 있는데 이는 큰 오산이다. 항상 데이터가 100개면 상관없으나 데이터가 증가하는 경우에 결과가 확연히 달라진다.

따라서, 알고리즘의 실행 시간이 얼마나 걸리는지만 고려할 것이 아니라, 리스트 크기가 증가할 때 어떻게 증가하는지를 파악할 필요가 있다. 이 점이 빅오 표기법을 사용하는 이유이다.

빅오 표기법은 속도를 시간 단위로 세지 않는다. 빅오 표기법은 **연산 횟수를 비교**하기 위한 것이다. 빅오 표기법을 사용하면 수행해야 할 일이 많아질 때 알고리즘에 걸리는 시간이 어떤 식으로 증가하는지를 알 수 있다.

`O(n)` 에서 O는 빅(Big)오할 때 O이고, n은 연산 횟수를 뜻한다. `O(n)`의 의미는 n개의 데이터를 처리하기 위해 n번의 연산이 필요하다와 같다. `O(log(n))`은 n개의 데이터를 처리하기 위해 log(n)번의 연산이 필요하다는 의미와 같다. 즉, 빅오 표기법에는 실질적인 실행 시간의 정보가 포함되어 있지 않다. 하지만, 연산 횟수를 통해 실행 시간을 가늠할 수 있다. 예를 들어, 1초에 100번의 연산을 할 수 있다고 가정하면 실행 시간을 구할 수 있다.

알고리즘은 동일해도 주어진 문제에 따라 연산 횟수가 달라질 수 있다. 최선의 경우(단순 검색에서 첫 번째 인덱스에서 찾고자하는 값이 있는 경우), 최악의 경우(단순 검색에서 마지막 인덱스에서 찾고자하는 값이 있는 경우)로 구분될 수 있다. 빅오 표기법은 (보통) **최악의 경우**에 대한 것이다. 즉, 단순 검색은 절대로 O(n) 시간보다 느려지지 않는다는 보장을 할 수 있다.

최악의 경우에 대한 실행 시간 이외에도 **평균 실행 시간**을 설펴보는 것도 중요하다. 최악의 경우와 평균에 대한 비교는 4장 퀵 정렬에서 살펴보자.


#### 많이 사용하는 빅오 실행 시간의 예

* O(log(n)), 로그 시간:	예) 이진 탐색
* O(n), 선형 시간:		예) 단순 탐색
* O(nlog(n)):		예) 퀵 정렬과 같은 빠른 정렬 알고리즘
* O(n^2):		예) 선택 정렬과 같이 느린 정렬 알고리즘
* O(n!):		예) 외판원 문제와 같이 정말 느린 알고리즘

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/1_1.PNG" width="60%" height="60%"></p>

#### 빅오 표기법 정리

* 알고리즘의 속도는 시간이 아니라 연산 횟수가 어떻게 증가하는지로 측정한다.
* 이렇게 하면 입력 데이터의 크기가 늘어날 때 알고리즘의 실행 속도가 얼마나 증가하는지 알 수 있다.
* 알고리즘의 실행 시간은 빅오 표기법으로 나타낸다.
* O(log(n))은 O(n)보다 빠르고, 찾으려는 리스트의 원소의 개수가 증가하면 상대적으로 더 빨라진다.

#### (참고) 외판원 문제 (traveling salesperson problem)

모든 도시를 방문해서 물건을 팔아야되는 외판원이 있다. 주어진 도시에서 이동 거리가 가장 짧은 경로는 어떻게 구할 수 있을까? 이 문제를 푸는 한 가지 방법은 도시를 방문하는 모든 경로를 살펴보는 것이다. 그 다음 전체 거리를 더해서 가장 짧은 경로를 택하면 된다. 문제는 연산의 수가 무시무시하게 증가한다.

| 도시          | 연산          |
| :---------------:| :--------------:|
| centered column  | centered column |
| 6      | 720 |
| 7      | 5040 |
| 8     | 40320 |
| ...     | ... |
| 15    | 1307674368000 |
| ...     | ... |
| 30    | 265252859812191058636308480000000 |

만약 n개의 도시가 있다면 n!번의 연산이 필요하다. 즉, O(n!)이다. 아주 안 좋은 방법인데, 다른 알고리즘이 없다. 이 문제는 컴퓨터 과학에서 아직 풀지 못한 문제 중 하나이다. 우리가 할 수 있는 방법은 대략적인 답을 얻는 것밖에 없다(10장 참고. 이진 탐색 트리 참고).

### 1장 정리

* 이진 탐색은 단순 탐색보다 아주 빠르다.
* O(log(n))은 O(n)보다 빠르다. 리스트의 원소의 개수가 증가하면 상대적으로 더 빨라진다.
* 알고리즘의 속도는 시간으로 측정하지 않는다.
* 알고리즘의 시간은 어떻게 증가하는가로 측정한다.
* 알고리즘의 시간은 빅오 표기법으로 나타낸다. 

### 1장 연습문제

알파벳 A로 시작하는 사람들의 전화번호를 탐색하는 실행 시간의 빅오 표기법은? O(n/26)이 아니라 O(n)이 된다. 4장 빅오 표기법 상수 참조.



<br>
<div id='2.'/>

## 2. 선택 정렬 (Selection Sort)

### 2.2. 배열과 연결 리스트

여러 개의 항목을 목록으로 메모리에 저장하고 싶다고 하자. 메모리 공간의 특징은 할당 가능한 영역이 듬성듬성 구멍이 뚫린 것처럼 흩어져 있다는 점이다. 배열은 항상 **연이은 공간**이 필요하므로 해당 리스트 크기만큼 비어있는 자리를 찾아야 한다. 찾는 시간을 줄이기 위해 큰 영역을 미리 할당해놓는 방법이 있는데, 만약 추가할 일이 생기지 않는다면 메모리를 쓸데없이 낭비한 셈이 된다. 

연결 리스트(Linked List)를 사용하면 원소를 메모리의 **어느 곳에나** 둘 수 있다. 연결 리스트를 사용하면 원소를 추가하는 일이 쉽다. 그냥 메모리의 아무 곳에나 원소를 넣고, 그 주소를 바로 앞의 원소에 저장해 놓으면 된다. 즉, 연결 리스트를 사용하면 원소를 옮길 일이 없다. 

연결 리스트의 문제는.. 리스트에서 마지막 원소를 보고 싶다면 바로 읽을 수 없다. 왜냐하면 주소를 바로 알 수 없기 때문이다(연결 리스트에서는 원소가 이웃하고 있지 않아서 몇 번째 원소가 어디에 있는지 바로 계산할 수 없다). 만약 모든 원소의 값을 한 번에 읽어야 한다면 연결 리스트가 좋지만, 특정한 원소만 알고 싶다면 연결 리스트는 최악이다.

배열(array)은 모든 원소의 주소를 다 알고 있다. 따라서 배열 안의 어떤 원소든 바로 찾을 수 있기 때문에 임의의 원소의 값을 읽는데 최고다.

|                  | 배열          | 리스트          |
| :---------------:| :---------------:| :--------------:|
| centered column  | centered column | centered column |
| 읽기      		| O(1) | O(n) |
| 쓰기      		| O(n) | O(1) |

왜 배열에 원소를 삽입하는데 O(n) 시간이 들까? 빅오 표기법의 기준은 최악의 경우다. 배열의 가장 앞부분에 원소를 삽입했을 때를 생각해보자. 리스트는 왜 O(1)일까? 가운데까지 찾아가는데 걸리는 시간이 O(n)이 아닌가? 여기서는 이미 찾아갔다고 가정한다. 순수하게 쓰기(삽입) 연산만 보면 O(1)이 맞다. 삭제도 똑같다. (cf. [stackoverflow](https://stackoverflow.com/questions/840648/why-is-inserting-in-the-middle-of-a-linked-list-o1))

#### 리스트의 가운데에 삽입하기

원소를 배열이나 리스트의 중앙에 삽입한다면 배열과 리스트 중 어느 것이 나을까? 리스트는 이전 원소가 무엇을 가리키느지 바꾸기만 하면 되므로 리스트에 삽입하는 것이 훨씬 쉽다. 하지만 배열에서는 다음에 오는 모든 원소의 위치를 바꾸어야 한다. 만약 공간이 부족하면 모든 원소를 새로운 장소로 복사해야 한다. 

#### 삭제하기

삭제의 경우에도 이전 원소가 가리키는 위치만 바꾸면 되기에 리스트가 더 낫다. 배열에서는 원소 하나만 삭제하고 싶을 때도 모든 것을 다 옮겨야 한다. 삽입할 때와 달리 삭제할 때는 실패하는 경우가 없다(삽입할 때는 가끔 메모리에 남아 있는 공간이 없어서 실패할 수도 있다). 하지만 원소를 삭제하는 것은 언제나 할 수 있다. 

|                  | 배열          | 리스트          |
| :---------------:| :---------------:| :--------------:|
| centered column  | centered column | centered column |
| 읽기      		| O(1) | O(n) |
| 쓰기      		| O(n) | O(1) |
| 삭제      		| O(n) | O(1) |

경우에 따라 다르지만, 임의의 원소에 접근하는 것이 가능하기 때문에 배열이 리스트보다 더 많이 쓰인다. 자료에 접근하는 방식에는 임의 접근(random access)과 순차 접근(sequential access)이라는 두 가지 방식이 있다. 배열에서는 임의 접근이 가능하기에 배열의 읽기 속도가 빠르다.

### 2.3. 선택 정렬 (Selection Sort)

나의 뮤직 플레이어 목록에서 가장 많이 들은 노래부터 가장 적게 들은 노래 순서로 정렬하여 가장 좋아하는 노래의 순위를 알고 싶다면 어떻게 해야 할까?

한 가지 (심플한) 방법은 리스트의 모든 항목을 살펴보고 가장 많이 연주된 가수를 찾아 새로운 리스트에 기록하는 것이다. 이런식으로 반복하면 정렬된 목록을 얻을 수 있다.

매번 실행할 때마다 n, n-1, n-2, ... 2, 1개의 항목을 점검해야 한다. 평균적으로 1/2 x n개의 항목을 점검해야 한다. 이러한 실행을 n번 해야 한다. 그렇다면 빅오는 O(n x 1/2 x n)이지만 상수항은 무시하여 O(n x n)이 된다.

선택 정렬은 깔끔한 알고리즘이지만 빠르지 않다. 퀵 정렬은 O(n x log(n)) 시간밖에 걸리지 않는 더 빠른 알고리즘이다.

```python
def findSmallest(arr):
    smallest = arr[0]
	smallest_index = 0
	for i in range(1, len(arr)):
	    if arr[i] < smallest:
		    smallest = arr[i]
			smallest_index = i
	return smallest_index
	
def selectionSort(arr):
    newArr = []
	for i in range(len(arr)):
	    smallest = findSmallest(arr)
		newArr.append(arr.pop(smallest))
	return newArr
	
print(selectionSort([5, 3, 6, 2, 10]))
```

### 2.4. 2장 정리

* 배열을 쓰면 모든 항목은 이웃하는 위치에 저장된다.
* 리스트를 쓰면 모든 항목이 흩어지지만, 각 항목은 다음 항목의 주소를 저장하고 있다.
* 배열은 읽기가 빠르다.
* 연결 리스트는 삽입과 삭제가 빠르다.
* 배열의 모든 원소는 같은 자료형이어야 한다.

### 2장 연습문제

큐를 구현하는 데 배열보다 연결 리스트를 사용하는 것이 좋다. 큐는 임의의 위치를 읽거나 검색할 필요가 없으므로 배열보다 연결 리스트가 훨씬 더 좋다.

페이스북이 사용자 이름 목록을 가지고 있다고 하자. 특정 사용자 이름을 검색하기 위해 이진 탐색을 사용한다고 가정하자. 이진 탐색을 하기 위해서는 임의 접근이 가능해야 한다. 이 경우에는 연결리스트보다 배열이 좋다. 이진 탐색을 하기 떄문에 리스트는 정렬되어 있어야 함을 잊지 말자.

페이스북에는 새로운 사용자 등록도 자주 발생한다. 이 경우에서는 배열이 좋지 않다. 

페이스북은 실제로 사용자 정보를 저장하기 위해 배열이나 연결 리스트를 사용하지 않는다. 다음과 같은 복합 자료구조를 생각해보자. 알파벳 하나하나를 지칭하는 26개의 칸이 있는 배열이 있다. 각각의 칸은 각자 다른 연결 리스트를 가리키고 있다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/2_1.PNG" width="60%" height="60%"></p>

이러한 복합 자료구조는 검색의 경우에는 배열보다 느리고 연결 리스트보다는 빠르다. 삽입의 경우에는 배열보다는 빠르고 연결 리스트와는 같은 시간이 걸린다. 즉, 배열보다는 검색 시간 측면에서만 느리고 연결 리스트보다는 모든 면에서 좋거나 최소한 같다.

이 책의 뒷부분에서는 해시 테이블이라고 하는 또 다른 복합 자료구조를 이야기할 것이다. 이 자료구조는 간단한 자료구조로부터 어떻게 복잡한 형태의 자료구조를 만들어 나가는지에 대한 아이디어를 줄 수 있다.

페이스북은 실제로 여러 가지 다른 데이터베이스를 사용하고, 각각의 데이터베이스 내부에서는 해시 테이블이나 B-트리와 같은 다양한 자료구조를 쓸 것이다. 배열과 연결 리스트는 이러한 복잡한 자료구조를 만드는 기초가 된다.


<br>
<div id='3.'/>

## 3. 재귀 (Recursion)

재귀(recursion)는 여러 가지 알고리즘에 쓰이는 코딩 테크닉으로 이 책의 나머지 장을 이해하기 위한 기초가 된다. 하나의 문제를 기본 단계와 재귀 단계로 나누는 방법을 배운다. 분할 정복(divide-and-conquer) 전략은 이런 간단한 개념을 사용하여 어려운 문제를 푸는 방법이다.

### 3.2. 재귀

큰 상자 속에 작은 상자들이 있고, 그 작은 상들 안에는 더 작은 상자들이 있다. 열쇠는 그 상자 속 어딘가에 있다. 열쇠를 찾기 위한 알고리즘은 무엇일까?

```python
# 방법 1 - while 반복문
def look_for_key(main_box):
    pile = main_box.make_a_pile_to_look_through()
	while pile is not empty:
	    box = pile.grab_a_box():
		for item in box:
		    if item.is_a_box():
			    pile.append(item)
			elif item.is_a_key():
			    print("열쇠를 찾았어요!")

# 방법 2 - 재귀
def look_for_key(box):
    for item in box:
	    if item.is_a_box():
		    look_for_key(item)
		elif item.is_a_key():
		    print("열쇠를 찾았어요!")
```

두 가지 방법 모두 같은 일을 하지만, 두 번째 방법이 더 명확하다. 재귀는 풀이를 더 명확하게 만들어 준다. 재귀를 쓴다고 성능이 더 나아지지는 않는다. 사실 반복문이 더 성능이 좋은 경우가 많다. 

"프로그램에 반복문을 사용하면 프로그램의 성능을 향상시킬 수 있지만, 재귀를 사용하면 프로그래머의 능력을 향상시킬 수 있다." - 스택 오버플로우: 레이 캐드웰

상황에 따라 적절한 방법을 골라 사용하자. 대부분의 중요한 알고리즘들이 재귀를 사용하므로 개념을 잘 이해하는 것이 중요하다.

### 3.3. 기본 단계와 재귀 단계

재귀 함수는 자기 자신을 호출하기 때문에 실수로 무한 반복을 하는 함수를 만들기 쉽다. 재귀 함수를 만들 때는 언제 재귀를 멈출지 알려줘야 한다. 그래서 모든 재귀 함수는 기본 단계(base case)와 재귀 단계(recursive case)라는 두 부분으로 나누어져 있다. 

재귀 단계는 함수가 자기 자신을 호출하는 부분이다. 기본 단계는 함수가 자기 자신을 다시 호출하지 않는 경우, 즉 무한 반복으로 빠져들지 않게 하는 부분이다. 

```python
def countdown(i):
    print(i)
	if i <= 1:	# 기본 단계
	    return
	else:	# 재귀 단계
	    countdown(i-1)
```

### 3.4. 스택

호출 스택은 프로그램에서 중요한 개념이지만 재귀를 사용할 때 더욱 중요하다. 컴퓨터는 호출 스택이라고 불리는 스택(stack)을 사용한다. 여러 개의 함수를 호출하면서 함수에 사용되는 변수를 저장하는 스택을 호출 스택(call stack)이라고 한다. 

스택을 사용하면 확인해야 할 상자 더미를 여러분이 일일이 추적하지 않아도 되므로 편리하다. 그렇지만 편리한만큼 대가를 치러야 한다. 모든 정보를 저장해야 하므로 메모리를 많이 소비한다. 함수 호출을 할 때마다 메모리를 사용하게 된다.

많은 메모리 소비를 방지하기 위한 방법으로
* 재귀 대신 반복문을 써서 코드를 다시 작성한다.
* 꼬리 재귀(tail recursion)라는 방법을 사용한다. 이는 고급 재귀 방법으로 모든 프로그래밍 언어에서 지원하는 것은 아니다.


### 3장 정리

* 재귀는 함수가 스스로를 호출하는 것이다.
* 모든 재귀 함수는 기본 단계와 재귀 단계라는 두 부분으로 나누어져 있다.
* 스택에는 푸시(push)와 팝(pop)이라는 두 가지 연산이 있다.
* 모든 함수 호출은 호출 스택을 사용한다.
* 호출 스택은 너무 커져서 메모리를 엄청나게 소비할 수도 있다.

### 3장 연습문제

재귀 함수가 무한 실행하면 스택에는 어떤 일이 발생할까? 스택에 할당할 수 있는 공간이 제한되어 있기 때문에 이 공간을 모두 사용하면 스택 오버플로우 오류가 발생하며 종료된다. 


<br>
<div id='4.'/>

## 4. 퀵 정렬 (Quicksort)

분할 정복(divide-and-conquer) 전략에 대해 알아보자. 가끔씩 여러분이 공부한 어떤 알고리즘으로도 풀 수 없는 문제를 만날 수 있다. 이런 문제를 풀기 위해서는 다양한 기술을 통해 해결 방법을 알아내야 한다. 분할 정복 전략은 여러분이 배우게 될 첫 번째 범용 기술(general technique)이다. 분할 정복 전략은 문제에 바로 적용할 수 있는 단순한 알고리즘이 아니고 문제를 풀기 위한 방법론에 가깝다.

퀵 정렬은 실무에 자주 사용되는 명쾌한 정렬 알고리즘 중 하나이다. 퀵 정렬은 분할 정복 전략을 사용한다.

### 4.1. 분할 정복

문제 해결 방법 중에서 가장 유명한 재귀적 기술인 분할 정복(divide-and-conquer) 전략에 대해 살펴보자.

한 가지 유형의 문제만 풀 수 있다면 그 알고리즘은 유용하다고 할 수 없다. 분할 정복 전략은 문제를 푸는 새로운 사고 방식을 제시한다. 여러분의 문제 해결 도구 상자에 새로운 도구를 넣게 되는거다. 새로운 문제에 부딪혀도 당황하지 말고 분할 정복 전략으로 문제를 풀 수 있는지 고민하자.

**토지 분할 문제**
여러분이 농부이고 1680m x 640m 크기의 농장을 가지고 있다하자. 이 농장을 똑같이 생긴 정사각형 토지들로 나누고 싶다. 어떻게 똑같은 크기의 가장 큰 정사각형으로 나눌 수 있을까? 재귀적 알고리즘인 분할 정복 전략을 활용하자. 다음과 같은 두 단계를 가진다.

1. 기본 단계를 해결한다. 이 부분은 가능한 한 간단한 문제이어야만 한다. (기본 단계)
2. 문제가 기본 단계가 될 때까지 나누거나 작게 만든다. (재귀 단계)

재귀 단계에서 분할 정복 전략이 활약할 타이밍이다. 분할 정복 전략에 따르면 재귀 함수 호출을 할 때마다 문제를 작게 나누어야 한다. 여기에서는 문제를 어떻게 나눌까? 조건에 맞는 가장 큰 상자를 알아내는 것부터 시작한다. 

한 변의 길이가 640m인 두 개의 정사각형 토지를 만들 수 있지만, 아직 나누지 못한 토지가 남게 된다. 이제 이 문제를 푸는 핵심 아이디어가 등장한다. 남은 토지를 나눌 때도 똑같은 방법을 사용하면 된다. 즉, 원래는 1680m x 640m 크기를 가진 농장의 토지를 나누는 문제로 시작했지만, 이제 더 작은 640m x 400m 크기의 농장의 토지를 나누는 새로운 문제를 푸는 것이다.

문제가 1680m x 640m -> 640m x 400m -> 400m x 240m -> 240m x 160m -> 160m x 80m 으로 바뀐다. 원래의 농장을 나눌 수 있는 가장 큰 정사각형의 크기는 80m x 80m이 된다.

**숫자들의 합 문제**

주어진 배열에 있는 숫자들을 모두 더하여 합계를 구하는 문제를 반복문을 사용하지 않고 재귀 함수를 사용해서 합계를 구해보자.

* 기본 단계를 찾는다. 가장 간단한 배열은 무엇일까?
* 재귀 함수 호출을 할 때마다 호출 대상이 되는 배열의 크기가 점점 감소해야 한다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/4_1.PNG" width="60%" height="60%"></p>

재귀에서는 상태를 추적한다는 점을 명심하자. 

배열을 포함하는 재귀 함수를 만들 떄, 기본 단계는 보통 빈 배열이나 원소가 하나뿐인 배열이 된다. 만약 문제를 풀다 막히면 이 방법을 사용하자.


**(TIP)함수형 프로그래밍**

반복문으로 풀 수 있는데 왜 재귀적으로 해야 하나? 함수형 프로그래밍을 살짝 맛본 것이다. 하스켈과 같은 함수형 프로그래밍 언어에는 반복문이란 것이 없다. 그러니 무조건 이렇게 재귀 함수를 사용해야 한다. 예를 들어, 하스켈 언어로 합계 함수는 다음과 같다.

```
sum [] = 0 					# 기본 단계
sum (x:xs) = x + (sum xs)	# 재귀 단계
```

### 4.2. 퀵 정렬

퀵 정렬(quicksort)은 선택 정렬보다 훨씬 빠르고 실제로도 자주 사용된다. 퀵 정렬은 분할 정복 전략을 가진다. 

기본 단계로는 정렬할 필요가 없는 배열, 즉 비어있거나 원소가 하나인 배열인 상태다. 주어진 배열을 기본 단계가 될 때까지 나눠야 한다. 퀵 정렬에서는 기준 원소(pivot)를 고르고, 모든 원소를 기준 원소보다 작은 원소와 큰 원소로 분류한다. 이것을 분할(partitioning)이라고 한다. 분할된 하위 배열(sub-array)에 대해서도 퀵 정렬을 호출한다. 이렇게 재귀적으로 호출하면 된다. 각 하위 배열들이 정렬되면 합쳐서 전체 배열을 정렬한다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/4_2.PNG" width="60%" height="60%"></p>

```python
def quicksort(array):
    if len(array) < 2:	# 기본 단계: 원소의 개수가 0이나 1이면 이미 정렬되어 있는 상태
	    return array
	else:	# 재귀 단계
	    pivot = array[0]	# 첫 번째 원소를 임의로 pivot이라 설정
		less = [i for i in array[1:] if i <= pivot]
		greater = [i for i in array[1:] if i > pivot]
		return quicksort(less) + [pivot] + quicksort(greater)
		
print(quicksort([10, 5, 2, 3]))
```

**(TIP)귀납적 증명**

방금 귀납적 증명을 살짝 맛보았다. 귀납적 증명은 알고리즘이 제대로 동작하는지 증명하는 방법 중 하나이다. 귀납적 증명에도 기본 단계(base case)와 귀납 단계(inductive case)라는 두 가지 단계가 필요하다.

기본 단계에서는 알고리즘이 가장 기본적인 경우, 즉 배열의 크기가 0이나 1인 경우에 대해 알고리즘이 동작한다는 것을 보여준다. 귀납 단계에서는 퀵 정렬이 크기가 1인 배열에 대해 동작하면 크기가 2인 배열에 대해서도 동작한다는 것을 보여준다. 3인 배열도 마찬가지로 보여준다. 이렇게 모든 크기의 배열에 대해 퀵 정렬이 동작한다고 말할 수 있다.

귀납적 증명은 흥미로운 주제일 뿐 아니라 분할 정복 전략과 함께 사용되기도 한다.


### 4.3. 빅오 표기법 복습

퀵 정렬은 여러분이 선택한 기준 원소에 따라 처리 속도가 달라진다는 특징이 있다. 먼저 일반적인 빅오 실행 시간 유형을 다시 보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/4_3.PNG" width="60%" height="80%"></p>

위의 추정치는 1초에 10회의 연산을 할 수 있는 느린 컴퓨터를 기준으로 하였다.

퀵 정렬의 실행 시간은 최악의 경우에는 O(n^2)이 될 수도 있다. 선택 정렬만큼 느린 것이다. 하지만 이것은 어디까지나 최악의 경우를 말한 것이고, 평균적인 경우에는 O(nlog(n)) 실행 시간을 가진다.

* 여기에서 최악의 경우와 일반적인 경우란 무엇을 뜻하나?
* 만약 퀵 정렬이 평균적으로 O(nlog(n))이라면 병합 정렬은 항상 O(nlog(n))인가? 그럼 왜 병합 정렬이 훨씬 빠른데 왜 쓰지 않는 것일까?

**병합 정렬과 퀵 정렬 비교**

리스트에 있는 모든 원소를 출력하는 간단한 함수가 있다고 하자.

```python

def print_items(list):
    for item in list:
	    print(item)
		
from time import sleep
def print_item2(list):
    for item in list:
	    sleep(1)
		print(item)
```

두 함수 모두 리스트를 한 번만 훑어보기 때문에 똑같이 O(n) 실행 시간을 가진다. 실제로는 print_items가 1초 동안 기다리지 않으므로 훨씬 빠르다. 

```
c x n
```

c는 알고리즘이 소비하는 어떤 특정한 시간으로 이를 상수(constant)라고 부른다. 

이진 탐색과 단숨 탐색을 예를 들어보자. 두 알고리즘 모두 다음과 같은 상수를 가진다고 하자. 

* 단순 탐색 - 10밀리초 x n
* 이진 탐색 - 1초 x log(n)

얼핏보면 단순 탐색이 훨씬 빠르게 보일수도 있다. 하지만, 40억 개의 원소를 가진 리스트를 탐색한다고 하자.

* 단순 탐색 - 10밀리초 x 40억 개 = 463초
* 이진 탐색 - 1초 x 32 = 32초

이진 탐색이 훨씬 빠르다. 즉, 상수는 전혀 문제가 되지 않는다.

가끔은 상수 때문에 차이가 발생하기도 한다. 퀵 정렬과 병합 정령이 그 예이다. 퀵 정렬이 병합 정렬보다 더 작은 상수를 가진다. 그래서 실행 시간이 O(nlog(n))으로 동일하다면 퀵 정렬이 더 빠르다. 그리고 퀵 정렬을 사용할 때 최악의 경우보다는 일반적인 경우가 훨씬 많이 발생하기 때문에 현실에서는 퀵 정렬이 더 빠르다.

**평균적인 경우와 최악의 경우 비교**

퀵 정렬의 성능은 여러분이 선택한 기준 원소에 크게 의존한다. 

만약 첫 번째 원소를 항상 기준 원소로 선택한다고 하고, 이미 정렬되어 있는 배열에 퀵 정렬을 호출해보자. 배열을 절반으로 나누지 않고 진행한다. 두 개의 하위 배열 중 하나는 항상 빈 배열이다. 그래서 호출 스택이 아주 길어진다. (배열 길이가 1024이라면 호출 스택의 전체 높이도 1024이다) 이 경우는 퀵 정렬의 최악의 경우를 나타내는 시나리오이다. 스택의 크기가 O(n)이다. (기준 원소를 임의로 첫 번째 원소로 정하지 않는 이상 이러한 시나리오는 발생하지 않지 않나?)

이번에는 정 가운데 있는 원소를 항상 기준 원소로 선택한다고 가정하자. 매번 배열을 절반으로 나누기 때문에 재귀적 호출을 많이 할 필요가 없다. 기본 단계에 더 빨리 도달하기 때문에 호출 스택이 짧아진다. (배열 길이가 1024이라면 호출 스택의 전체 높이는 10이다) 이 경우는 퀵 정렬의 최선의 경우를 나타내는 시나리오이다. 스택의 크기가 O(log(n))이다.

이제 스택의 각 단계를 살펴보자. 기준 원소로 원소 하나를 선택하면 나머지 원소들은 두 개의 하위 배열로 나누어진다. 이렇게 나누기 위해서는 1024개의 원소를 모두 기준 원소와 비교해야 한다. 이 작업에는 O(n) 실행 시간이 걸린다. 배열을 다르게 분할한다고 해도 여전히 매번 O(n)개의 원소를 모두 비교해야 하는 것은 마찬가지이다.

최악의 경우 호출 스택의 높이는 O(n)이고, 각각의 단계는 O(n) 시간이 걸리기 때문에 전체 알고리즘은 O(n) x O(n) = O(n^2) 시간이 걸린다. 최선의 경우는 O(log(n)) x O(n) = O(n x log(n)) 시간이 걸린다.

퀵 정렬에서는 일반적인 경우에도 최선의 경우와 같은 실행 속도를 가진다. 만약 기준 원소를 전체 배열에서 무작위로 선택한다면 퀵 정렬은 평균적으로 O(nlog(n)) 실행 시간을 가진다. 퀵 정렬은 가장 빠른 정렬 방법 중의 하나이고, 분할 정복의 좋은 예이다.

### 4장 정리

* 분할 정복은 문제를 더 작은 조각으로 나누어 푼다. 만약 리스트에 분할 정복을 적용한다면 기본 단계는 원소가 없는 빈 배열이거나 하나의 원소만 가진 배열이 된다.
* 퀵 정렬을 구현하려면 기준 원소를 무작위로 선택한다. 퀵 정렬의 평균적인 실행 시간은 O(log(n))이다.
* 빅오 표기법에서 가끔씩 상수가 중요해질 때도 있다. 퀵 정렬이 병합 정렬보다 빠른 이유도 상수 때문이다.
* 단순 탐색과 이진 탐색을 비교할 때는 상수항이 전혀 문제가 되지 않는다. 왜냐하면 리스트가 길어지면 O(log(n))이 O(n)보다 훨씬 빨라진다.

### 4장 연습문제

재귀 함수에 익숙해지기.

```python
# 리스트의 sum을 하는 재귀 함수
def sum(list):
    if list == []:
	    return 0
	return list[0] + sum(list[1:])

# 리스트에 포함된 원소의 숫자를 세는 재귀 함수
def count(list):
    if list == []:
	    return 0
	return 1 + count(list[1:])
	
# 리스트에서 가장 큰 수를 찾는 재귀 함수
def max(list):
    if len(list) == 2:
	    return list[0] if list[0] > list[1] else list[1]
	sub_max = max(list[1:])
	return list[0] if list[0] > sub_max else sub_max
```

이진 탐색 역시 분할 정복 전략이다. 이진 탐색의 기본 단계는 원소가 하나뿐인 배열이다. 만약 이 배열에서 원소를 찾으려면 바로 찾을 수 있다. 그렇지 않으면 배열에 없는 것이다. 이진 탐색의 재귀 단계에서는 배열을 2등분하고 하나씩 이진 탐색을 실행한다.

빅오 표기법의 중요한 포인트는 특정 연산 실행 시간이 아니라 접근하는 데이터 개수이다. 어떤 연산에 대해 신경을 쓸 것이 아니라 데이터가 증가할 때 연산은 어떻게 될 지를 신경써야 한다.

<br>
<div id='5.'/>

## 5. 해시 테이블 (Hash Tables)

### 5.1. 해시 함수의 소개

여러분이 식료품 가게에서 일을 하고 있다고 하자. 손님이 물건을 사러 오면 모든 물건의 가격이 적혀 있는 가격 장부(price book)에서 가격을 찾아봐야 한다. 만약 가격 장부가 알파벳 순서로 정렬되어 있지 않다면 단순 탐색(O(n))으로 모든 항목을 하나씩 확인해야 한다. 정렬되어 있다면 이진 탐색으로 O(log(n)) 시간이 소요된다. 밀려드는 손님을 대응하기 위해서 이진 탐색도 느리다. 해결책은 모든 장부를 외우고 있어야 한다. 해시 함수(hash function)를 통해 이를 실현할 수 있다.

|가격 장부에 있는 항목의 수| 단순 탐색 O(n)       | 이진 탐색 O(log(n))        | 해시 함수 O(1)        |
|:---------------:|:---------------:|:--------------:|:--------------:|
| centered column  | centered column | centered column | centered column |
| 100      		| 10초 | 1초 | 즉시 |
| 1000      		| 1.6분 | 1초 | 즉시 |
| 10000     		| 16.6분 | 2초 | 즉시 |

### 5.2. 해시 함수

해시 함수는 문자열(string)을 받아서 숫자를 반환하는 함수이다. 기술 용어로 말하면 문자열에 대해 숫자를 할당(mapping)한다. 해시 함수는 다음과 같은 요건을 갖추어야 한다.

* 해시 함수에는 일관성이 있어야 한다.
* 다른 단어가 들어가면 다른 숫자가 나와야 한다.

배열을 활용해서 해시 테이블(hash table)을 구성해보자 (해시 테이블이 일종의 자료구조이다). 매핑된 숫자를 배열의 인덱스라고 간주하자. 그리고 해당 인덱스 위치에 가격을 저장하자. 예를 들어, 'avocado'의 경우 해시 출력값이 3이라고 하면, 배열의 3번째 원소에 'avocado'의 가격을 저장한다. 이렇게 구성하면 탐색을 전혀 할 필요가 없어진다(해시 테이블의 장점).

* 해시 함수는 같은 이름에 대해서는 항상 같은 인덱스를 할당한다. 
* 해시 함수는 다른 문자열에 대해서는 다른 인덱스를 할당한다.
* 해시 함수는 배열의 크기를 알고 있어야 하며 유효한 인덱스만 반환해야 한다.

배열과 리스트는 직접 메모리를 할당하지만, 해시 테이블은 해시 함수를 사용해서 더 총명하게 어디에 원소를 저장할지 결정한다. 해시 테이블은 해시 맵(hash maps), 맵(maps), 딕셔너리(dictionaries), 연관 배열(associative arrays)이라는 이름으로도 알려져 있다. 

```python
book = dict()
book['apple'] = 0.67
book['milk'] = 1.49
book['avocado'] = 1.49
print(book)
>>>
{'avocado': 1.49, 'apple':0.67, 'milk':1.49}
```

해시 테이블은 키(key)와 값(value)을 가진다. book이라는 해시 테이블에서 상품 이름은 키가 되고, 가격은 값이 된다. 해시 테이블은 키에 대해 값을 할당한다.

### 5.3. 해시 테이블을 사용하는 예

**해시 테이블로 조회하기**

해시 테이블은 다음과 같은 일을 하고자 할 때 좋다.
* 어떤 것을 다른 것과 연관시키고자 할 때
* 무언가를 찾아보고자 할 때

```python
phone_book = dict()
phone_book['jenny'] = 8675309
phone_book['emergency'] = 911
print(phone_book['jenny'])
>>>
8675309
```

해시 테이블은 어떤 항목과 다른 항목 간의 관계를 쉽게 모형화한다.

해시 테이블은 더 큰 규모의 조회에서도 사용된다. 어떤 웹 사이트에 접속하든 그 주소는 모두 IP 주소로 번역되어야 한다. 이런 과정을 DNS 확인(DNS resolution) 작업이라고 한다. 해시 테이블은 이 기능을 제공하는 방법 중의 하나이다.

```python
dns_resolution = dict()
dns_resolution['google'] = '74.125.239.133'
dns_resolution['facebook'] = '173.252.120.6'

```

**중복된 항목을 방지하기**

대통령 선거를 한다고 하자. 한 사람당 하나의 투표만 할 수 있다. 투표하러 올 때마다 이미 투표했는지 확인하기 위해 아주 긴 목록(i.e. 5천만 길이)을 뒤져봐야 한다. 만약 투표한 사람의 이름을 리스트에 저장한다면 리스트 전체에 대해 산순 탐색을 반복해야 하기 떄문에 정말 느려질 것이다. 하지만, 해시 테이블에 저장하면 이름이 있는지, 없는지 순간적으로 알려준다. 따라서 중복을 확인하는 것도 해시 테이블이 훨씬 빠르다.

```python
voted = dict()
def check_voter(name):
    if voted.get(name):
	    print("돌려 보내세요!")
    else:
        voted[name] = True
        print("투표하게 하세요.")		
```

**해시 테이블을 캐시로 사용하기**

웹 사이트를 개발할 때 캐싱(caching)이 적합하다. 페이스북에 방문해서 페이스북 서버에 요청한다고 하자. 로그인을 하지 않았다면 모든 사용자에게 동일하게 로그인 페이지밖에 보이지 않는다. 페이스북은 똑같은 내용을 반복하도록 요청받는다. 이 경우 해당 내용을 그냥 외워서 사용자에게 보여주는 것이 좋다. 이것이 캐싱이다. 캐싱은 작업 속도를 올리는 일반적인 방법이다. 모든 대형 웹 사이트는 캐싱을 사용한다. 그리고 그 자료는 바로 해시 테이블에 저장된다.

페이스북은 홈페이지만 캐싱하는 것이 아니라 회사 소개, 회사 연락처, 사용 약관 등 많은 것을 캐싱하고 있다. 그래서 페이지 URL에 해당 페이지의 자료를 할당한다. 여러분이 페이스북을 방문할 때마다 서버는 먼저 해시 테이블에 저장된 페이지가 있는지 확인한다. 없으면 그제서야 서버에서 작업을 시작한다.

```python
cache = dict()
def get_page(url):
    if cache.get(url):
	    return cache[url]	# 캐싱된 자료를 전송
    else:
        data = get_data_from_server(url)
        cache[url] = data	# 캐시에 처음으로 자료를 저장
        return data
```

캐시에 URL이 없을 때만 서버가 작업을 한다. 또 자료를 반환하기 전에는 캐시에 저장한다. 다음에 누군가가 이 URL을 요청하면 서버에 작업을 시키는 대신에 캐싱한 자료를 꺼내서 보내줄 수 있다.

**해시 테이블의 장점**

* 어떤 것과 다른 것 사이의 관계를 모형화할 수 있다.
* 중복을 막을 수 있다.
* 서버에게 작업을 시키지 않고 자료를 캐싱할 수 있다.


### 5.4. 충돌

해시 테이블의 성능을 이해하기 위해 충돌을 알아보자. 이전에 해시 함수는 서로 다른 키를 배열의 서로 다른 위치에 할당한다고 하였다. 하지만, 정확하게 이렇게 할 수 있는 해시 함수를 만드는 것은 거의 불가능하다. 

예를 들어, 26 길이의 배열이 있다고 하자. 정말 간단한 해시 함수는 첫 글자에 따라 공간을 할당하는 것이다. 'Apples'를 해시 테이블에 넣으면 첫 공간이 할당된다. 문제는 'Avocados'를 해시에 넣고 싶으면 첫 번째 공간을 다시 할당해야 한다. 첫 번째 공간은 이미 'Apples'가 차지하고 있기에 이런 것을 **충돌(collision)**이라고 한다. 두 개의 키가 같은 공간에 할당되는 것이다. 덮어씌우게 될 것이다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/5_1.PNG" width="60%" height="80%"></p>

충돌을 해결하기 위한 방법은 여러 가지가 있다. 가장 간단한 방법은 같은 공간에 여러 개의 키를 연결 리스트로 만들어 넣는 것이다. 문제는 아이템이 많아질 경우 찾는 시간이 길어진다는 점이다. 만약 거의 대부분의 아이템이 'A'로 시작한다면, 전체 해시 테이블이 한 공간만 빼고 모두 비어있게 된다. 그 한 공간에는 거대한 연결 리스트가 있게 된다. 이건 그냥 모든 항목을 연결 리스트에 넣은 것이나 마찬가지다. 결국 해시 테이블이 느려지게 된다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/5_2.PNG" width="60%" height="80%"></p>

여기에서 두 가지 교훈을 얻을 수 있다.
* 해시 함수는 정말 중요하다. 방금 전의 해시 함수는 모든 키를 하나의 공간에 할당했다. 이상적으로는 해시 함수는 키를 해시 테이블 전체에 고르게 할당해야 한다.
* 만약 연결 리스트가 길어지면 해시 테이블의 속도도 느려진다. 하지만 좋은 해시 함수가 있다면 그런 일은 발생하지 않는다.

좋은 해시 함수는 충돌을 최소화한다. 

### 5.5. 성능

평균적인 경우에 해시 테이블은 모든 항목에 대해 O(1) 시간이 걸린다. O(1)은 상수 시간(constant time)이라고 불린다. 상수 시간은 순간적이라는 뜻이 아니라 해시 테이블의 크기에 상관없이 항상 똑같은 시간이 걸린다는 의미이다. 즉, 배열이 아무리 크든 작든 상관없이 원소 하나를 꺼내는 데 걸리는 시간은 동일하다. 

|                  | 평균적인 경우          | 최악의 경우          |
| :---------------:| :---------------:| :--------------:|
| centered column  | centered column | centered column |
| 탐색      		| O(1) | O(n) |
| 삽입      		| O(1) | O(n) |
| 삭제      		| O(1) | O(n) |

하지만 최악의 경우에 해시 테이블은 모든 항목에 대해 O(n) 시간, 즉 선형 시간이 걸린다. 정말 느리다. 배열, 연결 리스트와 비교해보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/5_3.PNG" width="60%" height="80%"></p>

평균적인 경우, 해시 테이블은 배열과 연결 리스트, 양쪽 세계의 좋은 점만 가진다. 하지만 최악의 경우에는 해시 테이블이 가장 느리다. 따라서 해시 테이블에서는 최악의 상황이 발생하지 않도록 하는 것이 중요하다. 그렇게 하려면 충돌을 피해야 한다. 충돌을 피하기 위해서 다음과 같은 것이 필요하다.

* 낮은 사용률
* 좋은 해시 함수

**사용률**

해시 테이블의 사용률(load factor)는 다음과 같이 계산한다. 해시 테이블은 저장을 위해 배열을 사용한다. 배열에서 이미 값이 차지하고 있는 공간의 수를 센다.

`해시 테이블에 있는 항목의 수 / 해시 테이블에 있는 (총) 공간의 수`

예를 들어, [,1,0,] 의 경우 사용률은 2/5이다. [,20,]은 1/3이다. 만약 100개의 물건을 50 길이의 배열에 할당한다면? 사용률이 2가 된다. 사용률이 1보다 크다는 것은 배열에 공간의 수보다 항목의 수가 많다는 뜻이다. 사용률이 커지기 시작하면 해시 테이블의 공간을 추가해야 한다. 이것을 **리사이징(resizing)**이라고 한다. 사용률이 낮을수록 충돌이 적게 일어나고, 해시 테이블의 성능도 좋아진다. 보통은 사용률이 0.7보다 커지면 리사이징한다.

라사이징은 엄청 비싼 작업이므로 자주 하는 것은 좋지 않다. 하지만 해시 테이블은 리사이징을 해도 평균적으로 O(1) 시간이 걸린다.

**좋은 해시 함수란**

좋은 해시 함수란 배열에 값을 고루 분포시키는 함수이다. 나쁜 해시 함수는 값들이 뭉쳐져 있어서 충돌이 자주 발생한다. 좋은 해시 함수의 예로 SHA 함수가 있다.


### 5장 정리

해시 테이블은 속도가 빠르고 자료를 여러 가지로 모형화할 수 있기에 아주 강력한 자료 구조이다.

* 해시 테이블은 해시 함수와 배열을 결합해서 만든다.
* 충돌은 나쁘다. 충돌을 줄이는 해시 함수가 있어야 한다.
* 해시 테이블은 정말 빠른 탐색, 삽입, 삭제 속도를 가진다.
* 해시 테이블은 어떤 항목과 다른 항목의 관계를 모형화하는 데 좋다.
* 사용률이 0.7보다 커지면 해시 테이블은 리사이징할 때이다.
* 해시 테이블은 (웹 서버 등에서) 데이터를 캐싱하는 데도 사용된다.
* 해시 테이블은 중복을 잡아내는 데도 뛰어나다.

<br>
<div id='6.'/>

## 6. 너비 우선 탐색 (Breadth-first Search)

### 6.2. 그래프의 소개

새로운 추상 자료구조인 그래프(graph)를 사용하여 네트워크를 모형화하는 방법을 배운다. 첫 번째 그래프 알고리즘을 살펴보자. 바로 너비 우선 탐색(BFS; Breadth-First Search)이라고 불리는 알고리즘이다. 너비 우선 탐색을 사용하면 두 항목 간의 최단 경로를 찾을 수 있다. 이 최단 경로라는 말은 여러 가지를 의미할 수 있다. 

* 체커 게임에서 가장 적은 수로 승리할 수 있는 방법을 계산하는 인공지능
* 맞춤법 검사기(실제 단어에서 가장 적은 개수의 글자를 고쳐서 올바른 단어를 만드는 방법)
* 여러분의 네트워크에서 가장 가까운 의사 선생님 찾기

그래프 알고리즘은 필자가 알고 있는 가장 유용한 알고리즘 중 하나이다. 이 장에서 배우는 알고리즘들은 몇 번이고 반복해서 적용할 수 있다.

여러분은 샌프란시스코에 있고, 트윈 픽스에서 금문교까지 가고 싶다고 하자. 버스로 가지만 최대한 적게 갈아 타고 싶다. 이런 종류의 문제를 최단 경로 문제(shortest-path problem)라고 한다. 최단 경로, 즉 가장 짧은 것을 찾아야 한다. 이렇게 최단 경로 문제를 푸는 알고리즘을 너비 우선 탐색이라고 한다. 

트윈 픽스에서 금문교까지 가는 최단 경로를 찾으려면 다음과 같은 절차가 필요하다.
* 문제를 그래프로 모형화한다.
* 너비 우선 탐색으로 문제를 푼다.

그래프란 무엇인가? 그래프는 정점(node)과 간선(edge)으로 이뤄진다. 정점은 여러 개의 다른 정점과 바로 이어질 수 있다. 이렇게 바로 이어진 정점을 이웃(neighbor)이라고 한다. 그래프는 항목들이 서로 어떻게 연결되어 있는지를 모형화하는 방법이다.

### 6.3. 너비 우선 탐색

앞에서 배운 이진 탐색이라고 하는 탐색 알고리즘을 살펴보았다. 너비 우선 탐색은 그래프를 대상으로 하는 다른 종류의 탐색 알고리즘이다. (이진 탐색은 배열을 대상으로 하는 탐색 알고리즘) 너비 우선 탐색은 다음과 같은 두 가지 종류의 질문에 대답하는 데 도움디 된다.

* Q1. 정점 A에서 정점 B까지 가는 경로가 존재하는가? (여러분의 네트워크에 망고 판매상이 있는가?)
* Q2. 정점 A에서 정점 B로 가는 최단 경로는 무엇인가? (누가 가장 가까운 망고 판매상인가?)

여러분이 망고 농장의 주인이라고 하자. 망고를 팔아 줄 수 있는 판매상을 찾고 있다. 여러분의 페이스북 친구 중에 망고 판매상이 있나? 확인하려면 페이스북의 친구 목록을 살펴보면 된다. 여러분의 친구 중에 망고 판매상이 없다면, 여러분의 친구의 친구를 찾아보면 된다. 친구의 친구, 이런 식으로 망고 판매상이 도달할 때까지 전체 네트워크를 탐색하면 된다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/6_1.PNG" width="60%" height="80%"></p>

**최단 경로 찾기**

가장 가까운 망고 판매상을 찾을 수 있나? 친구는 1촌, 친구의 친구는 2촌 관계이다. 만약 1촌 관계인 망고 판매상이 없을 경우에만 2촌 관계를 탐색한다. 너비 우선 탐색이 하는 일이 바로 이것이다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/6_2.PNG" width="60%" height="80%"></p>

또 다른 방법은 탐색 목록에 2촌 관계를 추가하기 전에 1촌 관계부터 모두 추가하는 것이다. 목록을 위에서부터 차례대로 망고 판매상이 있는지 확인한다면, 1촌 관계에 있는 망고 판매상을 2촌 관계에 있는 망고 판매상보다 먼저 찾을 수 있다. 너비 우선 탐색은 단순히 A에서 B로 가는 경로를 찾는 것이 아니라 최단 경로를 찾을 수 있다.

이 방법은 목록에 추가한 순서대로 사람을 찾을 때만 가능하다. 이를 위해 큐(queue) 또는 대기열이라고 불리는 자료구조를 사용한다. 

**큐**

큐는 큐 안의 원소에 임의로 접근할 수 없다는 점에서 스택과 비슷하다. 큐에는 삽입(enqueue)과 제거(dequeue)라고 하는 두 가지 연산이 있다. 큐는 탐색 목록에도 쓸 수 있다. 큐를 사용하면 목록에 먼저 추가된 사람들을 먼저 꺼내서 탐색한다. 그래서 큐를 선입 선출(FIFO; First In First Out) 자료구조라고도 한다. 반대로 스택은 후입 선출(LIFO; Last In First Out) 자료구조이다.

### 6.4. 그래프의 구현

그래프는 몇 개의 정점으로 이루어져 있다. 각각의 정점은 이웃하는 정점과 연결된다. '여러분->밥'과 같은 관계를 어떻게 표현할까? 관계를 표시하는 자료구조가 무엇이 있을까? 바로 해시 테이블이다. 해시 테이블을 사용하면 키에 값을 할당할 수 있다. 이 경우에는 어떤 정점에 이웃하는 정점을 할당한다. 다음과 같은 큰 그래프를 파이썬 코드로 나타내보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/6_3.PNG" width="60%" height="80%"></p>

```python
graph = {}
graph["you"] = ["alice", "bob", "claire"]
graph["bob"] = ["anuj", "peggy"]
graph["alice"] = ["peggy"]
graph["claire"] = ["thom", "jonny"]
graph["anuj"] = []
graph["peggy"] = []
graph["thom"] = []
graph["jonny"] = []
```

위 그림과 같이 화살표가 있는 그래프를 방향 그래프(directed graph)라고 한다. 관계에는 방향성이 있다. ANUJ는 BOB의 이웃이지만, BOB은 ANUJ의 이웃이 아니다. 무방향 그래프(undirected graph)는 화살표(방향성)를 가지지 않기 때문에 이어진 두 정점은 서로 이웃이 된다. 

### 6.5. 알고리즘의 구현

정리하자면 알고리즘이 구현되는 방식은 다음과 같다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/6_4.PNG" width="60%" height="80%"></p>

너비 우선 탐색의 코드는 다음과 같다.

```python
from collections import deque

def person_is_seller(name):
    # 좀 더 의미있는 함수로 바꿀 필요가 있음
    return name[-1] == 'm'

def search(name):

    search_queue = deque()	# 새로운 큐를 생성
	search_queue += graph[name]	# 모든 이웃을 탐색 큐에 추가
	searched = []	# 이 배열은 이미 확인한 사람을 추적하기 위한 것
	
	while search_queue:
	    person = search_queue.popleft()	# 큐의 첫 번째 사람을 꺼냄
		if not person in searched:	# 이전에 확인하지 않은 사람만 확인
		    if person_is_seller(person):	# 망고 판매상인지 확인
			    print(person + " is a mango seller!")
				return True
			else:
			    search_queue += graph[person]
				searched.append(person)	# 이 사람을 확인한 것으로 표시
    return False	# 망고 판매상이 아무도 없다는 의미
		
search("you")
```

망고 판매상인지 여부는 한 사람당 한 번만 확인하면 된다. 두 번 이상하면 컴퓨터 자원 낭비가 된다. 만약 탐색 큐에 어떤 두 사람이 반복해서 들어가면 무한 반복에 빠지게 된다. 이렇기 때문에 이미 확인한 사람인지 확실히 해두어야 한다.

**실행 시간**

망고 판매상을 찾기 위해 여러분의 네트워크 전체를 탐색한다는 것은 모든 정점을 따라서 움직인다는 뜻이다. 따라서 실행 시간은 최소한 O(간선의 개수)가 된다. 간선을 통해 친구를 찾아 나서기 때문에 여기서 정점의 개수가 아닌 점을 확인하자. 

그리고 탐색할 사람을 저장하는 큐가 있어야 한다. 큐에 사람을 추가하는 데는 상수 시간, 즉 O(1)이 걸린다. 모든 사람에 대해 이것을 적용하면 총 O(사람의수) 시간이 걸린다. 

따라서 너비 우선 탐색은 O(사람의 수 + 간선의 수)가 되고 보통 O(V+E)라고 표기한다. (V: 정점의 수, E: 간선의 수)

### 6장 정리

* 너비 우선 탐색은 A에서 B로 가는 경로가 있는지 알려준다
* 만약 경로가 존재한다면 최단 경로도 찾아준다
* 만약 X까지의 최단 경로를 찾는 문제가 있다면 그 문제를 그래프로 모형화하자. 그리고 너비 우선 탐색으로 문제를 풀자.
* 방향 그래프는 화살표를 가지며, 화살표 방향으로 관계를 가진다. (ex. rama -> adit: rama가 adit에게 돈을 빚지고 있다는 뜻)
* 무방향 그래프는 화살표가 없고, 둘 간의 상호 관계를 나타낸다. (ex. ross-rachel: ross와 rachel이 서로 데이터 했다는 뜻)
* 큐는 선입선출, 스택은 후입선출
* 탐색 목록에 추가된 순서대로 사람을 확인해야 한다. 그래서 탐색 목록은 큐가 되어야 한다. 그렇지 않으면 최단 경로를 구할 수 없다.
* 누군가를 확인한 다음에는 두 번 다시 확인하지 않도록 해야 한다. 그렇지 않으면 무한 반복이 될 수 있다.

### 6장 연습 문제

다음 그래프에 대해 올바른 목록을 만들어보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/6_5.PNG" width="60%" height="80%"></p>

['기상', '운동', '샤워', '양치질', '옷입기', '점심 도시락 싸기', '아침 식사']

이 목록은 어떤 의미에서는 정렬이 되어 있다고 할 수 있다. 만약 작업 A가 작업 B에 의존한다면 목록에서 작업 A가 작업 B보다 나중에 와야 한다. 이런 것을 위상 정렬(topological sort)이라고 하며, 그래프에서 정렬된 리스트를 만드는 방법의 하나이다. 할 일의 순서가 있는 계획표를 위상 정렬로 표현할 수 있다.

다음은 여러분의 가계도이다. 이것도 정점(사람)과 간선이 있으니까 그래프이다. 간선은 각 정점의 부모를 가리킨다. 모든 간선은 아래로 내려간다. 가계도에서 거꾸로 가는 선이 있을 수 없다. 이런 것을 트리(tree)라고 한다. 트리는 거꾸로 가는 간선이 없는 특별한 종류의 그래프이다. 트리는 항상 그래프이지만 그래프는 트리가 아닐 수도 있다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/6_6.PNG" width="60%" height="80%"></p>


<br>
<div id='7.'/>

## 7. 다익스트라 알고리즘 (Dijkstra’s algorithm)

그래프의 간선에 가중치를 준 가중 그래프(weighted graph)를 알아보자. 가중 그래프에서 X까지의 최단 경로를 구하는 다익스트라 알고리즘(Dijkstra's algorithm)을 알아보자. 

그래프에 싸이클(cycle)이 있는 경우에는 다익스트라 알고리즘을 사용할 수 없다. 싸이클을 지나갈 때마다 가중치가 늘어나기 때문에 싸이클을 지나면 최단 경로를 얻을 수 없다. 싸이클은 사실 무방향 그래프와 같다. 무방향 그래프에서는 각 정점에 사이클을 더할 수 있다. 다익스트라 알고리즘은 방향성 비순환 그래프(DAG; Directed Acyclic Graph) 또는 사이클을 가진 경우에는 가중치가 양수일 때만 적용된다.

다음 그림을 참조하자. 가중 그래프는 다익스트라 알고리즘을, 균일 그래프는 너비 우선 탐색을 사용한다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/7_2.PNG" width="60%" height="80%"></p>

### 7.2. 알고리즘의 구현

다음 그래프에서 다익스트라 알고리즘이 어떻게 동작하는지 알아보자. 각 구간은 분 단위로 표시한 이동 시간이다. 다익스트라를 사용해서 최단 시간 경로를 구해보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/7_1.PNG" width="60%" height="80%"></p>

다익스트라 알고리즘은 4단계로 구성된다.

* 가장 가격이 싼 정점을 찾는다. 가장 가격이 싼 정점이란 도달하는 데 시간이 가장 적게 걸리는 정점이다.
* 이 정점의 이웃 정점들의 가격을 조사한다. 현재의 가격보다 더 싼 경로가 있는지 확인하고, 있으면 가격을 수정한다.
* 그래프 상의 모든 정점에 대해 이러한 일을 반복한다.
* 최종 경로를 계산한다.

1단계 - 출발점 정점 기준

| 정점 | 정점까지 걸리는 시간 |
| :---------------:| :---------------:|
| centered column  | centered column |
| A      		| 6 |
| B      		| 2 |
| 도착점      		| 무한대 |

2단계 - B 정점 기준 (A 정점보다 싼 가격이므로 선택)

| 정점 | 정점까지 걸리는 시간 |
| :---------------:| :---------------:|
| centered column  | centered column |
| A      		| 6 -> 5 |
| B      		| 2 |
| 도착점      		| 무한대 -> 7 |

3단계 - A 정점 기준

| 정점 | 정점까지 걸리는 시간 |
| :---------------:| :---------------:|
| centered column  | centered column |
| A      		| 6 -> 5 |
| B      		| 2 |
| 도착점      		| 무한대 -> 7 -> 6 |

위 예제에서는 최종 경로를 계산하는 마지막 단계는 포함하고 있지 않다. 단지 정점을 돌아다니며 가격만 조사하고 있다. 이런식으로 알고리즘이 흘러간다는 사실만 알아두자.

### 7.4. 다익스트라 알고리즘을 사용한 물물 교환

라마는 악보를 팔아서 피아노를 구하고 싶어한다. 다음은 에이미와의 거래를 그래프로 표현한 것이다. 라마가 바꿀 수 있는 물건들은 정점을 나타냈다. 간선의 가중치는 물건을 바꾸는 데 드는 돈이다. 라마는 돈을 가장 적게 쓰면서 악보를 피아노와 바꾸려면 어떤 경로를 선택해야 하는지 알고 싶어 한다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/7_3.PNG" width="60%" height="80%"></p> 

시작하기에 앞서 각 정점에 대한 가격표를 만든다. 여기에 추가적으로 최종 경로 계산에 필요한 부모 정점도 만든다. 최종 경로를 구하기 위해서 정점, 가격뿐만 아니라 정점의 부모도 기록한다. 

1단계(초기 상태) - 악보(출발점) 정점 기준

| 부모 | 정점 | 가격 |
| :---------------: | :---------------: | :---------------: |
| centered column  | centered column | centered column |
| 악보 | LP | 5 |
| 악보 | 포스터 | 0 |
| -  | 기타  | 무한대 |
| -  | 드럼  | 무한대 |
| -  | 피아노 | 무한대 |

2단계 - 포스터 정점 기준 (LP보다 더 싼 가격이므로)

| 부모 | 정점 | 가격 |
| :---------------: | :---------------: | :---------------: |
| centered column  | centered column | centered column |
| 악보 | LP | 5 |
| 악보 | 포스터 | 0 |
| 포스터  | 기타  | 30 |
| 포스터  | 드럼  | 35 |
| -  | 피아노 | 무한대 |

3단계 - LP 정점 기준 (주의: BFS처럼 1단계씩 나아가야하므로 포스터 다음엔 LP이다)

| 부모 | 정점 | 가격 |
| :---------------: | :---------------: | :---------------: |
| centered column  | centered column | centered column |
| 악보 | LP | 5 |
| 악보 | 포스터 | 0 |
| LP  | 기타  | 20 |
| LP  | 드럼  | 25 |
| -  | 피아노 | 무한대 |

항상 가격이 싼 기준으로 업데이트된다. 

4단계 - 베이스기타 정점 기준 

| 부모 | 정점 | 가격 |
| :---------------: | :---------------: | :---------------: |
| centered column  | centered column | centered column |
| 악보 | LP | 5 |
| 악보 | 포스터 | 0 |
| LP  | 기타  | 20 |
| LP  | 드럼  | 25 |
| 베이스기타  | 피아노 | 40 |

5단계 - 드럼 정점 기준

| 부모 | 정점 | 가격 |
| :---------------: | :---------------: | :---------------: |
| centered column  | centered column | centered column |
| 악보 | LP | 5 |
| 악보 | 포스터 | 0 |
| LP  | 기타  | 20 |
| LP  | 드럼  | 25 |
| 드럼  | 피아노 | 35 |

5단계가 최종 결과이다. 피아노를 교환할 수 있는 가장 싼 가격은 35이다. 여기서 부모 정점을 하나씩 찾아서 가보면, '악보-LP-기타-드럼-피아노'인 경로를 가질 수 있는 것을 알 수 있다. 

이 예제를 통해 최단 경로라는 것이 반드시 거리를 최소화하는 것이 아니라는 것을 확인하자. 여기선 가중치가 있기 때문이다. 

### 7.5. 간선의 가중치가 음수인 경우

간선의 가중치가 음수인 경우는, 한 단계씩 나아갈 때 가격표의 일관성을 유지할 수 없다. 일단 어떤 정점을 처리하면 그 정점에 도달하는 더 싼 경로는 존재하지 않아야 하는데, 음수 가중치가 있으면 더 싼 경로가 발견되기도 한다. 따라서, 음의 가중치가 있는 경우 다익스트라 알고리즘을 사용할 수 없다. 만약, 음의 가중치를 가진 그래프에서 최단 경로를 찾고 싶다면 벨만-포드 알고리즘(Bellman-Ford algorithm)을 사용하면 된다.

### 7.6. 구현

다익스트라 알고리즘을 코드로 어떻게 구현할 지 다음 그래프를 예제로 살펴보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/7_4.PNG" width="60%" height="80%"></p> 

이 예제를 코딩하려면 3개의 해시 테이블이 필요하다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/7_5.PNG" width="60%" height="80%"></p> 

알고리즘을 실행하면서 가격 해시 테이블과 부모 해시 테이블을 갱신하게 된다.

다음은 그래프를 표현하는 해시 테이블이다.

```python
graph["start"] = {}
graph["start"]["a"] = 6
graph["start"]["b"] = 2

graph["a"] = {}
graph["a"]["fin"] = 1

graph["b"] = {}
graph["b"]["a"] = 3
graph["b"]["fin"] = 5

graph["fin"] = {}
```

다음은 가격을 저장하는 해시 테이블이다.

```python
infinity = float("inf")
costs = {}
costs["a"] = 6
costs["b"] = 2
costs["fin"] = infinity
```

부모를 위한 해시 테이블은 다음과 같습니다.

```python
parents = {}
parents["a"] = "start"
parents["b"] = "start"
parents["fin"] = None
```

마지막으로 각 정점은 한 번씩만 처리해야 하므로 이미 처리한 정점을 추적하기 위한 배열입니다.

```python
processed = []
```

모든 준비를 마쳤다. 이제 알고리즘을 살펴보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/7_6.PNG" width="60%" height="80%"></p> 

```python
def find_lowest_cost_node(costs): 
    # 입력이 costs(가격 해시 테이블)인 점을 확인. 
	# costs는 그래프 모형이 반영되고, (처음에 그래프의 엣지 방향에 따라 가격 해시 테이블 초기값이 달라짐)
	# 현재 state(출발 정점)가 반영되었다. (costs가 업데이트된 state마다 다르게 적용된다. costs가 항상 같진 않다. 매번 바뀐다)
    
	lowest_cost = float("inf")
	lowest_cost_node = None
	
	for node in costs: # 모든 정점을 확인
	    cost = costs[node]
		if cost < lowest_cost and node not in processed: # 아직 처리하지 않은 정점 중 더 싼 것이 있으면
		    lowest_cost = cost # 새로운 최저 정점으로 설정
			lowest_cost_node = node
    return lowest_cost_node


node = find_lowest_cost_node(costs) # 아직 처리하지 않은 가장 싼 정점을 찾는다.
# 출발선에서 가장 싼 정점 찾기. 왜냐? 위에 가격 해시 테이블 초기값이 출발선이기 때문이다.

while node is not None: # 모든 정점을 처리하면 반복문을 종료한다.
    cost = costs[node]
	neighbors = graph[node]
	
	for n in neighbors.keys(): # 모든 이웃에 대해 반복한다.
        new_cost = cost + neighbors[n]
		if costs[n] > new_cost: # 만약 현재 n 정점이 지나는 것이 가격이 더 싸다면
		    # 이렇게 한 단계 나아가면서 더 좋은 정보를 업데이트하는 것이 다익스트라 철학!
		    costs[n] = new_cost # 가격표를 업데이트!
			parents[n] = node # 부모 테이블을 업데이트!
			
    processed.append(node) # 정점을 처리한 사실을 기록
    node = find_lowest_cost_node(costs) # 다음으로 처리할 정점을 찾아서 반복
```

처리 순서는, B 정점 -> A 정점 -> FIN 정점이 된다. 각 정점마다 while 루프 내부의 로직을 처리한다. 처리할 때마다 모든 정점까지 가장 싼 가격과 부모 정점을 해시 테이블에 업데이트한다. 모든 정점을 다 처리하면 알고리즘이 끝난다. 자동으로 가격 해시 테이블과 부모 해시 테이블을 보면 정답을 찾을 수 있다.

### 7장 내용 정리

* 너비 우선 탐색은 가중치가 없는 균일 그래프에서 최단 경로를 계산하는 데 사용된다.
* 다익스트라 알고리즘은 가중 그래프에서 최단 거리를 계산하는 데 사용된다.
* 다익스트라 알고리즘은 모든 가중치가 양수일 때만 정상적으로 동작한다.
* 만약 가중치가 음수이면 벨만-포드 알고리즘을 사용한다.

<br>
<div id='8.'/>

## 8. 탐욕 알고리즘 (Greedy algorithms)

불가능한 문제, 즉 빠른 알고리즘 해법이 존재하지 않는 NP-완전 문제를 다루는 법을 배운다. 빠른 알고리즘을 찾느라 시간을 낭비하지 않도록 문제 해결이 불가능한지 아닌지 파악하는 방법을 공부한다. NP-완전 문제에 대한 간략한 해법을 빨리 구할 수 있는 근사 알고리즘도 배운다. 아주 간단한 문제 해결 기법 중 하나인 탐욕 알고리즘(greedy algorithm)을 공부한다.

### 8.1. 수업 시간표 짜기 문제 (The classroom scheduling problem)

여러분이 학교에서 되도록 많은 수업을 듣고 싶어 한다고 가정해보자. 여러분이 신청할 수 있는 과목의 목록은 다음과 같다. 어떤 과목들을 신청해야 가장 많은 수업을 들을 수 있을까?

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/8_1.PNG" width="60%" height="80%"></p> 

이를 해결하는 알고리즘은 매우 쉽다.

1. 가장 빨리 끝나는 과목을 고른다. 이 과목이 처음으로 신청해야 할 과목이다.
2. 첫 번째 과목이 끝난 후에 시작하는 과목을 고르는데, 마찬가지로 가장 빨리 끝나는 과목을 고른다. 이 과목이 두 번째로 신청해야 할 과목이다. 이런 식으로 반복한다.

결과적으로 미술, 수학, 음악 이 세 과목이 여러분이 신청해야 할 과목이 된다.

많은 사람이 이 알고리즘이 의심스러울 만큼 너무 간단해 보인다고 말한다. 하지만 간단하다는 것, 그것이 바로 탐욕 알고리즘(greedy algorithm)의 장점이다. 탐욕 알고리즘은 간단하다. 각각의 단계에서 최적의 수를 찾아내면 된다. 이 경우에는 과목 중에서 가장 빨리 끝나는 수업을 선택하는 것이 목표이다. 기술적 용어로 말하자면 각 단계에서 **국소 최적해(locally optimal solution)**를 찾음으로써 최종적으로는 전역 최적해(globally optimal solution)를 구하게 된다고 한다. 이 간단한 알고리즘으로 수업 시간표 짜기 문제(classroom scheduling problem)의 최적해를 구할 수 있다. 물론, 탐욕 알고리즘이 항상 성공하는 것은 아니다. 하지만 간단해서 구현하기 좋다.

### 8.2. 배낭 채우기 문제 (The knapsack problem)

여러분이 탐욕스러운 도둑이고 훔친 물건을 넣어 둘 배낭이 있다. 그 배낭에는 총 35파운드의 무게까지만 담을 수 있다. 여러분은 배낭에 넣을 물건의 가격의 합을 최대한 크게 하고자 한다. 여러분이 훔칠 수 있는 물건은 스테레오(30파운드, 3000$), 노트북(20파운드, 2000$), 기타(15파운드, 1500$)가 있다.

어떤 알고리즘을 써야 할까? 탐욕(greedy) 알고리즘을 사용하면 다음처럼 간단해 진다.

1. 가방에 들어갈 수 있는 것 중에서 가장 비싼 물건을 고른다.
2. 그 다음으로 가방에 들어갈 수 있는 물건 중에 가장 비싼 것을 고른다. 이 일을 반복한다.

하지만 이번에는 알고리즘이 제대로 동작하지 않는다. 스테레오 vs (노트북 + 기타)

분명히 탐욕 알고리즘은 올바른 답을 내놓지 못했다. 하지만 정답에 상당히 가까운 답이기도 하다. 여러분이 진짜 도둑이라면 완벽한 답 같은 것을 신경쓰지 않을 것이다. 그냥 "정답에 상당히 가까운" 답이기만 해도 충분할 것이다.

가끔은 완벽한 게 오히려 해가 될 수도 있다. 때로는 여러분에게 필요한 것이 완벽한 정답보다는 꽤 괜찮은 정도로만 문제를 풀어도 되는 알고리즘일 때가 있다. 이런 경우에 탐욕 알고리즘이 빛난다. 왜냐하면 구현이 간단하면서도 보통은 정답에 상당히 가까운 답을 주기 때문이다.

### 8.3. 집합 커버링 문제 (The set-covering problem)

여러분이 라디오 쇼를 시작했다고 하자. 미국 50개의 주에 있는 모든 사람에게 이 라디오 쇼를 들려주고 싶다. 그런데 하나의 방송국을 통해 청취할 수 있는 지역(커버(cover)하는 지역)이 한정되어 있기 때문에 전국에 흩어져 있는 몇 개의 라디오 방송국들을 방문해서 라디오 쇼를 진행할 예정이다. 전국의 모든 사람들이 최소한 한 번은 쇼를 들을 수 있도록 하려면 어떤 방송국을 방문해야 할지 계산해야 한다. 또, 방송국을 방문하여 한 번 쇼를 하는데 돈이 들기 때문에 최대한 적은 수의 방송국을 돌아야 한다. 

다음과 같이 각 방송국마다 커버할 수 있는 지역이 서로 다르고 겹치는 지역이 있을 수도 있다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/8_2.PNG" width="60%" height="80%"></p> 

50개 주 전체를 커버하는 가장 적은 수의 방송국의 집합은 어떻게 구해야 할까?

1. 가능한 모든 방속국의 부분 집합을 나열한다. 이를 멱집합(power set)이라고 한다. 가능한 부분 집합의 수는 2^n개이다.
2. 이 부분 집합 중에 50개 주 전체를 커버할 수 있으면서 가장 원소의 수가 적은 부분 집합을 고른다.

문제는 모두 가능한 부분 집합을 계산하는 데 시간이 많이 걸린다는 것이다. 부분 집합의 수가 2^n이기 때문에 O(2^n) 시간이 걸린다. 방송국의 수가 늘어나면 전체 실행 시간이 급격히 증가한다. 예를 들어, 초당 10개의 부분 집합을 확인할 수 있다고 가정하면 전체 실행 시간은 다음과 같다.

| 방송국의 수 | 전체 실행 시간 |
| :---------------: | :---------------: |
| centered column  | centered column |
| 5 | 3.2초 |
| 10 | 102.4초 |
| 32  | 13.6년 |
| 100  | 4 x 10^21 년  |

이 문제를 해결하는 충분히 빠른 속도를 가진 알고리즘은 존재하지 않는다. 그럼 어떻게 해야 하나?

**근사 알고리즘**

이때는 탐욕 알고리즘을 사용하면 된다. 다음과 같은 탐욕 알고리즘은 정답과 거의 비슷한 답을 유추한다. (탐욕 알고리즘을 근사 알고리즘이라보면 된다)

1. 아직 방송하지 않은 지역 중 가장 많은 지역에 방송할 수 있는 방송국을 고른다. 이미 방송되고 있는 지역이 일부 포함되어 있어도 상관없다.
2. 모든 주에 방송이 될 때까지 선택을 반복한다.

이것을 근사 알고리즘(approximation algorithm)이라고 한다. 정확한 답을 계산하는 데 시간이 너무 많이 걸린다면 근사 알고리즘을 사용할 수 있다. 근사 알고리즘의 성능은 다음 두 가지로 판단한다.

* 얼마나 빠른가
* 최적해에 얼마나 가까운가

탐욕 알고리즘의 단순함으로 인해 실행 속도가 빠르기 때문에 좋은 선택이 될 수 있다. 이 경우 탐욕 알고리즘으 실행 속도는 O(n^2) 시간이다. 여기서 n은 방송국의 수이다.



```python

## 주 목록 (여기선 50개 주 중 일부만 사용)
states_needed = set(['mt', 'wa', 'or', 'id', 'nv', 'ut', 'ca', 'az'])

## 방송국 목록
stations = {}
stations["kone"] = set(["id", "nv", "ut"])
stations["ktwo"] = set(["wa", "id", "mt"])
stations["kthree"] = set(["or", "nv", "ca"])
stations["kfour"] = set(["nv", "ut"])
stations["kfive"] = set(["ca", "az"])

## 여러분이 방문할 방송국의 목록
final_stations = set()


while states_needed:

    # 정답은 하나만 있는 것이 아니다. 모든 방송국을 하나씩 보면서 아직 방송이 되지 않는 주 중에서 가장 많은 주를 커버하고 있는 방송국을 고른다.
    # 이 방송국을 best_station이라 한다.
    best_station = None
    states_covered = set() # 아직 방송되지 않은 주 중에서 해당 방송국이 커버하는 주의 집합

    for station, states_for_station in stations.items():

        covered = states_needed & states_for_station # 아직 방송되지 않는 주 중에서 현재 고려하고 있는 방송국이 커버하는 주의 집합
        # 집합 연산 참고 => '|': 합집합, '&': 교집합, '-': 차집합
		
        if len(covered) > len(states_covered): # 이 방송국이 현재의 best_station보다 더 많은 주를 커버하는지 확인
            best_station = station
            states_covered = covered

    states_needed -= states_covered # 갱신; 이 방송국에서 커버하는 주는 이제 더 이상 고려할 필요 없다.
    final_stations.add(best_station) # 방송국 목록에 추가

>>> print(final_stations)
set(['ktwo', 'kthree', 'kone', 'kfive'])
```

1, 2, 3, 5번 방송국 대신에 2, 3, 4, 5번 방송국을 고를 수도 있다. 탐욕 알고리즘과 정확한 알고리즘의 실행 시간을 비교해보자.

| 방송국의 수 | O(n!) 정확한 알고리즘 | O(n^2) 탐욕 알고리즘 |
| :---------------: | :---------------: | :---------------: |
| centered column  | centered column |  centered column |
| 5 | 3.2초 | 2.5초 |
| 10 | 102.4초 | 10초 |
| 32  | 13.6년 | 102.4초 |
| 100  | 4 x 10^21 년  | 16.67분 |


### 8.4. NP-완전 문제 (NP-complete problems)

집합 커버링 문제와 외판원 문제를 풀기 위해서는 가능한 모든 집합을 계산해야 한다. 모든 가능한 경우를 다 따져서 최단/최소를 구해야 한다. 이런 문제를 NP-완전 문제라고 한다. 

외판원 문제의 경우 새로운 도시가 추가될 때마다 계산해야 할 경로의 수는 다음과 같이 팩토리얼 함수(factorial function)적으로 늘어난다. 만약 도시가 10개라면 가능한 경로는 10! = 2,628,800개이다. 약 3백만 개의 가능한 경로가 나온다. 도시의 수가 늘어나면 경로의 수가 엄청 빠르게 증가한다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/8_3.PNG" width="60%" height="80%"></p> 

참고로 외판원 문제를 풀기 위한 근사 알고리즘은 다음과 같다. 일단 아무 도시를 고르고, 아직 방문하지 않은 가장 가까운 도시를 다음 방문지로 선택. 이를 반복한다.

많은 똑똑한 사람들이 NP-완전 문제를 빠르게 해결할 수 있는 알고리즘을 만드는 것은 불가능하다고 생각한다.

**어떤 문제가 NP-완전 문제인지 알 수 있는 방법은?**

여러분이 풀고 있는 문제가 NP-완전 문제라는 것을 알아낸다는 것은 좋은 일이다. 그 시점에서 문제를 완벽하게 풀려는 노력을 멈추고, 대신 근사 알고리즘을 써서 풀 수 있을 것이다. 하지만 어떤 문제가 NP-완전인지 아는 것은 어려운 일이다. 보통 쉽게 풀리는 문제와 NP-완전 문제 사이에는 조그만 차이밖에 없다. 예를 들어, 앞 장에서 이야기한 최단 경로 문제는 두 지점 간의, 즉 지점 A에서 지점 B로 가는 최단 경로를 계산하는 것이다. 하지만 몇 개의 지점을 연결하는 최단 경로를 찾으려 하면 NP-완전 문제인 외판원 문제가 되어버린다.

여러분이 풀고 있는 문제가 NP-완전 문제인지 아닌지 알 수 있는 쉬운 방법은 없다. 다만 다음과 같은 몇 가지 참고 사항은 있다.

* 항목이 적을 때는 알고리즘이 빠른데, 항목이 늘어나면서 갑자기 느려진다. 
* "X의 모든 조합"이라고 하면 보통 NP-완전 문제이다.
* 더 작은 하위 문제로 변환할 수 없어서 X의 가능한 모든 버전을 계산해야 한다면 아마도 NP-완전 문제일 것이다.
* 문제가 수열(외판원 문제와 같은 도시의 순서같이)을 포함하고 풀기가 어려우면 NP-완전 문제일 수 있다.
* 만약 문제에 집합(라디오 방송국 집합처럼)이 있고 풀기가 어려우면 NP-완전 문제일 수 있다.
* 문제를 집합 커버링 문제나 외판원 문제로 재정의할 수 있다면, 명백하게 NP-완전 문제이다.

### 8장 내용 정리

* 탐욕 알고리즘은 전역 최적화를 목표로 하지만, 실제로는 국소 최적화를 한다.
* NP-완전 문제는 빠른 해답이 알려지지 않았다.
* 만약 NP-완전 문제가 주어지면 근사 알고리즘을 쓰는 것이 최선이다.
* 탐욕 알고리즘은 작성하기도 쉽고 빠르기 때문에 좋은 근사 알고리즘이 될 수 있다.

### 8장 연습 문제

* 퀵 정렬 - 탐욕 알고리즘이 아니다.
* 너비 우선 탐색 - 탐욕 알고리즘이다.
* 다익스트라 알고리즘 - 탐욕 알고리즘이다.

탐욕 알고리즘은 locally optimal choice at each stage를 한다는 것을 기억하자.

다음은 NP-완전 문제이다.

* 집배원이 20채의 집을 방문해야 한다. 모든 집을 방문하는 최단 거리를 찾아야 한다.
* 어떤 사람들의 집합 중에서 가장 큰 모임(서로를 아는 사람의 집합)을 찾느 문제.
* 여러분이 미국 지도를 만들고 있는데 인접한 주는 서로 다른 색을 칠하고 싶다. 인접한 주에 다른 색을 칠하면서 전체를 칠하는 가장 적은 수의 색을 찾고 싶다.


<br>
<div id='9.'/>

## 9. 동적 프로그래밍 (Dynamic programming)

어려운 문제를 여러 개의 하위 문제로 쪼개고, 이 하위 문제들을 먼저 해결하는 방법이 동적 프로그래밍 기법이다. 

### 9.1. 배낭 채우기 문제

8장에 나왔던 배낭 채우기 문제를 다시 들여다보자. 여러분은 4파운드의 집을 넣을 수 있는 배낭을 가진 도둑이다. 여러분이 훔칠 수 있는 물건은 다음과 같이 3개가 있다. 훔친 물건의 총 가치를 최대치로 높이려면 어떤 물건들을 훔쳐야 하나?

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_1.PNG" width="60%" height="80%"></p> 

**단순한 방법**

가장 단순한 방법은 모든 물건의 조합을 시도해서 각 경우의 총 가치를 모두 구해본 다음, 가장 가치가 높은 경우를 선택하는 것이다. 이 방법은 가능하지만 너무 느리다. 물건이 3개면 계산해야될 경우의 수가 8개이다. 이 알고리즘의 실행 시간은 O(2^n) 시간이 되는데 이는 너무 느리다.

물건의 수가 몇개만 되어도 이 문제를 푸는 것은 불가능에 가깝다. 8장에서는 어떻게 근사해를 구하는지 살펴보았다. 이 방법은 최적해에 가깝기는 해도 최적해 자체는 아닐 수도 있다. 그러면 최적해는 어떻게 계산할 수 있을까?

**동적 프로그래밍**

동적 프로그래밍으로 최적해를 구할 수 있다. 동적 프로그래밍은 하위의 작은 문제들을 풀고, 이를 이용해서 더 큰 문제를 풀어나가는 방법이다. 배낭 채우기 문제에서는 더 작은 배낭, 즉 하위 배낭(sub-knapsack)에 대한 문제를 풀고 이를 이용해서 원래의 문제를 풀어나간다.

모든 동적 프로그래밍 알고리즘은 격자(grid)로부터 시작한다.  (각 행은 물건을, 각 열은 물건을 담을 수 있는 배낭의 크기를 뜻한다)

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_2.PNG" width="60%" height="80%"></p> 

격자는 빈 상태에서 시작한다. 격자를 모두 채우게 되면 문제에 대한 답이 나온다. 행->열 순으로 격자를 채워나가자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_3.PNG" width="60%" height="80%"></p> 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_4.PNG" width="60%" height="80%"></p> 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_5.PNG" width="60%" height="80%"></p> 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_6.PNG" width="60%" height="80%"></p> 

만약 배낭에 공간이 남게 되었을 때, 그 하위 문제에 대한 답을 사용하여 빈 공간의 가치가 최대가 되는 값을 찾아낼 수 있다. 

각 칸의 가치는 모두 다음과 같은 공식으로 동일하게 계산할 수 있다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_7.PNG" width="60%" height="80%"></p> 


### 9.2. 배낭 채우기 문제에서 자주 하는 질문

**만약 물건이 추가되면 어떻게 되나요?**

새로운 물건이 추가되면 문제를 처음부터 다시 풀어야 하나? 그렇지 않다. 동적 프로그래밍은 점진적으로 답을 수정해 나가는 방법이다. 네 번째 물건인 아이폰(1파운드, $2000)이 추가되었다고 해보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_8.PNG" width="60%" height="80%"></p> 

참고로, 열의 최대값이 더 작아지는 경우는 없다. 매번 현재의 최대 가치를 저장해 놓고 비교해 보기 때문에 답이 이전의 값보다 더 나빠지는 경우는 있을 수 없다.

**만약 행의 순서가 바뀌면 어떻게 되나요?**

행의 순서가 바뀌어도 답은 바뀌지 않는다. 즉, 행의 순서에는 영향을 미치지 않는다.

**만약 더 작은 물건을 추가하면 어떻게 되나요?**

여러분이 목걸이도 훔칠 수 있다고 가정하자. 목걸이의 무게는 0.5파운드이고 1000달러의 가치가 있다. 지금까지는 모든 무게가 정수라고 가정했는데, 이제 무게가 0.5파운드인 목걸이를 훔치기로 했다. 남은 공간은 3.5파운드인데 이 3.5파운드의 공간에 들어갈 수 있는 최대 가치는 얼마일까? 지금은 이 값을 알 수 없다. 배낭의 종류를 목걸이의 단위에 맞게 세분화해야 한다. 그래서 격자는 다음과 같이 변경해야 한다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_9.PNG" width="60%" height="80%"></p> 

**물건의 일부만 훔칠 수도 있나요?**

여러분이 식료품 가게를 침입한 도둑이라 하자. 가게에는 콩 주머니와 쌀 주머니가 있다. 만약 주머니가 배낭에 다 들어가지 않는다면 주머니에서 콩이나 쌀을 필요한 만큼 꺼내서 담을 수 있다. 즉, 전체를 훔치는 것이 아니라 일부만 훔칠 수도 있는 것이다. 이런 상황은 동적 프로그래밍으로는 할 수 없다. 하지만 이 경우는 탐욕 알고리즘으로 쉽게 풀 수 있다. 우선 가장 값이 나가는 것을 담을 수 있을 만큼 담는다. 그러고도 배낭에 공간이 남는다면 그 다음으로 값진 물건을 담고, 그 다음에는 같은 방식으로 반복하면 된다.

**여행 일정 최적화 문제**

런던으로 휴가를 떠난다고 하자. 런던에 이틀 동안 머물면서 하고 싶은 것을 가능한 한 많이 해보고 싶다. 하지만 모든 것을 다 할 수는 없으니까 가고 싶은 곳의 표를 만든다. 이 문제는 배낭 채우기 문제와 같다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_10.PNG" width="60%" height="80%"></p> 

다음과 같이 격자를 그려 문제를 푼다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_11.PNG" width="60%" height="80%"></p> 

**서로 의존적인 물건을 다루는 방법**

이번에는 파리 여행도 가고 싶다. 그래서 표에 장소를 몇 개 추가한다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_12.PNG" width="60%" height="80%"></p> 

런던에서 파리로 가는 데만 반나절이 걸린다. 만약 세 군데를 모두 방문한다면 단순히 이 값을 모두 더한 4일과 반나절이 걸릴까? 그렇지 않다. 일단 파리로 가면 각 장소를 돌아보는 데는 하루밖에 걸리지 않는다. 그러니까 세 군데를 모두 돌면 각 장소당 하루 + 파리까지 반나절, 즉 4.5일이 아닌 3.5일이 걸린다.

만약 배낭에 에펠탑을 넣으면 루브르 박물관은 1.5일이 아니라 1일로 줄어든다. 이런 경우는 동적 프로그래밍으로 어떻게 푸나?

이 문제는 동적 프로그래밍으로 풀 수 없다. 동적 프로그래밍은 문제를 더 작은 하위 문제로 풀고, 이 하위 문제를 푼 결과를 이용해서 더 큰 문제를 푸는 방법이다. 그래서 강력하다. 하지만 동적 프로그래밍은 각 하위 문제들이 서로 관계가 없을 때, 즉 서로 의존하지 않는 경우에만 쓸 수 있다. 따라서 파리까지 고려하게 되면 동적 프로그래밍 알고리즘으로는 문제를 풀 수 없다.

**하위 배낭이 두개 이상인 경우도 있을 수 있나요?**

두 개 이상의 물건을 훔치는 경우에는 하위 배낭이 두 개 이상일 수도 있다. 기본적으로 여러분은 최대 두 개의 배낭을 합칠 수 있다. 하지만 그 배낭 중의 하나가 두 개의 더 작은 배낭으로 이루어져 있을 수도 있다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_13.PNG" width="60%" height="80%"></p> 

**배낭을 완전히 채우지 못하는 경우도 있나요?**

네 있다. 만약 무게가 3.5파운드인 다이아몬드가 있다고 하자. 그리고 100만 달러의 가치가 있다. 그런데 0.5파운드의 남는 공간이 있고 거기에 맞는 다른 물건은 없다. 이 경우에는 배낭을 완전히 채울 수는 없다.

### 9.3. 최장 공통 부분 문자열

* 동적 프로그래밍은 어떤 제한 조건이 주어졌을 때 무언가를 최적화하는 경우에 유용하다. 배낭 채우기 문제에서는 배낭의 크기가 제한 조건이었고, 이때 훔칠 물건의 총 가치를 최대화하는 것이 목표였다.
* 동적 프로그래밍은 하위 문제가 서로 의존하지 않는 경우에만 사용할 수 있다.

동적 프로그래밍을 사용한 답을 즉각 떠올리는 것은 어려운 일이다. 다음과 같은 사항들을 참조하면서 살펴보길 바란다.

* 모든 동적 프로그래밍의 답안에는 격자가 있다.
* 격자의 각 칸에는 최적화하고자 하는 값을 적는다. 배낭 문제의 경우에는 모든 물건의 총 가치를 썼다.
* 각 칸은 원래 문제에 대한 하위 문제이고, 다른 문제를 하위 문제로 가질 수 있다. 그러니까 원래의 문제를 어떻게 하위 문제로 나눌 수 있을지 생각해야 한다. 그러면 각각의 축이 어떻게 되어야 하는지 알아내는 데 도움이 된다.

다른 예제를 살펴보자. 사용자가 입력한 단어와 비슷한 단어를 어떻게 찾을 수 있을까? 예를 들어, 사용자가 "fish"라는 단어를 찾아보고 싶었는데 실수로 "hish"라고 입력했다. 이 단어는 여러분의 사전에는 없고 대신 비슷한 단어들이 있을 것이다. 사용자가 입력한 "hish"라는 단어는 "fish"를 뜻하는 것일까? 아니면 "vista"를 뜻하는 것일까?

**격자 만들기**

이 문제의 격자는 어떻게 생겼을까? 우선 다음과 같은 질문에 답해봐야 한다.

* 각 칸에 넣을 숫자는 무엇인가?
* 이 문제를 어떻게 하위 문제로 나눌 수 있을까?
* 격자의 축은 무엇인가?

동적 프로그래밍에서는 무언가를 최대화하는 것이 목표이다. 이 문제에서는 두 단어에서 공통적으로 가지는 가장 긴 부분 문자열, 즉 **최장 공통 부분 문자열**(Longest Common **Substring**)을 찾는 것이다.

최대화하고자 하는 값을 칸에 써야 한다는 것을 잊지 말자. 이 문제에서는 두 문자열이 공통으로 가지는 가장 긴 부분 문자열의 길이를 나타내는 숫자를 써야 한다.

이 문제를 어떻게 하위 문제로 나눌 수 있을까? 부분 문자열을 비교하는 문제를 풀면 된다. "high"와 "fish"라는 단어를 직접 비교하는 대신에 "his"와 "fis"라는 단어를 먼저 비교하는 것이다. 각 칸에는 이 두 단어의 최장 공통 부분 문자열의 길이를 쓴다. 그러면 각각의 축이 그 두 단어를 의미한다는 것도 알 수 있다. 결과적으로 격자는 다음과 같이 생긴다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_14.PNG" width="60%" height="80%"></p> 

**격자 채우기**

이제 격자가 어떻게 생겼는지도 안다. 그러면 이 격자에 값을 채우는 공식은 무엇일까? 사실 여러분은 답을 이미 알고 있다. "hish"와 "fish"의 최장 공통 부분 문자열은 "ish"라는 세 글자이다. 

하지만 이는 공식이 아니다. 컴퓨터 과학자가 하는 농담 중에 파인만 알고리즘(Feynman algorithm)이라는 것이 있다. 이 알고리즘은 (1) 문제를 작성한다. (2) 열심히 생각한다. (3) 답을 쓴다. 로 구성된다. 컴퓨터 과학자들의 농담이다.

이 농담이 말하고자 하는 바는 공식을 찾아내는 쉬운 방법이 없다는 것이다. 제대로 되는 무언가를 찾을 때까지 여러 가지 실험을 반복해야 한다. 알고리즘이라는 것은 그대로 따라하기만 하면 되는 요리법 같은 것이 아니다. 알고리즘은 단지 여러분의 아이디어를 쌓아 올릴 수 있는 토대에 지나지 않는다.

격자는 최종적으로 다음과 같아지고, 각 칸들을 채우기 위한 공식은 다음과 같다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_15.PNG" width="60%" height="80%"></p> 

의사코드로 나타내면 다음과 같다. 

```python
if word_a[i] == word_b[j]:
    cell[i][j] = cell[i-1][j-1] + 1
else:
    cell[i][j] = 0
```

"hish"와 "vista"의 경우에는 다음과 같다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_16.PNG" width="60%" height="80%"></p> 

한 가지 주의할 점이 있다. 이 문제의 경우에는 마지막 칸이 최종 답이 아니다. 배낭 채우기 문제에서는 마지막 칸이 최종 답이었다. 하지만 최장 공통 부분 문자열 문제에서의 답은 격자 전체에서 가장 큰 숫자이다. 그리고 그 숫자는 마지막 칸에 있는 숫자가 아닐 수도 있다.

결과적으로 사용자는 "vista"보다는 "fish"를 입력하고자 했던 것이다.

**최장 공통 부분열**

만약 알렉스가 실수로 "fosh"라고 입력했다고 하자. 원래 어떤 단어를 입력하려고 했던 걸까? "fish"일까 아니면 "fort"일까?

두 단어를 최장 공통 부분 문자열 공식으로 비교해보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_17.PNG" width="60%" height="80%"></p> 

답이 두 글자로 같다. 하지만 "fosh"가 "fish"에 더 가까운 단어이다. 

사실 최장 공통 부분 문자열의 길이가 아니라 **최장 공통 부분열**(Longest Common **Subsequence**), 즉 두 단어에서 순서가 바뀌지 않고 공통으로 들어간 글자의 개수를 최대화하는 것이 옳다. (이렇게 어떤 것을 최대화할 지 정의하는 것이 굉장히 중요하다. 하나의 격자가 필요할 수도 있고 두 개 이상의 격자가 필요할 수도 있을 것 같다. 보다 더 정확한 정답을 위해서..)

다음 격자는 최장 공통 부분열을 적용한 것이다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_18.PNG" width="60%" height="80%"></p> 

각 칸에 넣은 숫자의 공식은 다음과 같다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/9_19.PNG" width="60%" height="80%"></p> 

의사코드는 다음과 같다. 

```python
if word_a[i] == word_b[j]:
    cell[i][j] = cell[i-1][j-1] + 1
else:
    cell[i][j] = max(cell[i-1][j], cell[i][j-1])
```

이렇게 어려운 동적 프로그래밍은 현실에서 다양한 도메인에서 많이 활용된다.

* 생물학자는 DNA 가닥의 유사점을 찾기 위해 최장 공통 부분열 방법을 사용한다. 그러면 두 종류의 동물이나 질병이 얼마나 비슷한지 알 수 있다. 최장 공통 부분열 방법은 다발성 경화증이라는 병의 치료법을 찾는 데도 쓰인다.
* git diff와 같은 diff 명령은 두 파일의 차이점을 찾아준다. 이를 위해 동적 프로그래밍을 사용한다.
* 우리는 문자열의 유사성을 따지고 있다. 레벤슈타인의 거리(Levenshtein distance)는 두 문자열의 유사성을 측정한다. 물론 동적 프로그래밍을 사용한다. 레벤슈타인의 거리는 철자법 확인이나 누군가가 지적 재산권이 있는 데이터를 인터넷으로 업로드했는지 확인하는 데도 쓰인다.
* 마이크로소프트 워드와 같은 프로그램에서 줄 맞추기 기능을 구현하기 위해서 동적 프로그래밍을 사용한다.


### 9장 내용 정리

* 동적 프로그래밍은 제한 조건이 있는 경우에 무언가를 최적화할 때 유용하다.
* 동적 프로그래밍은 큰 문제를 작은 하위 문제로 나누어 푸는 방법이다.
* 동적 프로그래밍을 풀 때는 격자를 사용한다.
* 보통 격자의 각 칸에는 최적화하려는 값을 쓴다.
* 격자의 각 칸은 하위 문제를 뜻한다. 그러므로 원래의 문제를 어떻게 하위 문제로 나눌 수 있는지 생각해야 한다.
* 동적 프로그래밍의 해답을 계산해 주는 쉬운 공식 같은 것은 없다.



<br>
<div id='10.'/>

## 10. KNN 알고리즘 (K-nearest neighbors)

### 10.1. 오렌지와 자몽 분류하기

어떻게 분류할 수 있을까? 한 가지 방법은 그래프 상에서 주변을 살펴보는 것이다. 주변을 둘러보니 가장 가까운 이웃(neighbors)이 있다.

### 10.2. 추천 시스템 만들기

고객을 위한 영화 추천 시스템을 만들어보자. 우선 모든 고객을 그래프에 그릴 수 있다. 유사도(similarity)를 이용하여 고객을 그래프 상에 표현하였다. 즉, 서로 취향이 비슷한 고객을 근접한 위치에 그렸다. 이 그래프가 있으면 추천 시스템을 만드는 것은 쉽다. 일단 고객을 그래프에 표현할 수만 있다면 두 고객 사이의 거리를 측정할 수 있다. 거리는 피타고리스 정리의 거리 공식을 사용한다. 어떤 한 명은 보통 사람들과 달리 평점을 주는데 아주 인색하다고하면 취향이 비슷함에도 거리 공식으로는 이웃이 되지 않을 수도 있다. 이 경우는 크기 정규화까지 해주는 코사인 유사도를 활용하는 것이 좋다.

**특징 추출**

고객을 숫자의 집합으로 나타내야 한다. 각 숫자는 특징을 표현한다. 예를 들어, 각 장르(코디미, 액션, ...)에 대한 선호도 점수가 있다.

**회귀 분석**

어떤 영화에  프리얀카가 어떤 평점을 줄지 예측하고 싶다면 어떻게 해야 하나? 우선 그녀와 가장 비슷한 k명의 데이터를 모으자. k명의 이웃들의 평점의 평균을 구하자. 이런 것을 회귀(regression) 분석이라고 한다. 즉 KNN은 분류와 회귀 분석의 두 가지 기능이 있다.

**좋은 특징 고르기**

올바른 특징이란 다음과 같은 특징을 말한다. 

* 추천하고자 하는 영화와 직접 관련이 있는 특징
* 편향되지 않은 특징 (예를 들어, 코미디 영화에 대한 평점만 있는 경우)

좋은 특징을 고르는 데 있어 정답은 없다. 여러 가지 다른 관점에서 모두 살펴보아야 한다.

### 10.3. 머신러닝 소개

* OCR
* 스팸 필터
* 주식 시장 예측하기

### 10장 내용 정리

* KNN은 k개의 가장 가까운 이웃 데이터를 이용하여 분류와 회귀 분석을 할 수 있다.
* 분류 = 그룹으로 나누는 작업
* 회귀 = 숫자로 된 반응을 예측
* 특징 추출은 항목을 비교 가능한 몇 개의 숫자로 만드는 일이다.
* 좋은 특징을 고르는 것은 성공적인 KNN 알고리즘을 만드는 데 있어 중요한 부분이다.


<div id='11.'/>

## 11. 더 공부해야 할 것

### 11.1. 트리

이진 탐색을 위해 배열을 사용하면 한 가지 문제가 있다. 새로운 데이터를 삽입하면 배열을 다시 정렬해야 한다. 왜냐하면 이진 탐색은 정렬된 배열에 대해서만 쓸 수 있기 때문이다. 이진 탐색 트리(binary search tree)라는 자료구조를 사용하면 재정렬할 필요가 없다. 이진 탐색 트리는 모든 정점에 대해 왼쪽에는 더 작은 값을 가진 정점, 오른쪽에는 더 큰 값을 가진 정점이 온다.

이진 탐색 트리에서 항목을 찾으려면 평균적으로 O(log(n)) 시간이 걸리고, 최악의 경우에 O(n) 시간이 걸린다. 정렬된 배열에서는 최악의 경우에도 O(log(n)) 시간이 걸린다. 결과적으로 정렬된 배열이 더 낫긴 하지만, 이진 탐색 트리는 항목을 삽입하거나 삭제할 때도 평균적으로 훨씬 빠르다.

|  | 배열 | 이진 탐색 트리 |
| :---------------: | :---------------: | :---------------: |
| centered column  | centered column |  centered column |
| 탐색 | O(log(n)) | O(log(n)) |
| 삽입 | O(n) | O(log(n)) |
| 삭제 | O(n) | O(log(n)) |

이진 탐색 트리에도 몇 가지 단점이 있다. 하나는 임의 접근(random access)을 할 수 없다. 또한, 평균적인 성능이 트리가 얼마나 균형이 잡혀있는가에 따라 달라진다. 스스로 균형을 맞추는 특별한 이진 탐색 트리인 레드-블랙 트리(red-black tree)가 있다.

이러한 이진 탐색 트리의 특별한 유형인 B-트리는 데이터베이스에서 데이터를 저장할 때 흔히 사용된다. 데이터베이스나 고급 자료구조에 관심이 있다면 다음과 같은 것들을 공부해봐라.

* B-트리(B-trees)
* 레드-블랙 트리(red-black trees)
* 힙(heaps)
* 스플레이 트리(splay trees)

### 11.2. 역 인덱스

역 인덱스(inverted index)는 주로 검색엔진을 만드는 데 사용된다.

### 11.3. 푸리에 변환

Better Explained에서는 푸리에 변환을 다음과 같이 비유한다. "푸리에 변환을 사용하면 스무디(smoothie)가 무슨 성분으로 구성되어 있는지 알아내는 것처럼 하나의 노래를 여러 개의 개별적인 주파수들로 분리할 수 있다."

푸리에 변환을 통해서... 

* 노래를 주파수별로 분리해서 듣고 싶은 주파수만 들을 수 있다. 중저음 영역을 확대하고 고음 영역을 가릴 수도 있다.
* 음악을 압축하는 데 사용할 수 있다. 음향 파일을 개별 음파로 분리한 다음 각 음파가 전체 노래에 어느 정도 기여하는지를 계산해서 별로 중요하지 않은 음파는 제거한다. MP3 포맷이 이런 방식으로 동작한다.
* JPG 포맷도 압축 포맷의 일종인데 같은 방식으로 동작한다.
* 지진이 발생하는 것을 예측한다.
* DNA를 분석하는 데도 사용한다.
* (Shazam) 지금 나오는 음악이 어떤 음악인지 알아 맞추는 앱을 만들 때도 사용한다.

### 11.4. 병렬 알고리즘

알고리즘을 더 빨리 동작시키고 싶다면? 여러 개의 코어에서 동시에 돌아가도록 병렬 실행을 하면 된다.

정렬 알고리즘은 최고 O(nlog(n)) 실행 속도를 가진다. O(n) 시간에 정렬을 할 수 없다. 하지만 병렬화된 퀵 정렬 알고리즘을 사용하면 O(n) 시간에 배열을 정렬할 수 있다.

병렬 알고리즘(parallel algorithm)은 설계하기가 어렵다. 올바르게 동작하는지, 어느 정도의 속도 향상을 얻을 수 있는지 정확하게 파악하기도 어렵다. 또한, 속도 향상이 선형적이지 않다. 그러므로 한 개의 코어가 아니라 두 개의 코어에서 알고리즘을 돌린다고 하더라도 두 배로 빨라지지 않는다. 그 이유는...

* 병렬화를 관리하는 데 들어가는 부담 - 1000개의 항목을 가진 배열을 정렬할 때, 어떻게 두 개의 코어가 처리하도록 나눌까? 나누고 합치는 데도 시간이 걸린다.
* 로드 밸런싱 - 10개의 작업을 두 개의 코어에 5개씩 나누어 주었다. 그런데 A 코어는 쉬운 일만 받아서 10초 내에 끝내고, B 코어는 어려운 일만 받아서 1분에 끝냈다. B 코어가 일할 때 A 코어는 놀 수밖에 없다. 일을 균등하게 배분하려면 어떻게 해야 할까?

성능과 확장성에 관심이 있다면 병렬 알고리즘이 좋다.

### 11.5. 맵리듀스

점점 인기가 높아지고 있는 특별한 병렬 알고리즘이 있다. 바로 분산 알고리즘(distributed algorithm)이다. 만약 코어가 두 개나 네 개 정도 필요하다면 노트북에서 병렬 알고리즘을 돌려도 된다. 하지만 만약 수백 개의 코어가 필요하다면? 그럼 여러 대의 컴퓨터에서 돌아가는 분산 알고리즘을 만들어야 한다. 맵리듀스 알고리즘(MapReduce algorithm)은 인기 있는 분산 알고리즘이다. 아파치 하둡과 같은 오픈 소스 툴을 통해 맵리듀스 알고리즘을 사용할 수 있다. 맵리듀스는 맵 함수(map function)와 리듀스 함수(reduce function)라는 두 개의 간단한 개념을 이요하여 만들어졌다.

**맵 함수**

맵 함수는 배열을 입력으로 받아서 모든 원소에 같은 함수를 적용한다.

```python
arr1 = [1, 2, 3, 4, 5, ....., 1000000000000000]
map(lambda x: 2 * x, arr1)
>>>
[2, 4, 6, 8 ,10, ......, 2000000000000000]
```

만약 100개의 컴퓨터가 있다면 맵 함수는 이 작업을 모든 컴퓨터에 골고루 배분한다.

**리듀스 함수**

리스트 전체의 원소를 하나의 원소로 축소(reduce)하는 것이다. 맵 함수에서는 하나의 배열에서 같은 크기의 다른 배열을 얻었다. 리듀스에서는 이 배열을 하나의 원소로 변형한다.

```python
arr1 = [1, 2, 3, 4, 5, ....., 1000000000000000]
reduce(lambda x,y: x+y, arr1)
>>>
(총합)
```

맵리듀스는 이 두 가지의 간단한 개념을 이용해서 여러 대의 컴퓨터에 분산되어 있는 데이터에 대한 질의를 수행한다. 

### 11.6. 블룸 필터와 하이퍼로그로그

레딧 웹 서비스를 운영하고 있다고 하자. 어떤 사람이 링크를 올리고 여러분은 이 링크가 예전에 올라왔던 것인지 확인하고 싶다. 아니면 구글 검색 서비스를 운영하고 있어서 웹 페이지들을 크롤링한다면 이전에 찾아보지 않았던 웹 페이지만 크롤링하기를 원할 수도 있다. 또한, 비틀리와 같이 URL을 단축해 주는 서비스도 마찬가지이다. 사용자가 악성 코드가 있는 웹 사이트로 가지 않도록 악성 웹 사이트 주소를 저장해 놓고, 새로운 URL 요청이 왔을 때 이 사이트가 악성 사이트 목록에 있는 것인지 확인한다.

위의 모든 예의 문제점은 확인해야 할 집합이 너무 크다는 것이다.

새로운 항목이 들어오면 이 항목이 집합에 이미 있는지, 없는지를 확인하고 싶다. 해시 테이블을 사용하면 이 작업을 빨리 할 수 있다. (ex. test_dict['adit.com'] = 'yes'). 해시 테이블에 대한 평균 탐색 시간은 O(1)이므로 상수 시간으로 확인할 수 있다.

문제는 해시 테이블이 너무 크다는 점이다. 구글은 수조 개의 웹 페이스를 인덱싱한다. 이렇게 인덱싱한 모든 주소를 해시 테이블에 가지고 있다면 어마어마한 저장 공간이 필요하다. 레딧과 비틀리도 마찬가지로 저장 공간 문제를 가지고 있다.

**블룸 필터**

블룸 필터(bloom filter)가 이 문제를 해결할 수 있다. 블룸 필터는 확률론적인 자료구조이다. 거의 대부분 옳은 답을 주긴 하지만 항상 그렇지는 않는다. (해시 테이블은 항상 정확한 답을 준다).

* 블룸 필터는 틀린 답을 맞다고 할 수도 있다. 예를 들어, 구글 서비스의 경우, "이 사이트는 이미 크롤링했다." 라는 답을 얻었더라도 사실 크롤링하지 않았던 사이트일 수도 있다.
* 하지만 맞는 답을 틀리다고 하지는 않는다. 즉, "이 사이트는 크롤링하지 않았다."라는 답이 나왔다면 진짜 크롤링한 적이 없다는 뜻이다.

블룸 필터는 저장 공간을 아주 적게 차지하기 때문에 획기적이다. 위 예에서 보았던 것처럼 항상 정답이 필요한 상황이 아니라면 블룸 필터가 아주 유용하다. 비틀리 서비스라면 "이 사이트는 악성 코드가 있을 수도 있습니다. 그러니까 주의하세요."라고 말할 수도 있다.

**하이퍼로그로그**

블룸 필터와 비슷한 알고리즘으로 하이퍼로그로그(HyperLogLog)가 있다. 만약 구글에서 사용자의 검색내역 중 특정한 검색에 대한 횟수를 세고 싶다거나, 아마존에서 오늘 사용자가 특정 상품을 몇 번 봤는지 알고 싶다고 하자. 이 문제를 풀기 위해서는 엄청나게 많은 저장 공간이 필요하다. 구글이라면 모든 검색에 대해 로그를 남겨야 한다.

하이퍼로그로그는 집합에 있는 똑같은 원소의 개수를 대략적으로 셀 수 있다. 정확한 값을 주지 않지만 정확한 값을 주기 위해 필요한 메모리의 아주 일부분만 사용해서 꽤 근사한 값을 줄 수 있다.

만약 근사값이라도 괜찮은 경우라면 이런 확률론적 방법을 생각해봐라.

### 11.7. SHA 알고리즘

해시 테이블은 배열에 특정한 키와 관련된 값을 저장할 때 사용한다. 해시 함수를 사용하면 그 값을 어디에 넣을지 알 수 있다. 그러면 그 위치에 값을 저장하면 된다. 해시 테이블을 사용하면 상수 시간에 탐색을 할 수 있다. 이 경우에는 해시 함수가 좋은 분포 특성을 가져야 한다. 그래서 해시 함수에 문자열을 넣으면 그 문자열을 저장할 위치를 알려준다.

SHA(보안 해시 알고리즘; Secure Hash Algorithm) 함수도 해시 함수의 일종이다. SHA 함수는 문자열을 받아 그 문자열에 대한 해시값을 반환한다. (ex. "hello" => "2cf24db...")

SHA는 해시 함수이지만 출력된 해시값은 숫자가 아니라 짧은 문자열이다. 해시 테이블용 해시 함수는 배열 인덱스, 즉 숫자를 출력하지만 SHA는 문자열을 받아서 문자열을 출력한다.

**파일 비교**

두 파일이 같은지 알아보는 데도 SHA를 사용할 수 있다. 특히 파일 크기가 클 때 유용하다. 예를 들어, 4GB 크기의 파일이 있는데 친구가 가지고 있는 파일과 같은 파일인지 확인하고 싶을 때, 굳이 파일 전체를 이메일에 첨부해서 친구에게 보낼 필요가 없다. 대신에 두 파일에 대한 SHA 해시값을 비교하면 된다.

**패스워드 확인**

SHA는 원래 문자열을 밝히지 않고 두 문자열을 비교할 때도 유용하다. 구글은 패스워드 자체를 저장해 놓지 않는다. 패스워드에 대한 SHA 해시값만 저장해둔다. 여러분이 패스워드를 입력하면 구글에서는 그 문자열에 대한 해시값을 계산해서 데이터베이스에 저장해 놓았던 패스워드의 해시값과 비교한다. SHA는 단방향 해시이다. 문자열에서 해시값을 얻을 수는 있지만, 해시값에서 문자열을 알 수는 없다.

SHA 알고리즘에는 SHA-0, SHA-1, SHA-2, SHA-3과 같은 여러가지 버전이 있다. SHA-0과 SHA-1 알고리즘에는 취약점이 있으니 패스워드 해시에 SHA 알고리즘을 사용한다면 SHA-2나 SHA-3을 사용하자. 현재 패스워드 해시 함수의 표준은 bcrypt이다.

### 11.8. 지역 민감 해싱

SHA는 또 다른 중요한 특성을 가진다. 지역 민감적이지 않다는 점이다. 지역 민감적이란 말은 두 개의 입력 문자열이 비슷하면 출력되는 해시값도 비슷해진다는 뜻이다. 이는 해커가 패스워드를 추측할 때 패스워드와 어느 정도 비슷해졌는지 알 수 없기 떄문에 좋은 특성이다.

하지만 어떨 때는 반대로 지역 민감 해시(locality-sensitive hash) 함수가 필요할 수도 있다. 이때는 Simhash를 사용한다. Simhash를 쓰면 문자열이 조금 바뀌었을 때 해쉬값도 조금만 바뀐다. 이렇게 되면 두 개의 문자열이 어느 정도 비슷한지를 알 수 있는데, 다음과 같은 경우에 아주 유용하다.

* 구글은 Simhash를 사용해서 크롤링할 웹 페이지가 중복되었는지 판단한다.
* 선생님은 Simhash를 사용해서 학생이 작문 숙제를 인터넷에서 베꼈는지 알 수 있다.
* Scribd 서비스는 사용자가 문서나 책을 업로드해서 다른 사람들과 공유하도록 한다. 하지만 저작권이 있는 내용은 업로드하지 못하도록 한다. 이 서비스는 Simhash를 사용하여 사용자가 업로드한 내용이 해리포터 책과 같은지 살펴보고, 만약 같은 내용이라면 자동으로 업로드를 거절하도록 한다.

### 11.9. 디피-헬만 키 교환

메시지를 받은 사람만 읽을 수 있도록 하려면 메시지를 어떻게 암호화해야 할까?

암호 해독 규칙을 사용한다. 그런데 이는 두 사람이 같은 암호 해독 규칙을 가져야 한다. 매일 암호 해독 규칙을 바꾼다면 매일 직접 만나야 한다. 설사 이렇게 매일 바꾼다 하더라도 간단한 경우에는 암호를 깰 수도 있다. 2차 세계 대전 당시 독일은 아주 복잡한 암호 해독 규칙을 만들었지만 결국 깨졌다.

디피-헬만 알고리즘을 사용하면 다음과 같은 두 가지 문제를 해결할 수 있다.

* 양쪽 모두 암호 해독 규칙을 가질 필요가 없어야 한다. 그러면 만나서 암호 해독 규칙을 공유할 필요도 없다.
* 암호화된 메시지는 해독하기 어려워야 한다.

디피-헬만 알고리즘은 두 개의 키를 가진다. 공개 키(public key)와 개인 키(private key)이다. 누군가가 당신에게 메시지를 보내고 싶을 때는 모두가 알수 있는 공개 키를 써서 암호화를 한다. 암호화된 메시지를 해독할 때는 나 혼자만 아는 개인 키를 쓴다.

### 11.10. 선형 프로그래밍

선형 프로그래밍은 주어진 제한 조건하에서 무언가를 최대화할 때 사용한다.

그래프 알고리즘을 선형 프로그래밍 대신 사용할 수도 있다. 선형 프로그래밍은 훨씬 더 방대한 주제이고, 그래프 문제는 선형 프로그래밍의 특수한 경우에 지나지 않는다.

선형 프로그래밍에서는 심플렉스 알고리즘(Simplex algorithm)을 쓴다.

