# Grokking Algorithms

Aditya Y. Bhargava <br>
한국어판 - Hello Coding 알고리즘 <br>

## Contents

* [1. 알고리즘의 소개](#1.)
* [2. 선택 정렬 (Selection Sort)](#2.)
* [3. 재귀 (Recursion)](#3.)
* [4. 퀵 정렬 (Quicksort)](#4.)
* [5. 해시 테이블 (Hash Tables)](#5.)
* [6. 너비 우선 탐색 (Breadth-first Search)](#6.)
* [7. 다익스트라 알고리즘 (Dijkstra’s algorithm)](#7.)




<br>


<div id='1.'/>

## 1. 알고리즘의 소개

### 1.2. 이진 탐색

이진 탐색은 단계마다 절반의 숫자를 없앨 수 있다. 단, 정렬된 리스트를 입력으로 받는다. 만약 n개의 원소를 가진 리스트에서 이진 탐색을 사용하면 최대 log(n)번(logarithmic time) 만에 답을 찾을 수 있다. 이 책에서 log는 항상 log_2와 같다. 단순 탐색은 최대 n번(linear time)이 필요할 수도 있다. 로그를 거듭제곱의 반대인 점을 생각하면 그 크기를 짐작할 수 있다. 

```python
def bineary_search(list, item):
    low = 0
	high = len(list) - 1
	
	while low <= high:
	    mid = (low + high) / 2
		guess = list[mid]
		if guess == item:
		    return mid
		if guess > item:
		    high = mid - 1
		else:
		    low = mid + 1
	return None
	
my_list = [1, 3, 5, 7, 9]
print(bineary_search(my_list, 3)) 	# => 1
print(bineary_search(my_list, -1))	# => None
```

| 단순 탐색          | 이진 탐색          |
| :---------------:| :--------------:|
| centered column  | centered column |
| linear time      | logarithmic time|



### 1.3. 빅오 표기법

빅오 표기법으로 알고리즘이 얼마나 빠른지 설명해준다. 그런데 한 가지 주의 사항이 있다.

|                  | 단순 탐색          | 이진 탐색          |
| :---------------:| :---------------:| :--------------:|
| centered column  | centered column | centered column |
| 100개      		| 100밀리 초 | 7밀리 초 |
| 10,000개      		| 10초 | 14밀리 초 |
| 1000,000,000개      | 11일 | 32밀리 초 |

단순히 100개인 데이터만 생각해서 단순 탐색과 이진 탐색의 실행 시간이 별 차이가 없다고 판단할 수 있다. 아무래도 버그가 생길 가능성이 적은 단순 탐색을 최종으로 선택할 수 있는데 이는 큰 오산이다. 항상 데이터가 100개면 상관없으나 데이터가 증가하는 경우에 결과가 확연히 달라진다.

따라서, 알고리즘의 실행 시간이 얼마나 걸리는지만 고려할 것이 아니라, 리스트 크기가 증가할 때 어떻게 증가하는지를 파악할 필요가 있다. 이 점이 빅오 표기법을 사용하는 이유이다.

빅오 표기법은 속도를 시간 단위로 세지 않는다. 빅오 표기법은 **연산 횟수를 비교**하기 위한 것이다. 빅오 표기법을 사용하면 수행해야 할 일이 많아질 때 알고리즘에 걸리는 시간이 어떤 식으로 증가하는지를 알 수 있다.

`O(n)` 에서 O는 빅(Big)오할 때 O이고, n은 연산 횟수를 뜻한다. `O(n)`의 의미는 n개의 데이터를 처리하기 위해 n번의 연산이 필요하다와 같다. `O(log(n))`은 n개의 데이터를 처리하기 위해 log(n)번의 연산이 필요하다는 의미와 같다. 즉, 빅오 표기법에는 실질적인 실행 시간의 정보가 포함되어 있지 않다. 하지만, 연산 횟수를 통해 실행 시간을 가늠할 수 있다. 예를 들어, 1초에 100번의 연산을 할 수 있다고 가정하면 실행 시간을 구할 수 있다.

알고리즘은 동일해도 주어진 문제에 따라 연산 횟수가 달라질 수 있다. 최선의 경우(단순 검색에서 첫 번째 인덱스에서 찾고자하는 값이 있는 경우), 최악의 경우(단순 검색에서 마지막 인덱스에서 찾고자하는 값이 있는 경우)로 구분될 수 있다. 빅오 표기법은 (보통) **최악의 경우**에 대한 것이다. 즉, 단순 검색은 절대로 O(n) 시간보다 느려지지 않는다는 보장을 할 수 있다.

최악의 경우에 대한 실행 시간 이외에도 **평균 실행 시간**을 설펴보는 것도 중요하다. 최악의 경우와 평균에 대한 비교는 4장 퀵 정렬에서 살펴보자.


#### 많이 사용하는 빅오 실행 시간의 예

* O(log(n)), 로그 시간:	예) 이진 탐색
* O(n), 선형 시간:		예) 단순 탐색
* O(nlog(n)):		예) 퀵 정렬과 같은 빠른 정렬 알고리즘
* O(n^2):		예) 선택 정렬과 같이 느린 정렬 알고리즘
* O(n!):		예) 외판원 문제와 같이 정말 느린 알고리즘

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/1_1.PNG" width="60%" height="60%"></p>

#### 빅오 표기법 정리

* 알고리즘의 속도는 시간이 아니라 연산 횟수가 어떻게 증가하는지로 측정한다.
* 이렇게 하면 입력 데이터의 크기가 늘어날 때 알고리즘의 실행 속도가 얼마나 증가하는지 알 수 있다.
* 알고리즘의 실행 시간은 빅오 표기법으로 나타낸다.
* O(log(n))은 O(n)보다 빠르고, 찾으려는 리스트의 원소의 개수가 증가하면 상대적으로 더 빨라진다.

#### (참고) 외판원 문제 (traveling salesperson problem)

모든 도시를 방문해서 물건을 팔아야되는 외판원이 있다. 주어진 도시에서 이동 거리가 가장 짧은 경로는 어떻게 구할 수 있을까? 이 문제를 푸는 한 가지 방법은 도시를 방문하는 모든 경로를 살펴보는 것이다. 그 다음 전체 거리를 더해서 가장 짧은 경로를 택하면 된다. 문제는 연산의 수가 무시무시하게 증가한다.

| 도시          | 연산          |
| :---------------:| :--------------:|
| centered column  | centered column |
| 6      | 720 |
| 7      | 5040 |
| 8     | 40320 |
| ...     | ... |
| 15    | 1307674368000 |
| ...     | ... |
| 30    | 265252859812191058636308480000000 |

만약 n개의 도시가 있다면 n!번의 연산이 필요하다. 즉, O(n!)이다. 아주 안 좋은 방법인데, 다른 알고리즘이 없다. 이 문제는 컴퓨터 과학에서 아직 풀지 못한 문제 중 하나이다. 우리가 할 수 있는 방법은 대략적인 답을 얻는 것밖에 없다(10장 참고. 이진 탐색 트리 참고).

### 1장 정리

* 이진 탐색은 단순 탐색보다 아주 빠르다.
* O(log(n))은 O(n)보다 빠르다. 리스트의 원소의 개수가 증가하면 상대적으로 더 빨라진다.
* 알고리즘의 속도는 시간으로 측정하지 않는다.
* 알고리즘의 시간은 어떻게 증가하는가로 측정한다.
* 알고리즘의 시간은 빅오 표기법으로 나타낸다. 

### 1장 연습문제

알파벳 A로 시작하는 사람들의 전화번호를 탐색하는 실행 시간의 빅오 표기법은? O(n/26)이 아니라 O(n)이 된다. 4장 빅오 표기법 상수 참조.




<div id='2.'/>

## 2. 선택 정렬 (Selection Sort)

### 2.2. 배열과 연결 리스트

여러 개의 항목을 목록으로 메모리에 저장하고 싶다고 하자. 메모리 공간의 특징은 할당 가능한 영역이 듬성듬성 구멍이 뚫린 것처럼 흩어져 있다는 점이다. 배열은 항상 **연이은 공간**이 필요하므로 해당 리스트 크기만큼 비어있는 자리를 찾아야 한다. 찾는 시간을 줄이기 위해 큰 영역을 미리 할당해놓는 방법이 있는데, 만약 추가할 일이 생기지 않는다면 메모리를 쓸데없이 낭비한 셈이 된다. 

연결 리스트(Linked List)를 사용하면 원소를 메모리의 **어느 곳에나** 둘 수 있다. 연결 리스트를 사용하면 원소를 추가하는 일이 쉽다. 그냥 메모리의 아무 곳에나 원소를 넣고, 그 주소를 바로 앞의 원소에 저장해 놓으면 된다. 즉, 연결 리스트를 사용하면 원소를 옮길 일이 없다. 

연결 리스트의 문제는.. 리스트에서 마지막 원소를 보고 싶다면 바로 읽을 수 없다. 왜냐하면 주소를 바로 알 수 없기 때문이다(연결 리스트에서는 원소가 이웃하고 있지 않아서 몇 번째 원소가 어디에 있는지 바로 계산할 수 없다). 만약 모든 원소의 값을 한 번에 읽어야 한다면 연결 리스트가 좋지만, 특정한 원소만 알고 싶다면 연결 리스트는 최악이다.

배열(array)은 모든 원소의 주소를 다 알고 있다. 따라서 배열 안의 어떤 원소든 바로 찾을 수 있기 때문에 임의의 원소의 값을 읽는데 최고다.

|                  | 배열          | 리스트          |
| :---------------:| :---------------:| :--------------:|
| centered column  | centered column | centered column |
| 읽기      		| O(1) | O(n) |
| 쓰기      		| O(n) | O(1) |

왜 배열에 원소를 삽입하는데 O(n) 시간이 들까? 빅오 표기법의 기준은 최악의 경우다. 배열의 가장 앞부분에 원소를 삽입했을 때를 생각해보자. 리스트는 왜 O(1)일까? 가운데까지 찾아가는데 걸리는 시간이 O(n)이 아닌가? 여기서는 이미 찾아갔다고 가정한다. 순수하게 쓰기(삽입) 연산만 보면 O(1)이 맞다. 삭제도 똑같다. (cf. [stackoverflow](https://stackoverflow.com/questions/840648/why-is-inserting-in-the-middle-of-a-linked-list-o1))

#### 리스트의 가운데에 삽입하기

원소를 배열이나 리스트의 중앙에 삽입한다면 배열과 리스트 중 어느 것이 나을까? 리스트는 이전 원소가 무엇을 가리키느지 바꾸기만 하면 되므로 리스트에 삽입하는 것이 훨씬 쉽다. 하지만 배열에서는 다음에 오는 모든 원소의 위치를 바꾸어야 한다. 만약 공간이 부족하면 모든 원소를 새로운 장소로 복사해야 한다. 

#### 삭제하기

삭제의 경우에도 이전 원소가 가리키는 위치만 바꾸면 되기에 리스트가 더 낫다. 배열에서는 원소 하나만 삭제하고 싶을 때도 모든 것을 다 옮겨야 한다. 삽입할 때와 달리 삭제할 때는 실패하는 경우가 없다(삽입할 때는 가끔 메모리에 남아 있는 공간이 없어서 실패할 수도 있다). 하지만 원소를 삭제하는 것은 언제나 할 수 있다. 

|                  | 배열          | 리스트          |
| :---------------:| :---------------:| :--------------:|
| centered column  | centered column | centered column |
| 읽기      		| O(1) | O(n) |
| 쓰기      		| O(n) | O(1) |
| 삭제      		| O(n) | O(1) |

경우에 따라 다르지만, 임의의 원소에 접근하는 것이 가능하기 때문에 배열이 리스트보다 더 많이 쓰인다. 자료에 접근하는 방식에는 임의 접근(random access)과 순차 접근(sequential access)이라는 두 가지 방식이 있다. 배열에서는 임의 접근이 가능하기에 배열의 읽기 속도가 빠르다.

### 2.3. 선택 정렬 (Selection Sort)

나의 뮤직 플레이어 목록에서 가장 많이 들은 노래부터 가장 적게 들은 노래 순서로 정렬하여 가장 좋아하는 노래의 순위를 알고 싶다면 어떻게 해야 할까?

한 가지 (심플한) 방법은 리스트의 모든 항목을 살펴보고 가장 많이 연주된 가수를 찾아 새로운 리스트에 기록하는 것이다. 이런식으로 반복하면 정렬된 목록을 얻을 수 있다.

매번 실행할 때마다 n, n-1, n-2, ... 2, 1개의 항목을 점검해야 한다. 평균적으로 1/2 x n개의 항목을 점검해야 한다. 이러한 실행을 n번 해야 한다. 그렇다면 빅오는 O(n x 1/2 x n)이지만 상수항은 무시하여 O(n x n)이 된다.

선택 정렬은 깔끔한 알고리즘이지만 빠르지 않다. 퀵 정렬은 O(n x log(n)) 시간밖에 걸리지 않는 더 빠른 알고리즘이다.

```python
def findSmallest(arr):
    smallest = arr[0]
	smallest_index = 0
	for i in range(1, len(arr)):
	    if arr[i] < smallest:
		    smallest = arr[i]
			smallest_index = i
	return smallest_index
	
def selectionSort(arr):
    newArr = []
	for i in range(len(arr)):
	    smallest = findSmallest(arr)
		newArr.append(arr.pop(smallest))
	return newArr
	
print(selectionSort([5, 3, 6, 2, 10]))
```

### 2.4. 2장 정리

* 배열을 쓰면 모든 항목은 이웃하는 위치에 저장된다.
* 리스트를 쓰면 모든 항목이 흩어지지만, 각 항목은 다음 항목의 주소를 저장하고 있다.
* 배열은 읽기가 빠르다.
* 연결 리스트는 삽입과 삭제가 빠르다.
* 배열의 모든 원소는 같은 자료형이어야 한다.

### 2장 연습문제

큐를 구현하는 데 배열보다 연결 리스트를 사용하는 것이 좋다. 큐는 임의의 위치를 읽거나 검색할 필요가 없으므로 배열보다 연결 리스트가 훨씬 더 좋다.

페이스북이 사용자 이름 목록을 가지고 있다고 하자. 특정 사용자 이름을 검색하기 위해 이진 탐색을 사용한다고 가정하자. 이진 탐색을 하기 위해서는 임의 접근이 가능해야 한다. 이 경우에는 연결리스트보다 배열이 좋다. 이진 탐색을 하기 떄문에 리스트는 정렬되어 있어야 함을 잊지 말자.

페이스북에는 새로운 사용자 등록도 자주 발생한다. 이 경우에서는 배열이 좋지 않다. 

페이스북은 실제로 사용자 정보를 저장하기 위해 배열이나 연결 리스트를 사용하지 않는다. 다음과 같은 복합 자료구조를 생각해보자. 알파벳 하나하나를 지칭하는 26개의 칸이 있는 배열이 있다. 각각의 칸은 각자 다른 연결 리스트를 가리키고 있다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/2_1.PNG" width="60%" height="60%"></p>

이러한 복합 자료구조는 검색의 경우에는 배열보다 느리고 연결 리스트보다는 빠르다. 삽입의 경우에는 배열보다는 빠르고 연결 리스트와는 같은 시간이 걸린다. 즉, 배열보다는 검색 시간 측면에서만 느리고 연결 리스트보다는 모든 면에서 좋거나 최소한 같다.

이 책의 뒷부분에서는 해시 테이블이라고 하는 또 다른 복합 자료구조를 이야기할 것이다. 이 자료구조는 간단한 자료구조로부터 어떻게 복잡한 형태의 자료구조를 만들어 나가는지에 대한 아이디어를 줄 수 있다.

페이스북은 실제로 여러 가지 다른 데이터베이스를 사용하고, 각각의 데이터베이스 내부에서는 해시 테이블이나 B-트리와 같은 다양한 자료구조를 쓸 것이다. 배열과 연결 리스트는 이러한 복잡한 자료구조를 만드는 기초가 된다.



<div id='3.'/>

## 3. 재귀 (Recursion)

재귀(recursion)는 여러 가지 알고리즘에 쓰이는 코딩 테크닉으로 이 책의 나머지 장을 이해하기 위한 기초가 된다. 하나의 문제를 기본 단계와 재귀 단계로 나누는 방법을 배운다. 분할 정복(divide-and-conquer) 전략은 이런 간단한 개념을 사용하여 어려운 문제를 푸는 방법이다.

### 3.2. 재귀

큰 상자 속에 작은 상자들이 있고, 그 작은 상들 안에는 더 작은 상자들이 있다. 열쇠는 그 상자 속 어딘가에 있다. 열쇠를 찾기 위한 알고리즘은 무엇일까?

```python
# 방법 1 - while 반복문
def look_for_key(main_box):
    pile = main_box.make_a_pile_to_look_through()
	while pile is not empty:
	    box = pile.grab_a_box():
		for item in box:
		    if item.is_a_box():
			    pile.append(item)
			elif item.is_a_key():
			    print("열쇠를 찾았어요!")

# 방법 2 - 재귀
def look_for_key(box):
    for item in box:
	    if item.is_a_box():
		    look_for_key(item)
		elif item.is_a_key():
		    print("열쇠를 찾았어요!")
```

두 가지 방법 모두 같은 일을 하지만, 두 번째 방법이 더 명확하다. 재귀는 풀이를 더 명확하게 만들어 준다. 재귀를 쓴다고 성능이 더 나아지지는 않는다. 사실 반복문이 더 성능이 좋은 경우가 많다. 

"프로그램에 반복문을 사용하면 프로그램의 성능을 향상시킬 수 있지만, 재귀를 사용하면 프로그래머의 능력을 향상시킬 수 있다." - 스택 오버플로우: 레이 캐드웰

상황에 따라 적절한 방법을 골라 사용하자. 대부분의 중요한 알고리즘들이 재귀를 사용하므로 개념을 잘 이해하는 것이 중요하다.

### 3.3. 기본 단계와 재귀 단계

재귀 함수는 자기 자신을 호출하기 때문에 실수로 무한 반복을 하는 함수를 만들기 쉽다. 재귀 함수를 만들 때는 언제 재귀를 멈출지 알려줘야 한다. 그래서 모든 재귀 함수는 기본 단계(base case)와 재귀 단계(recursive case)라는 두 부분으로 나누어져 있다. 

재귀 단계는 함수가 자기 자신을 호출하는 부분이다. 기본 단계는 함수가 자기 자신을 다시 호출하지 않는 경우, 즉 무한 반복으로 빠져들지 않게 하는 부분이다. 

```python
def countdown(i):
    print(i)
	if i <= 1:	# 기본 단계
	    return
	else:	# 재귀 단계
	    countdown(i-1)
```

### 3.4. 스택

호출 스택은 프로그램에서 중요한 개념이지만 재귀를 사용할 때 더욱 중요하다. 컴퓨터는 호출 스택이라고 불리는 스택(stack)을 사용한다. 여러 개의 함수를 호출하면서 함수에 사용되는 변수를 저장하는 스택을 호출 스택(call stack)이라고 한다. 

스택을 사용하면 확인해야 할 상자 더미를 여러분이 일일이 추적하지 않아도 되므로 편리하다. 그렇지만 편리한만큼 대가를 치러야 한다. 모든 정보를 저장해야 하므로 메모리를 많이 소비한다. 함수 호출을 할 때마다 메모리를 사용하게 된다.

많은 메모리 소비를 방지하기 위한 방법으로
* 재귀 대신 반복문을 써서 코드를 다시 작성한다.
* 꼬리 재귀(tail recursion)라는 방법을 사용한다. 이는 고급 재귀 방법으로 모든 프로그래밍 언어에서 지원하는 것은 아니다.


### 3장 정리

* 재귀는 함수가 스스로를 호출하는 것이다.
* 모든 재귀 함수는 기본 단계와 재귀 단계라는 두 부분으로 나누어져 있다.
* 스택에는 푸시(push)와 팝(pop)이라는 두 가지 연산이 있다.
* 모든 함수 호출은 호출 스택을 사용한다.
* 호출 스택은 너무 커져서 메모리를 엄청나게 소비할 수도 있다.

### 3장 연습문제

재귀 함수가 무한 실행하면 스택에는 어떤 일이 발생할까? 스택에 할당할 수 있는 공간이 제한되어 있기 때문에 이 공간을 모두 사용하면 스택 오버플로우 오류가 발생하며 종료된다. 



<div id='4.'/>

## 4. 퀵 정렬 (Quicksort)

분할 정복(divide-and-conquer) 전략에 대해 알아보자. 가끔씩 여러분이 공부한 어떤 알고리즘으로도 풀 수 없는 문제를 만날 수 있다. 이런 문제를 풀기 위해서는 다양한 기술을 통해 해결 방법을 알아내야 한다. 분할 정복 전략은 여러분이 배우게 될 첫 번째 범용 기술(general technique)이다. 분할 정복 전략은 문제에 바로 적용할 수 있는 단순한 알고리즘이 아니고 문제를 풀기 위한 방법론에 가깝다.

퀵 정렬은 실무에 자주 사용되는 명쾌한 정렬 알고리즘 중 하나이다. 퀵 정렬은 분할 정복 전략을 사용한다.

### 4.1. 분할 정복

문제 해결 방법 중에서 가장 유명한 재귀적 기술인 분할 정복(divide-and-conquer) 전략에 대해 살펴보자.

한 가지 유형의 문제만 풀 수 있다면 그 알고리즘은 유용하다고 할 수 없다. 분할 정복 전략은 문제를 푸는 새로운 사고 방식을 제시한다. 여러분의 문제 해결 도구 상자에 새로운 도구를 넣게 되는거다. 새로운 문제에 부딪혀도 당황하지 말고 분할 정복 전략으로 문제를 풀 수 있는지 고민하자.

**토지 분할 문제**
여러분이 농부이고 1680m x 640m 크기의 농장을 가지고 있다하자. 이 농장을 똑같이 생긴 정사각형 토지들로 나누고 싶다. 어떻게 똑같은 크기의 가장 큰 정사각형으로 나눌 수 있을까? 재귀적 알고리즘인 분할 정복 전략을 활용하자. 다음과 같은 두 단계를 가진다.

1. 기본 단계를 해결한다. 이 부분은 가능한 한 간단한 문제이어야만 한다. (기본 단계)
2. 문제가 기본 단계가 될 때까지 나누거나 작게 만든다. (재귀 단계)

재귀 단계에서 분할 정복 전략이 활약할 타이밍이다. 분할 정복 전략에 따르면 재귀 함수 호출을 할 때마다 문제를 작게 나누어야 한다. 여기에서는 문제를 어떻게 나눌까? 조건에 맞는 가장 큰 상자를 알아내는 것부터 시작한다. 

한 변의 길이가 640m인 두 개의 정사각형 토지를 만들 수 있지만, 아직 나누지 못한 토지가 남게 된다. 이제 이 문제를 푸는 핵심 아이디어가 등장한다. 남은 토지를 나눌 때도 똑같은 방법을 사용하면 된다. 즉, 원래는 1680m x 640m 크기를 가진 농장의 토지를 나누는 문제로 시작했지만, 이제 더 작은 640m x 400m 크기의 농장의 토지를 나누는 새로운 문제를 푸는 것이다.

문제가 1680m x 640m -> 640m x 400m -> 400m x 240m -> 240m x 160m -> 160m x 80m 으로 바뀐다. 원래의 농장을 나눌 수 있는 가장 큰 정사각형의 크기는 80m x 80m이 된다.

**숫자들의 합 문제**

주어진 배열에 있는 숫자들을 모두 더하여 합계를 구하는 문제를 반복문을 사용하지 않고 재귀 함수를 사용해서 합계를 구해보자.

* 기본 단계를 찾는다. 가장 간단한 배열은 무엇일까?
* 재귀 함수 호출을 할 때마다 호출 대상이 되는 배열의 크기가 점점 감소해야 한다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/4_1.PNG" width="60%" height="60%"></p>

재귀에서는 상태를 추적한다는 점을 명심하자. 

배열을 포함하는 재귀 함수를 만들 떄, 기본 단계는 보통 빈 배열이나 원소가 하나뿐인 배열이 된다. 만약 문제를 풀다 막히면 이 방법을 사용하자.


**(TIP)함수형 프로그래밍**

반복문으로 풀 수 있는데 왜 재귀적으로 해야 하나? 함수형 프로그래밍을 살짝 맛본 것이다. 하스켈과 같은 함수형 프로그래밍 언어에는 반복문이란 것이 없다. 그러니 무조건 이렇게 재귀 함수를 사용해야 한다. 예를 들어, 하스켈 언어로 합계 함수는 다음과 같다.

```
sum [] = 0 					# 기본 단계
sum (x:xs) = x + (sum xs)	# 재귀 단계
```

### 4.2. 퀵 정렬

퀵 정렬(quicksort)은 선택 정렬보다 훨씬 빠르고 실제로도 자주 사용된다. 퀵 정렬은 분할 정복 전략을 가진다. 

기본 단계로는 정렬할 필요가 없는 배열, 즉 비어있거나 원소가 하나인 배열인 상태다. 주어진 배열을 기본 단계가 될 때까지 나눠야 한다. 퀵 정렬에서는 기준 원소(pivot)를 고르고, 모든 원소를 기준 원소보다 작은 원소와 큰 원소로 분류한다. 이것을 분할(partitioning)이라고 한다. 분할된 하위 배열(sub-array)에 대해서도 퀵 정렬을 호출한다. 이렇게 재귀적으로 호출하면 된다. 각 하위 배열들이 정렬되면 합쳐서 전체 배열을 정렬한다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/4_2.PNG" width="60%" height="60%"></p>

```python
def quicksort(array):
    if len(array) < 2:	# 기본 단계: 원소의 개수가 0이나 1이면 이미 정렬되어 있는 상태
	    return array
	else:	# 재귀 단계
	    pivot = array[0]	# 첫 번째 원소를 임의로 pivot이라 설정
		less = [i for i in array[1:] if i <= pivot]
		greater = [i for i in array[1:] if i > pivot]
		return quicksort(less) + [pivot] + quicksort(greater)
		
print(quicksort([10, 5, 2, 3]))
```

**(TIP)귀납적 증명**

방금 귀납적 증명을 살짝 맛보았다. 귀납적 증명은 알고리즘이 제대로 동작하는지 증명하는 방법 중 하나이다. 귀납적 증명에도 기본 단계(base case)와 귀납 단계(inductive case)라는 두 가지 단계가 필요하다.

기본 단계에서는 알고리즘이 가장 기본적인 경우, 즉 배열의 크기가 0이나 1인 경우에 대해 알고리즘이 동작한다는 것을 보여준다. 귀납 단계에서는 퀵 정렬이 크기가 1인 배열에 대해 동작하면 크기가 2인 배열에 대해서도 동작한다는 것을 보여준다. 3인 배열도 마찬가지로 보여준다. 이렇게 모든 크기의 배열에 대해 퀵 정렬이 동작한다고 말할 수 있다.

귀납적 증명은 흥미로운 주제일 뿐 아니라 분할 정복 전략과 함께 사용되기도 한다.


### 4.3. 빅오 표기법 복습

퀵 정렬은 여러분이 선택한 기준 원소에 따라 처리 속도가 달라진다는 특징이 있다. 먼저 일반적인 빅오 실행 시간 유형을 다시 보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/4_3.PNG" width="60%" height="80%"></p>

위의 추정치는 1초에 10회의 연산을 할 수 있는 느린 컴퓨터를 기준으로 하였다.

퀵 정렬의 실행 시간은 최악의 경우에는 O(n^2)이 될 수도 있다. 선택 정렬만큼 느린 것이다. 하지만 이것은 어디까지나 최악의 경우를 말한 것이고, 평균적인 경우에는 O(nlog(n)) 실행 시간을 가진다.

* 여기에서 최악의 경우와 일반적인 경우란 무엇을 뜻하나?
* 만약 퀵 정렬이 평균적으로 O(nlog(n))이라면 병합 정렬은 항상 O(nlog(n))인가? 그럼 왜 병합 정렬이 훨씬 빠른데 왜 쓰지 않는 것일까?

**병합 정렬과 퀵 정렬 비교**

리스트에 있는 모든 원소를 출력하는 간단한 함수가 있다고 하자.

```python

def print_items(list):
    for item in list:
	    print(item)
		
from time import sleep
def print_item2(list):
    for item in list:
	    sleep(1)
		print(item)
```

두 함수 모두 리스트를 한 번만 훑어보기 때문에 똑같이 O(n) 실행 시간을 가진다. 실제로는 print_items가 1초 동안 기다리지 않으므로 훨씬 빠르다. 

```
c x n
```

c는 알고리즘이 소비하는 어떤 특정한 시간으로 이를 상수(constant)라고 부른다. 

이진 탐색과 단숨 탐색을 예를 들어보자. 두 알고리즘 모두 다음과 같은 상수를 가진다고 하자. 

* 단순 탐색 - 10밀리초 x n
* 이진 탐색 - 1초 x log(n)

얼핏보면 단순 탐색이 훨씬 빠르게 보일수도 있다. 하지만, 40억 개의 원소를 가진 리스트를 탐색한다고 하자.

* 단순 탐색 - 10밀리초 x 40억 개 = 463초
* 이진 탐색 - 1초 x 32 = 32초

이진 탐색이 훨씬 빠르다. 즉, 상수는 전혀 문제가 되지 않는다.

가끔은 상수 때문에 차이가 발생하기도 한다. 퀵 정렬과 병합 정령이 그 예이다. 퀵 정렬이 병합 정렬보다 더 작은 상수를 가진다. 그래서 실행 시간이 O(nlog(n))으로 동일하다면 퀵 정렬이 더 빠르다. 그리고 퀵 정렬을 사용할 때 최악의 경우보다는 일반적인 경우가 훨씬 많이 발생하기 때문에 현실에서는 퀵 정렬이 더 빠르다.

**평균적인 경우와 최악의 경우 비교**

퀵 정렬의 성능은 여러분이 선택한 기준 원소에 크게 의존한다. 

만약 첫 번째 원소를 항상 기준 원소로 선택한다고 하고, 이미 정렬되어 있는 배열에 퀵 정렬을 호출해보자. 배열을 절반으로 나누지 않고 진행한다. 두 개의 하위 배열 중 하나는 항상 빈 배열이다. 그래서 호출 스택이 아주 길어진다. (배열 길이가 1024이라면 호출 스택의 전체 높이도 1024이다) 이 경우는 퀵 정렬의 최악의 경우를 나타내는 시나리오이다. 스택의 크기가 O(n)이다. (기준 원소를 임의로 첫 번째 원소로 정하지 않는 이상 이러한 시나리오는 발생하지 않지 않나?)

이번에는 정 가운데 있는 원소를 항상 기준 원소로 선택한다고 가정하자. 매번 배열을 절반으로 나누기 때문에 재귀적 호출을 많이 할 필요가 없다. 기본 단계에 더 빨리 도달하기 때문에 호출 스택이 짧아진다. (배열 길이가 1024이라면 호출 스택의 전체 높이는 10이다) 이 경우는 퀵 정렬의 최선의 경우를 나타내는 시나리오이다. 스택의 크기가 O(log(n))이다.

이제 스택의 각 단계를 살펴보자. 기준 원소로 원소 하나를 선택하면 나머지 원소들은 두 개의 하위 배열로 나누어진다. 이렇게 나누기 위해서는 1024개의 원소를 모두 기준 원소와 비교해야 한다. 이 작업에는 O(n) 실행 시간이 걸린다. 배열을 다르게 분할한다고 해도 여전히 매번 O(n)개의 원소를 모두 비교해야 하는 것은 마찬가지이다.

최악의 경우 호출 스택의 높이는 O(n)이고, 각각의 단계는 O(n) 시간이 걸리기 때문에 전체 알고리즘은 O(n) x O(n) = O(n^2) 시간이 걸린다. 최선의 경우는 O(log(n)) x O(n) = O(n x log(n)) 시간이 걸린다.

퀵 정렬에서는 일반적인 경우에도 최선의 경우와 같은 실행 속도를 가진다. 만약 기준 원소를 전체 배열에서 무작위로 선택한다면 퀵 정렬은 평균적으로 O(nlog(n)) 실행 시간을 가진다. 퀵 정렬은 가장 빠른 정렬 방법 중의 하나이고, 분할 정복의 좋은 예이다.

### 4장 정리

* 분할 정복은 문제를 더 작은 조각으로 나누어 푼다. 만약 리스트에 분할 정복을 적용한다면 기본 단계는 원소가 없는 빈 배열이거나 하나의 원소만 가진 배열이 된다.
* 퀵 정렬을 구현하려면 기준 원소를 무작위로 선택한다. 퀵 정렬의 평균적인 실행 시간은 O(log(n))이다.
* 빅오 표기법에서 가끔씩 상수가 중요해질 때도 있다. 퀵 정렬이 병합 정렬보다 빠른 이유도 상수 때문이다.
* 단순 탐색과 이진 탐색을 비교할 때는 상수항이 전혀 문제가 되지 않는다. 왜냐하면 리스트가 길어지면 O(log(n))이 O(n)보다 훨씬 빨라진다.

### 4장 연습문제

재귀 함수에 익숙해지기.

```python
# 리스트의 sum을 하는 재귀 함수
def sum(list):
    if list == []:
	    return 0
	return list[0] + sum(list[1:])

# 리스트에 포함된 원소의 숫자를 세는 재귀 함수
def count(list):
    if list == []:
	    return 0
	return 1 + count(list[1:])
	
# 리스트에서 가장 큰 수를 찾는 재귀 함수
def max(list):
    if len(list) == 2:
	    return list[0] if list[0] > list[1] else list[1]
	sub_max = max(list[1:])
	return list[0] if list[0] > sub_max else sub_max
```

이진 탐색 역시 분할 정복 전략이다. 이진 탐색의 기본 단계는 원소가 하나뿐인 배열이다. 만약 이 배열에서 원소를 찾으려면 바로 찾을 수 있다. 그렇지 않으면 배열에 없는 것이다. 이진 탐색의 재귀 단계에서는 배열을 2등분하고 하나씩 이진 탐색을 실행한다.

빅오 표기법의 중요한 포인트는 특정 연산 실행 시간이 아니라 접근하는 데이터 개수이다. 어떤 연산에 대해 신경을 쓸 것이 아니라 데이터가 증가할 때 연산은 어떻게 될 지를 신경써야 한다.


<div id='5.'/>

## 5. 해시 테이블 (Hash Tables)

### 5.1. 해시 함수의 소개

여러분이 식료품 가게에서 일을 하고 있다고 하자. 손님이 물건을 사러 오면 모든 물건의 가격이 적혀 있는 가격 장부(price book)에서 가격을 찾아봐야 한다. 만약 가격 장부가 알파벳 순서로 정렬되어 있지 않다면 단순 탐색(O(n))으로 모든 항목을 하나씩 확인해야 한다. 정렬되어 있다면 이진 탐색으로 O(log(n)) 시간이 소요된다. 밀려드는 손님을 대응하기 위해서 이진 탐색도 느리다. 해결책은 모든 장부를 외우고 있어야 한다. 해시 함수(hash function)를 통해 이를 실현할 수 있다.

|가격 장부에 있는 항목의 수| 단순 탐색 O(n)       | 이진 탐색 O(log(n))        | 해시 함수 O(1)        |
|:---------------:|:---------------:|:--------------:|:--------------:|
| centered column  | centered column | centered column | centered column |
| 100      		| 10초 | 1초 | 즉시 |
| 1000      		| 1.6분 | 1초 | 즉시 |
| 10000     		| 16.6분 | 2초 | 즉시 |

### 5.2. 해시 함수

해시 함수는 문자열(string)을 받아서 숫자를 반환하는 함수이다. 기술 용어로 말하면 문자열에 대해 숫자를 할당(mapping)한다. 해시 함수는 다음과 같은 요건을 갖추어야 한다.

* 해시 함수에는 일관성이 있어야 한다.
* 다른 단어가 들어가면 다른 숫자가 나와야 한다.

배열을 활용해서 해시 테이블(hash table)을 구성해보자 (해시 테이블이 일종의 자료구조이다). 매핑된 숫자를 배열의 인덱스라고 간주하자. 그리고 해당 인덱스 위치에 가격을 저장하자. 예를 들어, 'avocado'의 경우 해시 출력값이 3이라고 하면, 배열의 3번째 원소에 'avocado'의 가격을 저장한다. 이렇게 구성하면 탐색을 전혀 할 필요가 없어진다(해시 테이블의 장점).

* 해시 함수는 같은 이름에 대해서는 항상 같은 인덱스를 할당한다. 
* 해시 함수는 다른 문자열에 대해서는 다른 인덱스를 할당한다.
* 해시 함수는 배열의 크기를 알고 있어야 하며 유효한 인덱스만 반환해야 한다.

배열과 리스트는 직접 메모리를 할당하지만, 해시 테이블은 해시 함수를 사용해서 더 총명하게 어디에 원소를 저장할지 결정한다. 해시 테이블은 해시 맵(hash maps), 맵(maps), 딕셔너리(dictionaries), 연관 배열(associative arrays)이라는 이름으로도 알려져 있다. 

```python
book = dict()
book['apple'] = 0.67
book['milk'] = 1.49
book['avocado'] = 1.49
print(book)
>>>
{'avocado': 1.49, 'apple':0.67, 'milk':1.49}
```

해시 테이블은 키(key)와 값(value)을 가진다. book이라는 해시 테이블에서 상품 이름은 키가 되고, 가격은 값이 된다. 해시 테이블은 키에 대해 값을 할당한다.

### 5.3. 해시 테이블을 사용하는 예

**해시 테이블로 조회하기**

해시 테이블은 다음과 같은 일을 하고자 할 때 좋다.
* 어떤 것을 다른 것과 연관시키고자 할 때
* 무언가를 찾아보고자 할 때

```python
phone_book = dict()
phone_book['jenny'] = 8675309
phone_book['emergency'] = 911
print(phone_book['jenny'])
>>>
8675309
```

해시 테이블은 어떤 항목과 다른 항목 간의 관계를 쉽게 모형화한다.

해시 테이블은 더 큰 규모의 조회에서도 사용된다. 어떤 웹 사이트에 접속하든 그 주소는 모두 IP 주소로 번역되어야 한다. 이런 과정을 DNS 확인(DNS resolution) 작업이라고 한다. 해시 테이블은 이 기능을 제공하는 방법 중의 하나이다.

```python
dns_resolution = dict()
dns_resolution['google'] = '74.125.239.133'
dns_resolution['facebook'] = '173.252.120.6'

```

**중복된 항목을 방지하기**

대통령 선거를 한다고 하자. 한 사람당 하나의 투표만 할 수 있다. 투표하러 올 때마다 이미 투표했는지 확인하기 위해 아주 긴 목록(i.e. 5천만 길이)을 뒤져봐야 한다. 만약 투표한 사람의 이름을 리스트에 저장한다면 리스트 전체에 대해 산순 탐색을 반복해야 하기 떄문에 정말 느려질 것이다. 하지만, 해시 테이블에 저장하면 이름이 있는지, 없는지 순간적으로 알려준다. 따라서 중복을 확인하는 것도 해시 테이블이 훨씬 빠르다.

```python
voted = dict()
def check_voter(name):
    if voted.get(name):
	    print("돌려 보내세요!")
    else:
        voted[name] = True
        print("투표하게 하세요.")		
```

**해시 테이블을 캐시로 사용하기**

웹 사이트를 개발할 때 캐싱(caching)이 적합하다. 페이스북에 방문해서 페이스북 서버에 요청한다고 하자. 로그인을 하지 않았다면 모든 사용자에게 동일하게 로그인 페이지밖에 보이지 않는다. 페이스북은 똑같은 내용을 반복하도록 요청받는다. 이 경우 해당 내용을 그냥 외워서 사용자에게 보여주는 것이 좋다. 이것이 캐싱이다. 캐싱은 작업 속도를 올리는 일반적인 방법이다. 모든 대형 웹 사이트는 캐싱을 사용한다. 그리고 그 자료는 바로 해시 테이블에 저장된다.

페이스북은 홈페이지만 캐싱하는 것이 아니라 회사 소개, 회사 연락처, 사용 약관 등 많은 것을 캐싱하고 있다. 그래서 페이지 URL에 해당 페이지의 자료를 할당한다. 여러분이 페이스북을 방문할 때마다 서버는 먼저 해시 테이블에 저장된 페이지가 있는지 확인한다. 없으면 그제서야 서버에서 작업을 시작한다.

```python
cache = dict()
def get_page(url):
    if cache.get(url):
	    return cache[url]	# 캐싱된 자료를 전송
    else:
        data = get_data_from_server(url)
        cache[url] = data	# 캐시에 처음으로 자료를 저장
        return data
```

캐시에 URL이 없을 때만 서버가 작업을 한다. 또 자료를 반환하기 전에는 캐시에 저장한다. 다음에 누군가가 이 URL을 요청하면 서버에 작업을 시키는 대신에 캐싱한 자료를 꺼내서 보내줄 수 있다.

**해시 테이블의 장점**

* 어떤 것과 다른 것 사이의 관계를 모형화할 수 있다.
* 중복을 막을 수 있다.
* 서버에게 작업을 시키지 않고 자료를 캐싱할 수 있다.


### 5.4. 충돌

해시 테이블의 성능을 이해하기 위해 충돌을 알아보자. 이전에 해시 함수는 서로 다른 키를 배열의 서로 다른 위치에 할당한다고 하였다. 하지만, 정확하게 이렇게 할 수 있는 해시 함수를 만드는 것은 거의 불가능하다. 

예를 들어, 26 길이의 배열이 있다고 하자. 정말 간단한 해시 함수는 첫 글자에 따라 공간을 할당하는 것이다. 'Apples'를 해시 테이블에 넣으면 첫 공간이 할당된다. 문제는 'Avocados'를 해시에 넣고 싶으면 첫 번째 공간을 다시 할당해야 한다. 첫 번째 공간은 이미 'Apples'가 차지하고 있기에 이런 것을 **충돌(collision)**이라고 한다. 두 개의 키가 같은 공간에 할당되는 것이다. 덮어씌우게 될 것이다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/5_1.PNG" width="60%" height="80%"></p>

충돌을 해결하기 위한 방법은 여러 가지가 있다. 가장 간단한 방법은 같은 공간에 여러 개의 키를 연결 리스트로 만들어 넣는 것이다. 문제는 아이템이 많아질 경우 찾는 시간이 길어진다는 점이다. 만약 거의 대부분의 아이템이 'A'로 시작한다면, 전체 해시 테이블이 한 공간만 빼고 모두 비어있게 된다. 그 한 공간에는 거대한 연결 리스트가 있게 된다. 이건 그냥 모든 항목을 연결 리스트에 넣은 것이나 마찬가지다. 결국 해시 테이블이 느려지게 된다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/5_2.PNG" width="60%" height="80%"></p>

여기에서 두 가지 교훈을 얻을 수 있다.
* 해시 함수는 정말 중요하다. 방금 전의 해시 함수는 모든 키를 하나의 공간에 할당했다. 이상적으로는 해시 함수는 키를 해시 테이블 전체에 고르게 할당해야 한다.
* 만약 연결 리스트가 길어지면 해시 테이블의 속도도 느려진다. 하지만 좋은 해시 함수가 있다면 그런 일은 발생하지 않는다.

좋은 해시 함수는 충돌을 최소화한다. 

### 5.5. 성능

평균적인 경우에 해시 테이블은 모든 항목에 대해 O(1) 시간이 걸린다. O(1)은 상수 시간(constant time)이라고 불린다. 상수 시간은 순간적이라는 뜻이 아니라 해시 테이블의 크기에 상관없이 항상 똑같은 시간이 걸린다는 의미이다. 즉, 배열이 아무리 크든 작든 상관없이 원소 하나를 꺼내는 데 걸리는 시간은 동일하다. 

|                  | 평균적인 경우          | 최악의 경우          |
| :---------------:| :---------------:| :--------------:|
| centered column  | centered column | centered column |
| 탐색      		| O(1) | O(n) |
| 삽입      		| O(1) | O(n) |
| 삭제      		| O(1) | O(n) |

하지만 최악의 경우에 해시 테이블은 모든 항목에 대해 O(n) 시간, 즉 선형 시간이 걸린다. 정말 느리다. 배열, 연결 리스트와 비교해보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/5_3.PNG" width="60%" height="80%"></p>

평균적인 경우, 해시 테이블은 배열과 연결 리스트, 양쪽 세계의 좋은 점만 가진다. 하지만 최악의 경우에는 해시 테이블이 가장 느리다. 따라서 해시 테이블에서는 최악의 상황이 발생하지 않도록 하는 것이 중요하다. 그렇게 하려면 충돌을 피해야 한다. 충돌을 피하기 위해서 다음과 같은 것이 필요하다.

* 낮은 사용률
* 좋은 해시 함수

**사용률**

해시 테이블의 사용률(load factor)는 다음과 같이 계산한다. 해시 테이블은 저장을 위해 배열을 사용한다. 배열에서 이미 값이 차지하고 있는 공간의 수를 센다.

`해시 테이블에 있는 항목의 수 / 해시 테이블에 있는 (총) 공간의 수`

예를 들어, [,1,0,] 의 경우 사용률은 2/5이다. [,20,]은 1/3이다. 만약 100개의 물건을 50 길이의 배열에 할당한다면? 사용률이 2가 된다. 사용률이 1보다 크다는 것은 배열에 공간의 수보다 항목의 수가 많다는 뜻이다. 사용률이 커지기 시작하면 해시 테이블의 공간을 추가해야 한다. 이것을 **리사이징(resizing)**이라고 한다. 사용률이 낮을수록 충돌이 적게 일어나고, 해시 테이블의 성능도 좋아진다. 보통은 사용률이 0.7보다 커지면 리사이징한다.

라사이징은 엄청 비싼 작업이므로 자주 하는 것은 좋지 않다. 하지만 해시 테이블은 리사이징을 해도 평균적으로 O(1) 시간이 걸린다.

**좋은 해시 함수란**

좋은 해시 함수란 배열에 값을 고루 분포시키는 함수이다. 나쁜 해시 함수는 값들이 뭉쳐져 있어서 충돌이 자주 발생한다. 좋은 해시 함수의 예로 SHA 함수가 있다.


### 5장 정리

해시 테이블은 속도가 빠르고 자료를 여러 가지로 모형화할 수 있기에 아주 강력한 자료 구조이다.

* 해시 테이블은 해시 함수와 배열을 결합해서 만든다.
* 충돌은 나쁘다. 충돌을 줄이는 해시 함수가 있어야 한다.
* 해시 테이블은 정말 빠른 탐색, 삽입, 삭제 속도를 가진다.
* 해시 테이블은 어떤 항목과 다른 항목의 관계를 모형화하는 데 좋다.
* 사용률이 0.7보다 커지면 해시 테이블은 리사이징할 때이다.
* 해시 테이블은 (웹 서버 등에서) 데이터를 캐싱하는 데도 사용된다.
* 해시 테이블은 중복을 잡아내는 데도 뛰어나다.


<div id='6.'/>

## 6. 너비 우선 탐색 (Breadth-first Search)

### 6.2. 그래프의 소개

새로운 추상 자료구조인 그래프(graph)를 사용하여 네트워크를 모형화하는 방법을 배운다. 첫 번째 그래프 알고리즘을 살펴보자. 바로 너비 우선 탐색(BFS; Breadth-First Search)이라고 불리는 알고리즘이다. 너비 우선 탐색을 사용하면 두 항목 간의 최단 경로를 찾을 수 있다. 이 최단 경로라는 말은 여러 가지를 의미할 수 있다. 

* 체커 게임에서 가장 적은 수로 승리할 수 있는 방법을 계산하는 인공지능
* 맞춤법 검사기(실제 단어에서 가장 적은 개수의 글자를 고쳐서 올바른 단어를 만드는 방법)
* 여러분의 네트워크에서 가장 가까운 의사 선생님 찾기

그래프 알고리즘은 필자가 알고 있는 가장 유용한 알고리즘 중 하나이다. 이 장에서 배우는 알고리즘들은 몇 번이고 반복해서 적용할 수 있다.

여러분은 샌프란시스코에 있고, 트윈 픽스에서 금문교까지 가고 싶다고 하자. 버스로 가지만 최대한 적게 갈아 타고 싶다. 이런 종류의 문제를 최단 경로 문제(shortest-path problem)라고 한다. 최단 경로, 즉 가장 짧은 것을 찾아야 한다. 이렇게 최단 경로 문제를 푸는 알고리즘을 너비 우선 탐색이라고 한다. 

트윈 픽스에서 금문교까지 가는 최단 경로를 찾으려면 다음과 같은 절차가 필요하다.
* 문제를 그래프로 모형화한다.
* 너비 우선 탐색으로 문제를 푼다.

그래프란 무엇인가? 그래프는 정점(node)과 간선(edge)으로 이뤄진다. 정점은 여러 개의 다른 정점과 바로 이어질 수 있다. 이렇게 바로 이어진 정점을 이웃(neighbor)이라고 한다. 그래프는 항목들이 서로 어떻게 연결되어 있는지를 모형화하는 방법이다.

### 6.3. 너비 우선 탐색

앞에서 배운 이진 탐색이라고 하는 탐색 알고리즘을 살펴보았다. 너비 우선 탐색은 그래프를 대상으로 하는 다른 종류의 탐색 알고리즘이다. (이진 탐색은 배열을 대상으로 하는 탐색 알고리즘) 너비 우선 탐색은 다음과 같은 두 가지 종류의 질문에 대답하는 데 도움디 된다.

* Q1. 정점 A에서 정점 B까지 가는 경로가 존재하는가? (여러분의 네트워크에 망고 판매상이 있는가?)
* Q2. 정점 A에서 정점 B로 가는 최단 경로는 무엇인가? (누가 가장 가까운 망고 판매상인가?)

여러분이 망고 농장의 주인이라고 하자. 망고를 팔아 줄 수 있는 판매상을 찾고 있다. 여러분의 페이스북 친구 중에 망고 판매상이 있나? 확인하려면 페이스북의 친구 목록을 살펴보면 된다. 여러분의 친구 중에 망고 판매상이 없다면, 여러분의 친구의 친구를 찾아보면 된다. 친구의 친구, 이런 식으로 망고 판매상이 도달할 때까지 전체 네트워크를 탐색하면 된다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/6_1.PNG" width="60%" height="80%"></p>

**최단 경로 찾기**

가장 가까운 망고 판매상을 찾을 수 있나? 친구는 1촌, 친구의 친구는 2촌 관계이다. 만약 1촌 관계인 망고 판매상이 없을 경우에만 2촌 관계를 탐색한다. 너비 우선 탐색이 하는 일이 바로 이것이다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/6_2.PNG" width="60%" height="80%"></p>

또 다른 방법은 탐색 목록에 2촌 관계를 추가하기 전에 1촌 관계부터 모두 추가하는 것이다. 목록을 위에서부터 차례대로 망고 판매상이 있는지 확인한다면, 1촌 관계에 있는 망고 판매상을 2촌 관계에 있는 망고 판매상보다 먼저 찾을 수 있다. 너비 우선 탐색은 단순히 A에서 B로 가는 경로를 찾는 것이 아니라 최단 경로를 찾을 수 있다.

이 방법은 목록에 추가한 순서대로 사람을 찾을 때만 가능하다. 이를 위해 큐(queue) 또는 대기열이라고 불리는 자료구조를 사용한다. 

**큐**

큐는 큐 안의 원소에 임의로 접근할 수 없다는 점에서 스택과 비슷하다. 큐에는 삽입(enqueue)과 제거(dequeue)라고 하는 두 가지 연산이 있다. 큐는 탐색 목록에도 쓸 수 있다. 큐를 사용하면 목록에 먼저 추가된 사람들을 먼저 꺼내서 탐색한다. 그래서 큐를 선입 선출(FIFO; First In First Out) 자료구조라고도 한다. 반대로 스택은 후입 선출(LIFO; Last In First Out) 자료구조이다.

### 6.4. 그래프의 구현

그래프는 몇 개의 정점으로 이루어져 있다. 각각의 정점은 이웃하는 정점과 연결된다. '여러분->밥'과 같은 관계를 어떻게 표현할까? 관계를 표시하는 자료구조가 무엇이 있을까? 바로 해시 테이블이다. 해시 테이블을 사용하면 키에 값을 할당할 수 있다. 이 경우에는 어떤 정점에 이웃하는 정점을 할당한다. 다음과 같은 큰 그래프를 파이썬 코드로 나타내보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/6_3.PNG" width="60%" height="80%"></p>

```python
graph = {}
graph["you"] = ["alice", "bob", "claire"]
graph["bob"] = ["anuj", "peggy"]
graph["alice"] = ["peggy"]
graph["claire"] = ["thom", "jonny"]
graph["anuj"] = []
graph["peggy"] = []
graph["thom"] = []
graph["jonny"] = []
```

위 그림과 같이 화살표가 있는 그래프를 방향 그래프(directed graph)라고 한다. 관계에는 방향성이 있다. ANUJ는 BOB의 이웃이지만, BOB은 ANUJ의 이웃이 아니다. 무방향 그래프(undirected graph)는 화살표(방향성)를 가지지 않기 때문에 이어진 두 정점은 서로 이웃이 된다. 

### 6.5. 알고리즘의 구현

정리하자면 알고리즘이 구현되는 방식은 다음과 같다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/6_4.PNG" width="60%" height="80%"></p>

너비 우선 탐색의 코드는 다음과 같다.

```python
from collections import deque

def person_is_seller(name):
    # 좀 더 의미있는 함수로 바꿀 필요가 있음
    return name[-1] == 'm'

def search(name):

    search_queue = deque()	# 새로운 큐를 생성
	search_queue += graph[name]	# 모든 이웃을 탐색 큐에 추가
	searched = []	# 이 배열은 이미 확인한 사람을 추적하기 위한 것
	
	while search_queue:
	    person = search_queue.popleft()	# 큐의 첫 번째 사람을 꺼냄
		if not person in searched:	# 이전에 확인하지 않은 사람만 확인
		    if person_is_seller(person):	# 망고 판매상인지 확인
			    print(person + " is a mango seller!")
				return True
			else:
			    search_queue += graph[person]
				searched.append(person)	# 이 사람을 확인한 것으로 표시
    return False	# 망고 판매상이 아무도 없다는 의미
		
search("you")
```

망고 판매상인지 여부는 한 사람당 한 번만 확인하면 된다. 두 번 이상하면 컴퓨터 자원 낭비가 된다. 만약 탐색 큐에 어떤 두 사람이 반복해서 들어가면 무한 반복에 빠지게 된다. 이렇기 때문에 이미 확인한 사람인지 확실히 해두어야 한다.

**실행 시간**

망고 판매상을 찾기 위해 여러분의 네트워크 전체를 탐색한다는 것은 모든 정점을 따라서 움직인다는 뜻이다. 따라서 실행 시간은 최소한 O(간선의 개수)가 된다. 간선을 통해 친구를 찾아 나서기 때문에 여기서 정점의 개수가 아닌 점을 확인하자. 

그리고 탐색할 사람을 저장하는 큐가 있어야 한다. 큐에 사람을 추가하는 데는 상수 시간, 즉 O(1)이 걸린다. 모든 사람에 대해 이것을 적용하면 총 O(사람의수) 시간이 걸린다. 

따라서 너비 우선 탐색은 O(사람의 수 + 간선의 수)가 되고 보통 O(V+E)라고 표기한다. (V: 정점의 수, E: 간선의 수)

### 6장 정리

* 너비 우선 탐색은 A에서 B로 가는 경로가 있는지 알려준다
* 만약 경로가 존재한다면 최단 경로도 찾아준다
* 만약 X까지의 최단 경로를 찾는 문제가 있다면 그 문제를 그래프로 모형화하자. 그리고 너비 우선 탐색으로 문제를 풀자.
* 방향 그래프는 화살표를 가지며, 화살표 방향으로 관계를 가진다. (ex. rama -> adit: rama가 adit에게 돈을 빚지고 있다는 뜻)
* 무방향 그래프는 화살표가 없고, 둘 간의 상호 관계를 나타낸다. (ex. ross-rachel: ross와 rachel이 서로 데이터 했다는 뜻)
* 큐는 선입선출, 스택은 후입선출
* 탐색 목록에 추가된 순서대로 사람을 확인해야 한다. 그래서 탐색 목록은 큐가 되어야 한다. 그렇지 않으면 최단 경로를 구할 수 없다.
* 누군가를 확인한 다음에는 두 번 다시 확인하지 않도록 해야 한다. 그렇지 않으면 무한 반복이 될 수 있다.

### 6장 연습 문제

다음 그래프에 대해 올바른 목록을 만들어보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/6_5.PNG" width="60%" height="80%"></p>

['기상', '운동', '샤워', '양치질', '옷입기', '점심 도시락 싸기', '아침 식사']

이 목록은 어떤 의미에서는 정렬이 되어 있다고 할 수 있다. 만약 작업 A가 작업 B에 의존한다면 목록에서 작업 A가 작업 B보다 나중에 와야 한다. 이런 것을 위상 정렬(topological sort)이라고 하며, 그래프에서 정렬된 리스트를 만드는 방법의 하나이다. 할 일의 순서가 있는 계획표를 위상 정렬로 표현할 수 있다.

다음은 여러분의 가계도이다. 이것도 정점(사람)과 간선이 있으니까 그래프이다. 간선은 각 정점의 부모를 가리킨다. 모든 간선은 아래로 내려간다. 가계도에서 거꾸로 가는 선이 있을 수 없다. 이런 것을 트리(tree)라고 한다. 트리는 거꾸로 가는 간선이 없는 특별한 종류의 그래프이다. 트리는 항상 그래프이지만 그래프는 트리가 아닐 수도 있다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/6_6.PNG" width="60%" height="80%"></p>



<div id='7.'/>
## 7. 다익스트라 알고리즘 (Dijkstra’s algorithm)

그래프의 간선에 가중치를 준 가중 그래프(weighted graph)를 알아보자. 가중 그래프에서 X까지의 최단 경로를 구하는 다익스트라 알고리즘(Dijkstra's algorithm)을 알아보자. 

그래프에 싸이클(cycle)이 있는 경우에는 다익스트라 알고리즘을 사용할 수 없다. 싸이클을 지나갈 때마다 가중치가 늘어나기 때문에 싸이클을 지나면 최단 경로를 얻을 수 없다. 싸이클은 사실 무방향 그래프와 같다. 무방향 그래프에서는 각 정점에 사이클을 더할 수 있다. 다익스트라 알고리즘은 방향성 비순환 그래프(DAG; Directed Acyclic Graph) 또는 사이클을 가진 경우에는 가중치가 양수일 때만 적용된다.

다음 그림을 참조하자. 가중 그래프는 다익스트라 알고리즘을, 균일 그래프는 너비 우선 탐색을 사용한다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/7_2.PNG" width="60%" height="80%"></p>

### 7.2. 알고리즘의 구현

다음 그래프에서 다익스트라 알고리즘이 어떻게 동작하는지 알아보자. 각 구간은 분 단위로 표시한 이동 시간이다. 다익스트라를 사용해서 최단 시간 경로를 구해보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/7_1.PNG" width="60%" height="80%"></p>

다익스트라 알고리즘은 4단계로 구성된다.

* 가장 가격이 싼 정점을 찾는다. 가장 가격이 싼 정점이란 도달하는 데 시간이 가장 적게 걸리는 정점이다.
* 이 정점의 이웃 정점들의 가격을 조사한다. 현재의 가격보다 더 싼 경로가 있는지 확인하고, 있으면 가격을 수정한다.
* 그래프 상의 모든 정점에 대해 이러한 일을 반복한다.
* 최종 경로를 계산한다.

1단계 - 출발점 정점 기준

| 정점 | 정점까지 걸리는 시간 |
| :---------------:| :---------------:|
| centered column  | centered column |
| A      		| 6 |
| B      		| 2 |
| 도착점      		| 무한대 |

2단계 - B 정점 기준 (A 정점보다 싼 가격이므로 선택)

| 정점 | 정점까지 걸리는 시간 |
| :---------------:| :---------------:|
| centered column  | centered column |
| A      		| 6 -> 5 |
| B      		| 2 |
| 도착점      		| 무한대 -> 7 |

3단계 - A 정점 기준

| 정점 | 정점까지 걸리는 시간 |
| :---------------:| :---------------:|
| centered column  | centered column |
| A      		| 6 -> 5 |
| B      		| 2 |
| 도착점      		| 무한대 -> 7 -> 6 |

위 예제에서는 최종 경로를 계산하는 마지막 단계는 포함하고 있지 않다. 단지 정점을 돌아다니며 가격만 조사하고 있다. 이런식으로 알고리즘이 흘러간다는 사실만 알아두자.

### 7.4. 다익스트라 알고리즘을 사용한 물물 교환

라마는 악보를 팔아서 피아노를 구하고 싶어한다. 다음은 에이미와의 거래를 그래프로 표현한 것이다. 라마가 바꿀 수 있는 물건들은 정점을 나타냈다. 간선의 가중치는 물건을 바꾸는 데 드는 돈이다. 라마는 돈을 가장 적게 쓰면서 악보를 피아노와 바꾸려면 어떤 경로를 선택해야 하는지 알고 싶어 한다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/code/book/grokking-algorithms/images/7_3.PNG" width="60%" height="80%"></p> 

시작하기에 앞서 각 정점에 대한 가격표를 만든다. 여기에 추가적으로 최종 경로 계산에 필요한 부모 정점도 만든다. 최종 경로를 구하기 위해서 정점, 가격뿐만 아니라 정점의 부모도 기록한다. 

1단계(초기 상태) - 악보(출발점) 정점 기준

| 부모 | 정점 | 가격 |
| :---------------: | :---------------: | :---------------: |
| centered column  | centered column | centered column |
| 악보 | LP | 5 |
| 악보 | 포스터 | 0 |
| -  | 기타  | 무한대 |
| -  | 드럼  | 무한대 |
| -  | 피아노 | 무한대 |

2단계 - 포스터 정점 기준 (LP보다 더 싼 가격이므로)

| 부모 | 정점 | 가격 |
| :---------------: | :---------------: | :---------------: |
| centered column  | centered column | centered column |
| 악보 | LP | 5 |
| 악보 | 포스터 | 0 |
| 포스터  | 기타  | 30 |
| 포스터  | 드럼  | 35 |
| -  | 피아노 | 무한대 |

3단계 - LP 정점 기준 (주의: BFS처럼 1단계씩 나아가야하므로 포스터 다음엔 LP이다)

| 부모 | 정점 | 가격 |
| :---------------: | :---------------: | :---------------: |
| centered column  | centered column | centered column |
| 악보 | LP | 5 |
| 악보 | 포스터 | 0 |
| LP  | 기타  | 20 |
| LP  | 드럼  | 25 |
| -  | 피아노 | 무한대 |

항상 가격이 싼 기준으로 업데이트된다. 

4단계 - 베이스기타 정점 기준 

| 부모 | 정점 | 가격 |
| :---------------: | :---------------: | :---------------: |
| centered column  | centered column | centered column |
| 악보 | LP | 5 |
| 악보 | 포스터 | 0 |
| LP  | 기타  | 20 |
| LP  | 드럼  | 25 |
| 베이스기타  | 피아노 | 40 |

5단계 - 드럼 정점 기준

| 부모 | 정점 | 가격 |
| :---------------: | :---------------: | :---------------: |
| centered column  | centered column | centered column |
| 악보 | LP | 5 |
| 악보 | 포스터 | 0 |
| LP  | 기타  | 20 |
| LP  | 드럼  | 25 |
| 드럼  | 피아노 | 35 |

5단계가 최종 결과이다. 피아노를 교환할 수 있는 가장 싼 가격은 35이다. 여기서 부모 정점을 하나씩 찾아서 가보면, '악보-LP-기타-드럼-피아노'인 경로를 가질 수 있는 것을 알 수 있다. 

이 예제를 통해 최단 경로라는 것이 반드시 거리를 최소화하는 것이 아니라는 것을 확인하자. 여기선 가중치가 있기 때문이다. 

### 7.5. 간선의 가중치가 음수인 경우

간선의 가중치가 음수인 경우는, 한 단계씩 나아갈 때 가격표의 일관성을 유지할 수 없다. 일단 어떤 정점을 처리하면 그 정점에 도달하는 더 싼 경로는 존재하지 않아야 하는데, 음수 가중치가 있으면 더 싼 경로가 발견되기도 한다. 따라서, 음의 가중치가 있는 경우 다익스트라 알고리즘을 사용할 수 없다. 만약, 음의 가중치를 가진 그래프에서 최단 경로를 찾고 싶다면 벨만-포드 알고리즘(Bellman-Ford algorithm)을 사용하면 된다.

### 7.6. 구현






































