{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8장. 텍스트 분석\n",
    "\n",
    "* [8.1. 텍스트 분석 이해](#8.1.)\n",
    "* [8.2. 텍스트 사전 준비 작업(텍스트 전처리) - 텍스트 정규화](#8.2.)\n",
    "* [8.3. Bag of Words - BOW](#8.3.)\n",
    "* [8.4. 텍스트 분류 실습 - 20 뉴스그룹 분류](#8.4.)\n",
    "* [8.5. 감성 분석](#8.5)\n",
    "* [8.6. 토픽 모델링 - 20 뉴스그룹](#8.6.)\n",
    "* [8.7. 문서 군집화 실습 - Opinion Review](#8.7.)\n",
    "* [8.8. 문서 유사도](#8.8.)\n",
    "* [8.9. 한글 텍스트 처리 - 네이버 영화 평점 감성 분석](#8.9.)\n",
    "* [8.10. 캐글 Mercari Price Suggestion Challenge](#8.10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='8.1.'/>\n",
    "\n",
    "## 8.1. 텍스트 분석 이해\n",
    "\n",
    "* NLP(Natural Language Processing)과 텍스트 분석(Text Analytics) \n",
    "   * NLP: 머신이 인간의 언어를 이해하고 해석하는 데 더 중점을 두고 기술이 발전\n",
    "      * NLP는 텍스트 분석의 성능을 더 높이는 기반 기술이라고 볼 수 있다.\n",
    "      * NLP 기술이 발전함에 따라 텍스트 분석도 더욱 정교하게 발전할 수 있다.\n",
    "   * Text Analytics: 비정형 텍스트에서 의미 있는 정보를 추출하는 것에 더 중점을 두고 기술이 발전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='8.2.'/>\n",
    "\n",
    "## 8.2. 텍스트 사전 준비 작업(텍스트 전처리) - 텍스트 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문장 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/gritmind/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 3\n",
      "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "text_sample = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
    "               You can see it out your window or on your television. \\\n",
    "               You feel it when you go to work, or go to church or pay your taxes.'\n",
    "sentences = sent_tokenize(text=text_sample)\n",
    "print(type(sentences),len(sentences))\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 15\n",
      "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "sentence = \"The Matrix is everywhere its all around us, here even in this room.\"\n",
    "words = word_tokenize(sentence)\n",
    "print(type(words), len(words))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문장 & 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 3\n",
      "[['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television', '.'], ['You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'taxes', '.']]\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "#여러개의 문장으로 된 입력 데이터를 문장별로 단어 토큰화 만드는 함수 생성\n",
    "def tokenize_text(text):\n",
    "    \n",
    "    # 문장별로 분리 토큰\n",
    "    sentences = sent_tokenize(text)\n",
    "    # 분리된 문장별 단어 토큰화\n",
    "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "    return word_tokens\n",
    "\n",
    "#여러 문장들에 대해 문장별 단어 토큰화 수행. \n",
    "word_tokens = tokenize_text(text_sample)\n",
    "print(type(word_tokens),len(word_tokens))\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문장을 단어별로 하나씩 토큰화 할 경우 문맥적인 의미는 무시된다.\n",
    "* 이 문제를 조금이라도 해결하기 위해서 n-gram이 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gritmind/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 stop words 갯수: 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "print('영어 stop words 갯수:',len(nltk.corpus.stopwords.words('english')))\n",
    "print(nltk.corpus.stopwords.words('english')[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.'], ['see', 'window', 'television', '.'], ['feel', 'go', 'work', ',', 'go', 'church', 'pay', 'taxes', '.']]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "all_tokens = []\n",
    "# 위 예제의 3개의 문장별로 얻은 word_tokens list 에 대해 stop word 제거 Loop\n",
    "for sentence in word_tokens:\n",
    "    filtered_words=[]\n",
    "    # 개별 문장별로 tokenize된 sentence list에 대해 stop word 제거 Loop\n",
    "    for word in sentence:\n",
    "        #소문자로 모두 변환합니다. \n",
    "        word = word.lower()\n",
    "        # tokenize 된 개별 word가 stop words 들의 단어에 포함되지 않으면 word_tokens에 추가\n",
    "        if word not in stopwords:\n",
    "            filtered_words.append(word)\n",
    "    all_tokens.append(filtered_words)\n",
    "    \n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming & Lemmatization\n",
    "\n",
    "* 모두 원형 단어를 찾는다는 목적은 같다.\n",
    "* Lemmatizing은 언어 리소스와 품사 정보를 활용하여 정확한 어근 단어를 찾아준다. (속도는 느리다)\n",
    "* 반면, stemming은 단순한 문법 규칙을 기반으로 원형 단어를 찾는다. (속도는 빠르다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work work work\n",
      "amus amus amus\n",
      "happy happiest\n",
      "fant fanciest\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\n",
    "print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))\n",
    "print(stemmer.stem('happier'),stemmer.stem('happiest'))\n",
    "print(stemmer.stem('fancier'),stemmer.stem('fanciest'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gritmind/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amuse amuse amuse\n",
      "happy happy\n",
      "fancy fancy\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "print(lemma.lemmatize('amusing','v'),lemma.lemmatize('amuses','v'),lemma.lemmatize('amused','v'))\n",
    "print(lemma.lemmatize('happier','a'),lemma.lemmatize('happiest','a'))\n",
    "print(lemma.lemmatize('fancier','a'),lemma.lemmatize('fanciest','a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='8.3.'/>\n",
    "\n",
    "## 8.3. Bag of Words - BOW\n",
    "\n",
    "* BOW 모델의 장점은 쉽고 빠른 구축에 있다. 단순히 단어의 발생 횟수에 기반하지만 예상보다 문서의 특징을 잘 나타낸다.\n",
    "* BOW 모델의 단점은 다음과 같다.\n",
    "   * 문맥 의미(Semantic Context) 반영 부족\n",
    "   * 희소 행렬 문제(벡터의 회소성)\n",
    "   \n",
    "   \n",
    "* BOW 피처 벡터화\n",
    "   * one-hot encoding\n",
    "   * count 기반 벡터화\n",
    "   * tf-idf 기반 벡터화\n",
    "   \n",
    "   \n",
    "* 사이킷런에서 Count / TFIDF 벡터화\n",
    "   * CountVectorizer - 피처 벡터화뿐만 아니라 수문자 일괄 변환, 토큰화, stopword 필터링 등의 텍스트 전처리도 함께 수행\n",
    "      * max_df: 전체 문서에 걸쳐서 너무 높은 빈도수를 가지는 단어를 제외하기 위한 파라미터\n",
    "      * min_df: 전체 문서에 걸쳐서 너무 낮은 빈도수를 가지는 단어를 제외하기 위한 파라미터\n",
    "      * max_features: 추출하는 피처의 개수를 제한. (ex. 2000이면, 가장 높은 빈도를 가지는 단어순으로 2000개까지만 피처로 추출)\n",
    "      * stop_words: 불용어 리스트 입력, (ex. 'english'라 지정하면 영어의 stopword 리스트 입력)\n",
    "      * n_gram_range: 튜플 형태로 (범위 최솟값, 범위 최댓값)을 지정한다. (ex. (1, 2)이면 토큰화된 단어를 1개씩(최소), 그리고 순서대로 2개씩(최대) 묶어서 피처로 추출)\n",
    "      * analyzer: 피처 추출을 수행할 단위를 지정 (디폴트: 'word'). Word가 아니라 character의 특정 범위를 피처로 만드는 특별한 경우에 사용)\n",
    "      * token_pattern: 토큰화를 수행하는 정규 표현식 패턴을 지정. (디폴트: `'\\b\\w\\w+\\b`로 '공백단어공백'으로 분리하는 토크나이저) 디폴트를 변경할 경우는 거의 없음.\n",
    "      * tokenizer: 토큰화를 별도의 커스텀 함수로 이용시에 적용.\n",
    "   * TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW 벡터화를 위한 희소 행렬\n",
    "\n",
    "* 사이킷런의 CountVectorizer/TfidfVectorizer는 텍스트를 피처 단위로 벡터화해 변환하고 CSR 형태의 희소 행렬로 반환한다.\n",
    "* BOW 벡터는 대부분 0으로 구성된 희소 행렬이다. 0이라도 하나의 값으로 메모리 공간에 할당된다. BOW 벡터의 크기는 매우 크기 때문에 이는 매우 비효율적이다.\n",
    "* 이러한 희소 행렬을 물리적으로 적은 메모리 공간을 차지할 수 있도록 반환해야 한다. 대표적인 방법으로 COO 형식과 CSR 형식이 있다.\n",
    "* 일반적으로 큰 희소 행렬을 저장하고 계산을 수행하는 능력이 CSR 형식이 더 뛰어나므로 CSR을 많이 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회소 행렬 - COO 형식\n",
    "\n",
    "* COO(Coordinate) 형식은 0이 아닌 데이터만 별도의 데이터 배열에 저장하고, 그 데이터가 가리키는 행과 열의 위치를 별도의 배열에 저장하는 방식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dense = np.array( [ [ 3, 0, 1 ], [0, 2, 0 ] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "# 0 이 아닌 데이터 추출\n",
    "data = np.array([3,1,2])\n",
    "\n",
    "# 행 위치와 열 위치를 각각 array로 생성 \n",
    "# 위 예제에서 0이 아닌 데이터 개수는 3개 이므로, 각각 3 크기의 벡터가 된다.\n",
    "row_pos = np.array([0,0,1])\n",
    "col_pos = np.array([0,2,1])\n",
    "\n",
    "# sparse 패키지의 coo_matrix를 이용하여 COO 형식으로 희소 행렬 생성\n",
    "sparse_coo = sparse.coo_matrix((data, (row_pos,col_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1],\n",
       "       [0, 2, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_coo.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회소 행렬 - CSR 형식\n",
    "\n",
    "* CSR(Compressed Sparse Row) 형식은 COO 형식이 행과 열의 위치를 나타내기 위해 반복적인 위치 데이터를 사용해야 하는 문제점을 해결한 방식이다.\n",
    "\n",
    "<img src=\"./images/pic_8_1.png\" width=\"80%\" height=\"80%\">\n",
    "\n",
    "* 위 그림은 COO 형식을 나타낸다.\n",
    "* 행 위치 배열을 보면 순차적으로 같은 인덱스를 반복해서 나타내는 걸 알 수 있다.\n",
    "* 행 위치 배열이 0부터 순차적으로 증가하는 값으로 이뤄졌다는 특성을 고려하면 행 위치 배열의 고유한 값의 사작 위치만 표기하는 방법으로 이러반 반복을 제거할 수 있다. (즉, 위치의 위치를 표현)\n",
    "* CSR는 Compressed Sparse Row의 약자이며, 이처럼 행 위치 배열 내에 있는 고유한 값의 시작 위치만 다시 별도의 위치 배열로 가지는 변환 방식을 의미한다.\n",
    "* 아래 그림은 CSR 형식을 나타낸다.\n",
    "\n",
    "<img src=\"./images/pic_8_2.png\" width=\"80%\" height=\"80%\">\n",
    "\n",
    "* 맨 매자막에 데이터의 총 개수를 배열에 추가한다.\n",
    "* 이렇게 고유 값의 시작 위치만 알고 있으면 COO 방식보다 메모리가 적게 들고 빠른 연산이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n",
      "[[0 0 1 0 0 5]\n",
      " [1 4 0 3 2 5]\n",
      " [0 6 0 3 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 7 0 8]\n",
      " [1 0 0 0 0 0]]\n",
      "CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인\n",
      "[[0 0 1 0 0 5]\n",
      " [1 4 0 3 2 5]\n",
      " [0 6 0 3 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 7 0 8]\n",
      " [1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "dense2 = np.array([[0,0,1,0,0,5],\n",
    "             [1,4,0,3,2,5],\n",
    "             [0,6,0,3,0,0],\n",
    "             [2,0,0,0,0,0],\n",
    "             [0,0,0,7,0,8],\n",
    "             [1,0,0,0,0,0]])\n",
    "\n",
    "# 0 이 아닌 데이터 추출\n",
    "data2 = np.array([1, 5, 1, 4, 3, 2, 5, 6, 3, 2, 7, 8, 1])\n",
    "\n",
    "# 행 위치와 열 위치를 각각 array로 생성 \n",
    "row_pos = np.array([0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 5])\n",
    "col_pos = np.array([2, 5, 0, 1, 3, 4, 5, 1, 3, 0, 3, 5, 0])\n",
    "\n",
    "# COO 형식으로 변환 \n",
    "sparse_coo = sparse.coo_matrix((data2, (row_pos,col_pos)))\n",
    "\n",
    "# 행 위치 배열의 고유한 값들의 시작 위치 인덱스를 배열로 생성\n",
    "row_pos_ind = np.array([0, 2, 7, 9, 10, 12, 13])\n",
    "\n",
    "# CSR 형식으로 변환 \n",
    "sparse_csr = sparse.csr_matrix((data2, col_pos, row_pos_ind))\n",
    "\n",
    "print('COO 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n",
    "print(sparse_coo.toarray())\n",
    "print('CSR 변환된 데이터가 제대로 되었는지 다시 Dense로 출력 확인')\n",
    "print(sparse_csr.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 실제 사용 시에는 다음과 같은 dense3 행렬을 생성 파라미터로 입력하면 COO나 CSR 희소 행렬로 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense3 = np.array([[0,0,1,0,0,5],\n",
    "             [1,4,0,3,2,5],\n",
    "             [0,6,0,3,0,0],\n",
    "             [2,0,0,0,0,0],\n",
    "             [0,0,0,7,0,8],\n",
    "             [1,0,0,0,0,0]])\n",
    "\n",
    "coo = sparse.coo_matrix(dense3)\n",
    "csr = sparse.csr_matrix(dense3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 사이킷런의 CountVectorizer나 TfidfVectorizer 클래스로 변환된 피처 벡터화 행렬은 모두 scipy의 CSR 형태의 희소 행렬이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='8.4.'/>\n",
    "\n",
    "## 8.4. 텍스트 분류 실습 - 20 뉴스그룹 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news_data = fetch_20newsgroups(subset='all',random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(news_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 클래스의 값과 분포도 \n",
      " 0     799\n",
      "1     973\n",
      "2     985\n",
      "3     982\n",
      "4     963\n",
      "5     988\n",
      "6     975\n",
      "7     990\n",
      "8     996\n",
      "9     994\n",
      "10    999\n",
      "11    991\n",
      "12    984\n",
      "13    990\n",
      "14    987\n",
      "15    997\n",
      "16    910\n",
      "17    940\n",
      "18    775\n",
      "19    628\n",
      "dtype: int64\n",
      "target 클래스의 이름들 \n",
      " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print('target 클래스의 값과 분포도 \\n',pd.Series(news_data.target).value_counts().sort_index())\n",
    "print('target 클래스의 이름들 \\n',news_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
      "Subject: Re: Observation re: helmets\n",
      "Organization: Sun Microsystems, RTP, NC\n",
      "Lines: 21\n",
      "Distribution: world\n",
      "Reply-To: egreen@east.sun.com\n",
      "NNTP-Posting-Host: laser.east.sun.com\n",
      "\n",
      "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
      "> \n",
      "> The question for the day is re: passenger helmets, if you don't know for \n",
      ">certain who's gonna ride with you (like say you meet them at a .... church \n",
      ">meeting, yeah, that's the ticket)... What are some guidelines? Should I just \n",
      ">pick up another shoei in my size to have a backup helmet (XL), or should I \n",
      ">maybe get an inexpensive one of a smaller size to accomodate my likely \n",
      ">passenger? \n",
      "\n",
      "If your primary concern is protecting the passenger in the event of a\n",
      "crash, have him or her fitted for a helmet that is their size.  If your\n",
      "primary concern is complying with stupid helmet laws, carry a real big\n",
      "spare (you can put a big or small head in a big helmet, but not in a\n",
      "small one).\n",
      "\n",
      "---\n",
      "Ed Green, former Ninjaite |I was drinking last night with a biker,\n",
      "  Ed.Green@East.Sun.COM   |and I showed him a picture of you.  I said,\n",
      "DoD #0111  (919)460-8302  |\"Go on, get to know her, you'll like her!\"\n",
      " (The Grateful Dead) -->  |It seemed like the least I could do...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news_data.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 텍스트 데이터를 확인해 보면 뉴스그룹 기사의 내용뿐만 아니라 뉴스그룹 제목, 작성자, 소속, 이메일 등의 다양한 정보가 있다.\n",
    "* 이 중에서 내용을 제외하고 제목 등 다른 정보는 제거한다.\n",
    "* 제목과 소속, 이메일 주소 등의 헤더와 푸터 정보들은 뉴스그룹 분류의 타겟 클래스 값과 유사한 데이터를 가지고 있는 경우가 많다. 이 피처들을 포함하면 왠만한 ML 알고리즘을 적용해도 상당히 높은 예측 성능을 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "학습 데이터 크기 11314 , 테스트 데이터 크기 7532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# subset='train'으로 학습용(Train) 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
    "train_news= fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=156)\n",
    "X_train = train_news.data\n",
    "y_train = train_news.target\n",
    "print(type(X_train))\n",
    "\n",
    "# subset='test'으로 테스트(Test) 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
    "test_news= fetch_20newsgroups(subset='test',remove=('headers', 'footers','quotes'),random_state=156)\n",
    "X_test = test_news.data\n",
    "y_test = test_news.target\n",
    "print('학습 데이터 크기 {0} , 테스트 데이터 크기 {1}'.format(len(train_news.data) , len(test_news.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피처 벡터화 변환과 머신러닝 모델 학습/예측/평가\n",
    "\n",
    "* CountVectorizer를 적용할 때는 학습 데이터로 fit & transform하고, 테스트 데이터는 tranform할 때만 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CountVectorizer 기반 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 Text의 CountVectorizer Shape: (11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Count Vectorization으로 feature extraction 변환 수행. \n",
    "cnt_vect = CountVectorizer()\n",
    "# 개정판 소스 코드 변경(2019.12.24)\n",
    "cnt_vect.fit(X_train)\n",
    "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
    "\n",
    "# 학습 데이터로 fit( )된 CountVectorizer를 이용하여 테스트 데이터를 feature extraction 변환 수행. \n",
    "X_test_cnt_vect = cnt_vect.transform(X_test)\n",
    "\n",
    "print('학습 데이터 Text의 CountVectorizer Shape:',X_train_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorized Logistic Regression 의 예측 정확도는 0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# LogisticRegression을 이용하여 학습/예측/평가 수행. \n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_cnt_vect , y_train)\n",
    "pred = lr_clf.predict(X_test_cnt_vect)\n",
    "print('CountVectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TfidfVectorizer (기본) 기반 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic Regression 의 예측 정확도는 0.674\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환. \n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "# LogisticRegression을 이용하여 학습/예측/평가 수행. \n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect , y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TfidfVectorizer (stopword, ngram) 기반 LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.692\n"
     ]
    }
   ],
   "source": [
    "# stop words 필터링을 추가하고 ngram을 기본(1,1)에서 (1,2)로 변경하여 Feature Vectorization 적용.\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300 )\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect , y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 최적 C 값 도출 튜닝 수행. CV는 3 Fold셋으로 설정. \n",
    "params = { 'C':[0.01, 0.1, 1, 5, 10]}\n",
    "grid_cv_lr = GridSearchCV(lr_clf ,param_grid=params , cv=3, scoring='accuracy', verbose=1, n_jobs=5)\n",
    "grid_cv_lr.fit(X_train_tfidf_vect , y_train)\n",
    "print('Logistic Regression best C parameter :',grid_cv_lr.best_params_ )\n",
    "\n",
    "# 최적 C 값으로 학습된 grid_cv로 예측 수행하고 정확도 평가. \n",
    "pred = grid_cv_lr.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷런 파이프라인(Pipeline) 사용 및 GridSearchCV와의 결합\n",
    "\n",
    "* 사이킷런의 Pipeline 클래스를 이용하면 피처 벡터화와 ML 알고리즘 학습/예측을 위한 코드 작성을 한 번에 진행할 수 있다.\n",
    "* Pipeline을 이용하면 데이터의 전처리와 머신러닝 학습 과정을 통일된 API 기반에서 처리할 수 있다.\n",
    "* 대용량 데이터의 피처 벡터화 결과를 별도 데이터로 저장하지 않고 스트림 기반에서 바로 머신러닝 알고리즘의 데이터로 입력할 수 있기에 수행 시간을 절약할 수 있다.\n",
    "* 일반적으로 사이킷런 Pipeline은 텍스트 기반의 피처 벡터화뿐만 아니라 모든 데이터 전처리 작업과 Estimator를 결합할 수 있다.\n",
    "* pipeline.fit 과 pipeline.predict 만 수행하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline을 통한 Logistic Regression 의 예측 정확도는 0.701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# TfidfVectorizer 객체를 tfidf_vect 객체명으로, LogisticRegression객체를 lr_clf 객체명으로 생성하는 Pipeline생성\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)),\n",
    "    ('lr_clf', LogisticRegression(C=10))\n",
    "])\n",
    "\n",
    "# 별도의 TfidfVectorizer객체의 fit_transform( )과 LogisticRegression의 fit(), predict( )가 필요 없음. \n",
    "# pipeline의 fit( ) 과 predict( ) 만으로 한꺼번에 Feature Vectorization과 ML 학습/예측이 가능. \n",
    "pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_test)\n",
    "print('Pipeline을 통한 Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pipeline 기반에서도 하이퍼 파라미터 튜닝을 GridSearchCV 방식으로 진행할 수 있다.\n",
    "* 파라미터 변수는 헤깔릴 수 있는데 언더바 2개를 연달아 붙여 파라미터 정의와 실제 이름을 구분할 수 있다.\n",
    "* Pipeline 기반 하이퍼 파라미터 튜닝은 너무 많은 경우의 수가 발생하기 쉬우니 주의를 해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Pipeline에 기술된 각각의 객체 변수에 언더바(_)2개를 연달아 붙여 GridSearchCV에 사용될 \n",
    "# 파라미터/하이퍼 파라미터 이름과 값을 설정. . \n",
    "params = { 'tfidf_vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "           'tfidf_vect__max_df': [100, 300, 700],\n",
    "           'lr_clf__C': [1,5,10]\n",
    "}\n",
    "\n",
    "# GridSearchCV의 생성자에 Estimator가 아닌 Pipeline 객체 입력\n",
    "grid_cv_pipe = GridSearchCV(pipeline, param_grid=params, cv=3 , scoring='accuracy',verbose=1)\n",
    "grid_cv_pipe.fit(X_train , y_train)\n",
    "print(grid_cv_pipe.best_params_ , grid_cv_pipe.best_score_)\n",
    "\n",
    "pred = grid_cv_pipe.predict(X_test)\n",
    "print('Pipeline을 통한 Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='8.5.'/>\n",
    "\n",
    "## 8.5. 감성 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지도학습 기반 감성 분석 실습 - IMDB 영화평"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* .tsv 파일은 탭('\\t')으로 분리된 파일인데, 판다스의 read_csv()에 sep='\\t'을 명시해주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "review_df = pd.read_csv('./labeledTrainData.tsv', header=0, sep=\"\\t\", quoting=3)\n",
    "review_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n"
     ]
    }
   ],
   "source": [
    "print(review_df['review'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `<br>` html 태그 제거\n",
    "* 영어가 아닌 숫자/특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# <br> html 태그는 replace 함수로 공백으로 변환\n",
    "review_df['review'] = review_df['review'].str.replace('<br />',' ')\n",
    "\n",
    "# 파이썬의 정규 표현식 모듈인 re를 이용하여 영어 문자열이 아닌 문자는 모두 공백으로 변환 \n",
    "review_df['review'] = review_df['review'].apply( lambda x : re.sub(\"[^a-zA-Z]\", \" \", x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17500, 1), (7500, 1))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_df = review_df['sentiment']\n",
    "feature_df = review_df.drop(['id','sentiment'], axis=1, inplace=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(feature_df, class_df, test_size=0.3, random_state=156)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pipeline - CountVectorizer & LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도는 0.8860, ROC-AUC는 0.9503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 스톱 워드는 English, filtering, ngram은 (1,2)로 설정해 CountVectorization수행. \n",
    "# LogisticRegression의 C는 10으로 설정. \n",
    "pipeline = Pipeline([\n",
    "    ('cnt_vect', CountVectorizer(stop_words='english', ngram_range=(1,2) )),\n",
    "    ('lr_clf', LogisticRegression(C=10))])\n",
    "\n",
    "# Pipeline 객체를 이용하여 fit(), predict()로 학습/예측 수행. predict_proba()는 roc_auc때문에 수행.  \n",
    "pipeline.fit(X_train['review'], y_train)\n",
    "pred = pipeline.predict(X_test['review'])\n",
    "pred_probs = pipeline.predict_proba(X_test['review'])[:,1]\n",
    "\n",
    "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test ,pred),\n",
    "                                         roc_auc_score(y_test, pred_probs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pipeline - TfidfVectorizer & LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도는 0.8936, ROC-AUC는 0.9598\n"
     ]
    }
   ],
   "source": [
    "# 스톱 워드는 english, filtering, ngram은 (1,2)로 설정해 TF-IDF 벡터화 수행. \n",
    "# LogisticRegression의 C는 10으로 설정. \n",
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2) )),\n",
    "    ('lr_clf', LogisticRegression(C=10))])\n",
    "\n",
    "pipeline.fit(X_train['review'], y_train)\n",
    "pred = pipeline.predict(X_test['review'])\n",
    "pred_probs = pipeline.predict_proba(X_test['review'])[:,1]\n",
    "\n",
    "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test ,pred),\n",
    "                                         roc_auc_score(y_test, pred_probs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비지도학습 기반 감성 분석 소개\n",
    "\n",
    "* 학습 데이터가 없기 때문에 비지도 감성 분석은 Lexicon을 기반으로 한다.\n",
    "* Lexicon은 일반적으로 어휘집을 의미한다. 여기서는 주로 감성 분석을 위해 감성 어휘 사전이라 생각하자.\n",
    "* 감성 사전은 긍정 감성 또는 부정 감성의 정도를 의미하는 수치를 가지고 있으며 이를 감성 지수(Polarity score)라 한다.\n",
    "* 이 감성 지수는 단어의 위치나 주변 단어, 문맥, POS 등을 참고해 결정된다.\n",
    "\n",
    "\n",
    "* WordNet\n",
    "   * 단순한 어휘 사전이 아닌 시맨틱 분석을 제공하는 어휘 사전이다.\n",
    "   * 다양한 상황에서 같은 어휘라도 다르게 사용되는 어휘의 시맨틱 정보를 제공\n",
    "   * 각각의 품사(명사, 동사, 형용사, 부사 등)로 구성된 개별 단어를 Synset(Sets of cognitive synonyms)이라는 개념으로 표현\n",
    "   * Synset은 단순한 하나의 단어가 아니라 그 단어가 가지는 문맥, 시맨틱 정보를 제공하는 WordNet의 핵심 개념\n",
    "   \n",
    "   \n",
    "* 감성사전\n",
    "   * SentiWordNet (예측 정확도가 그리 높지 않아 잘 사용하지 않음)\n",
    "      * WordNet의 Synset 개념을 감성 분석에 적용한 것이다.\n",
    "      * WordNet의 Synset별로 3가지 감성 점수(sentiment score)를 할당한다. (긍정 감성 지수, 부정 감성 지수, 객관성 지수)\n",
    "      * 문장별로 단어들의 긍정 감성 지수와 부정 감성 지수를 합산하여 최종 감성 지수를 계산하고 이에 기반해 감성이 긍정인지 부정인지 결정한다.\n",
    "   * VADER\n",
    "      * 주로 소셜 미디어의 텍스트에 대한 감성 분석을 위한 패키지이다.\n",
    "      * 뛰어난 감성 분석 결과를 제공하며, 비교적 빠른 수행 시간을 보장해 대용량 텍스트 데이터에 잘 사용된다.\n",
    "   * Pattern\n",
    "      * 예측 성능 측면에서 가장 주목받는 패키지이다.\n",
    "      * 파이썬 2.x에서만 동작하고 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WordNet 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 특정 단어에 대한 synsets 추출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synsets() 반환 type : <class 'list'>\n",
      "synsets() 반환 값 갯수: 18\n",
      "synsets() 반환 값 : [Synset('present.n.01'), Synset('present.n.02'), Synset('present.n.03'), Synset('show.v.01'), Synset('present.v.02'), Synset('stage.v.01'), Synset('present.v.04'), Synset('present.v.05'), Synset('award.v.01'), Synset('give.v.08'), Synset('deliver.v.01'), Synset('introduce.v.01'), Synset('portray.v.04'), Synset('confront.v.03'), Synset('present.v.12'), Synset('salute.v.06'), Synset('present.a.01'), Synset('present.a.02')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "term = 'present'\n",
    "\n",
    "# 'present'라는 단어로 wordnet의 synsets 생성. \n",
    "synsets = wn.synsets(term)\n",
    "print('synsets() 반환 type :', type(synsets))\n",
    "print('synsets() 반환 값 갯수:', len(synsets))\n",
    "print('synsets() 반환 값 :', synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* synsets 객체는 품사(POS), 정의(Definition), 부명제(Lemma) 등으로 시맨틱적인 요소를 표현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Synset name :  present.n.01 #####\n",
      "POS : noun.time\n",
      "Definition: the period of time that is happening now; any continuous stretch of time including the moment of speech\n",
      "Lemmas: ['present', 'nowadays']\n",
      "##### Synset name :  present.n.02 #####\n",
      "POS : noun.possession\n",
      "Definition: something presented as a gift\n",
      "Lemmas: ['present']\n",
      "##### Synset name :  present.n.03 #####\n",
      "POS : noun.communication\n",
      "Definition: a verb tense that expresses actions or states at the time of speaking\n",
      "Lemmas: ['present', 'present_tense']\n",
      "##### Synset name :  show.v.01 #####\n",
      "POS : verb.perception\n",
      "Definition: give an exhibition of to an interested audience\n",
      "Lemmas: ['show', 'demo', 'exhibit', 'present', 'demonstrate']\n",
      "##### Synset name :  present.v.02 #####\n",
      "POS : verb.communication\n",
      "Definition: bring forward and present to the mind\n",
      "Lemmas: ['present', 'represent', 'lay_out']\n",
      "##### Synset name :  stage.v.01 #####\n",
      "POS : verb.creation\n",
      "Definition: perform (a play), especially on a stage\n",
      "Lemmas: ['stage', 'present', 'represent']\n",
      "##### Synset name :  present.v.04 #####\n",
      "POS : verb.possession\n",
      "Definition: hand over formally\n",
      "Lemmas: ['present', 'submit']\n",
      "##### Synset name :  present.v.05 #####\n",
      "POS : verb.stative\n",
      "Definition: introduce\n",
      "Lemmas: ['present', 'pose']\n",
      "##### Synset name :  award.v.01 #####\n",
      "POS : verb.possession\n",
      "Definition: give, especially as an honor or reward\n",
      "Lemmas: ['award', 'present']\n",
      "##### Synset name :  give.v.08 #####\n",
      "POS : verb.possession\n",
      "Definition: give as a present; make a gift of\n",
      "Lemmas: ['give', 'gift', 'present']\n",
      "##### Synset name :  deliver.v.01 #####\n",
      "POS : verb.communication\n",
      "Definition: deliver (a speech, oration, or idea)\n",
      "Lemmas: ['deliver', 'present']\n",
      "##### Synset name :  introduce.v.01 #####\n",
      "POS : verb.communication\n",
      "Definition: cause to come to know personally\n",
      "Lemmas: ['introduce', 'present', 'acquaint']\n",
      "##### Synset name :  portray.v.04 #####\n",
      "POS : verb.creation\n",
      "Definition: represent abstractly, for example in a painting, drawing, or sculpture\n",
      "Lemmas: ['portray', 'present']\n",
      "##### Synset name :  confront.v.03 #####\n",
      "POS : verb.communication\n",
      "Definition: present somebody with something, usually to accuse or criticize\n",
      "Lemmas: ['confront', 'face', 'present']\n",
      "##### Synset name :  present.v.12 #####\n",
      "POS : verb.communication\n",
      "Definition: formally present a debutante, a representative of a country, etc.\n",
      "Lemmas: ['present']\n",
      "##### Synset name :  salute.v.06 #####\n",
      "POS : verb.communication\n",
      "Definition: recognize with a gesture prescribed by a military regulation; assume a prescribed position\n",
      "Lemmas: ['salute', 'present']\n",
      "##### Synset name :  present.a.01 #####\n",
      "POS : adj.all\n",
      "Definition: temporal sense; intermediate between past and future; now existing or happening or in consideration\n",
      "Lemmas: ['present']\n",
      "##### Synset name :  present.a.02 #####\n",
      "POS : adj.all\n",
      "Definition: being or existing in a specified place\n",
      "Lemmas: ['present']\n"
     ]
    }
   ],
   "source": [
    "for synset in synsets :\n",
    "    print('##### Synset name : ', synset.name(),'#####')\n",
    "    print('POS :',synset.lexname())\n",
    "    print('Definition:',synset.definition())\n",
    "    print('Lemmas:',synset.lemma_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* WordNet은 어휘 사이의 유사도를 측정할 수 있다.\n",
    "* synset 객체는 단어 간의 유사도를 나타내기 위해서 path_similarity() 메서드를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>tiger</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tree</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lion</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tiger</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cat</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dog</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tree  lion  tiger   cat   dog\n",
       "tree   1.00  0.07   0.07  0.08  0.12\n",
       "lion   0.07  1.00   0.33  0.25  0.17\n",
       "tiger  0.07  0.33   1.00  0.25  0.17\n",
       "cat    0.08  0.25   0.25  1.00  0.20\n",
       "dog    0.12  0.17   0.17  0.20  1.00"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# synset 객체를 단어별로 생성합니다. \n",
    "tree = wn.synset('tree.n.01')\n",
    "lion = wn.synset('lion.n.01')\n",
    "tiger = wn.synset('tiger.n.02')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog = wn.synset('dog.n.01')\n",
    "\n",
    "entities = [tree , lion , tiger , cat , dog]\n",
    "similarities = []\n",
    "entity_names = [ entity.name().split('.')[0] for entity in entities]\n",
    "\n",
    "# 단어별 synset 들을 iteration 하면서 다른 단어들의 synset과 유사도를 측정합니다. \n",
    "for entity in entities:\n",
    "    similarity = [ round(entity.path_similarity(compared_entity), 2)  for compared_entity in entities ]\n",
    "    similarities.append(similarity)\n",
    "    \n",
    "# 개별 단어별 synset과 다른 단어의 synset과의 유사도를 DataFrame형태로 저장합니다.  \n",
    "similarity_df = pd.DataFrame(similarities , columns=entity_names,index=entity_names)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SentiWordNet을 이용한 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senti_synsets() 반환 type : <class 'list'>\n",
      "senti_synsets() 반환 값 갯수: 11\n",
      "senti_synsets() 반환 값 : [SentiSynset('decelerate.v.01'), SentiSynset('slow.v.02'), SentiSynset('slow.v.03'), SentiSynset('slow.a.01'), SentiSynset('slow.a.02'), SentiSynset('dense.s.04'), SentiSynset('slow.a.04'), SentiSynset('boring.s.01'), SentiSynset('dull.s.08'), SentiSynset('slowly.r.01'), SentiSynset('behind.r.03')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "senti_synsets = list(swn.senti_synsets('slow'))\n",
    "print('senti_synsets() 반환 type :', type(senti_synsets))\n",
    "print('senti_synsets() 반환 값 갯수:', len(senti_synsets))\n",
    "print('senti_synsets() 반환 값 :', senti_synsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SentiSynset 객체는 단어의 감성을 나타내는 감성 지수와 객관성(감성과 반대)을 나타내는 객관성 지수를 가진다.\n",
    "* 감성 지수는 다시 긍정 감성 지수와 부정 감성 지수로 나뉜다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "father 긍정감성 지수:  0.0\n",
      "father 부정감성 지수:  0.0\n",
      "father 객관성 지수:  1.0\n",
      "\n",
      "\n",
      "fabulous 긍정감성 지수:  0.875\n",
      "fabulous 부정감성 지수:  0.125\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "father = swn.senti_synset('father.n.01')\n",
    "print('father 긍정감성 지수: ', father.pos_score())\n",
    "print('father 부정감성 지수: ', father.neg_score())\n",
    "print('father 객관성 지수: ', father.obj_score())\n",
    "print('\\n')\n",
    "fabulous = swn.senti_synset('fabulous.a.01')\n",
    "print('fabulous 긍정감성 지수: ',fabulous .pos_score())\n",
    "print('fabulous 부정감성 지수: ',fabulous .neg_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SentiWordNet / WordNet을 이용하기 위해서 어근 추출과 품사 태깅을 해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# 간단한 NTLK PennTreebank Tag를 기반으로 WordNet기반의 품사 Tag로 변환\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다음은 일종의 Lexicon 기반 (SentiWordNet) 감성 분류기이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "def swn_polarity(text):\n",
    "    # 감성 지수 초기화 \n",
    "    sentiment = 0.0\n",
    "    tokens_count = 0\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    raw_sentences = sent_tokenize(text)\n",
    "    # 분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산 \n",
    "    for raw_sentence in raw_sentences:\n",
    "        # NTLK 기반의 품사 태깅 문장 추출  \n",
    "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
    "        for word , tag in tagged_sentence:\n",
    "            \n",
    "            # WordNet 기반 품사 태깅과 어근 추출\n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if wn_tag not in (wn.NOUN , wn.ADJ, wn.ADV):\n",
    "                continue                   \n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            if not lemma:\n",
    "                continue\n",
    "            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성. \n",
    "            synsets = wn.synsets(lemma , pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    "            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n",
    "            # 모든 단어에 대해 긍정 감성 지수는 +로 부정 감성 지수는 -로 합산해 감성 지수 계산. \n",
    "            synset = synsets[0]\n",
    "            swn_synset = swn.senti_synset(synset.name())\n",
    "            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())           \n",
    "            tokens_count += 1\n",
    "    \n",
    "    if not tokens_count:\n",
    "        return 0\n",
    "    \n",
    "    # 총 score가 0 이상일 경우 긍정(Positive) 1, 그렇지 않을 경우 부정(Negative) 0 반환\n",
    "    if sentiment >= 0 :\n",
    "        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['preds'] = review_df['review'].apply( lambda x : swn_polarity(x) )\n",
    "y_target = review_df['sentiment'].values\n",
    "preds = review_df['preds'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7668 4832]\n",
      " [3636 8864]]\n",
      "정확도: 0.6613\n",
      "정밀도: 0.6472\n",
      "재현율: 0.7091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score \n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "print(confusion_matrix( y_target, preds))\n",
    "print(\"정확도:\", np.round(accuracy_score(y_target , preds), 4))\n",
    "print(\"정밀도:\", np.round(precision_score(y_target , preds),4))\n",
    "print(\"재현율:\", np.round(recall_score(y_target, preds), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VADER를 이용한 감성 분석\n",
    "\n",
    "* 설치: NLTK 패키지 - nltk.download('all') OR pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.13, 'neu': 0.743, 'pos': 0.127, 'compound': -0.7943}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "senti_analyzer = SentimentIntensityAnalyzer()\n",
    "senti_scores = senti_analyzer.polarity_scores(review_df['review'][0])\n",
    "print(senti_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'compound'는 neg, neu, pos score를 적절히 조합해 -1에서 1 사이의 감성 지수를 표현한 값이다.\n",
    "* compound score를 기반으로 부정 감성 또는 긍정 감성 여부를 결정한다.\n",
    "* 보통 0.1 이상이면 긍정 감성, 그 이하이면 부정 감성으로 판단하나 상황에 따라 이 임계값을 적절히 조정해 예측 성능을 조절한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6736  5764]\n",
      " [ 1867 10633]]\n",
      "정확도: 0.6948\n",
      "정밀도: 0.6485\n",
      "재현율: 0.8506\n"
     ]
    }
   ],
   "source": [
    "def vader_polarity(review,threshold=0.1):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    \n",
    "    # compound 값에 기반하여 threshold 입력값보다 크면 1, 그렇지 않으면 0을 반환 \n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 1 if agg_score >= threshold else 0\n",
    "    return final_sentiment\n",
    "\n",
    "# apply lambda 식을 이용하여 레코드별로 vader_polarity( )를 수행하고 결과를 'vader_preds'에 저장\n",
    "review_df['vader_preds'] = review_df['review'].apply( lambda x : vader_polarity(x, 0.1) )\n",
    "y_target = review_df['sentiment'].values\n",
    "vader_preds = review_df['vader_preds'].values\n",
    "\n",
    "print(confusion_matrix( y_target, vader_preds))\n",
    "print(\"정확도:\", np.round(accuracy_score(y_target , vader_preds),4))\n",
    "print(\"정밀도:\", np.round(precision_score(y_target , vader_preds),4))\n",
    "print(\"재현율:\", np.round(recall_score(y_target, vader_preds),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pattern 패키지를 통한 감성 분석\n",
    "\n",
    "https://www.clips.uantwerpen.be/pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='8.6.'/>\n",
    "\n",
    "## 8.6. 토픽 모델링 - 20 뉴스그룹\n",
    "\n",
    "* 토픽 모델링(Topic Modeling)이란 문서 집합에 숨어 있는 주제를 찾아내는 것이다.\n",
    "* 사람이 수행하는 토픽 모델링은 더 함축적인 의미로 문장을 요약하는 것에 반해, 머신러닝 기반의 토픽 모델은 숨겨진 주제를 효과적으로 표현할 수 있는 중심 단어를 함축적으로 추출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20 뉴스그룹 데이터셋에 토픽 모델링 적용\n",
    "* 20개 주제 중 8개 주제(모토사이클, 야구, 그래픽스, 윈도우, 중동, 기독교, 전자공학, 의학)만 사용\n",
    "* 사이킷런은 LDA(Latent Dirichlet Allocation) 기반의 토픽 모델링을 제공\n",
    "* 텍스트를 Count 기반으로 벡터화 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Shape: (7862, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 의학, 우주 주제를 추출. \n",
    "cats = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
    "        'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med'  ]\n",
    "\n",
    "# 위에서 cats 변수로 기재된 category만 추출. featch_20newsgroups( )의 categories에 cats 입력\n",
    "news_df= fetch_20newsgroups(subset='all',remove=('headers', 'footers', 'quotes'), \n",
    "                            categories=cats, random_state=0)\n",
    "\n",
    "#LDA 는 Count기반의 Vectorizer만 적용합니다.  \n",
    "count_vect = CountVectorizer(max_df=0.95, max_features=1000, min_df=2, stop_words='english', ngram_range=(1,2))\n",
    "feat_vect = count_vect.fit_transform(news_df.data)\n",
    "print('CountVectorizer Shape:', feat_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 토픽의 개수는 50개로 한다. (원래 문서 임베딩이 1000차원임을 감안)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=50, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=50, random_state=0)\n",
    "lda.fit(feat_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문서 기준에서는 각 문서 임베딩을 이제 50 차원으로 표현할 수 있게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 토픽 기준에서는 각 토픽마다 1000개의 word 피처와 해당 토픽 사이의 연관도 값을 가진다.\n",
    "   * 즉, components_array의 3번째 row, 10번째 col에 있는 값은 <br>\n",
    "     3번째 토픽에 대해서 피처 벡터화된 행렬에 10번째 칼럼에 해당하는 피처가 <br>\n",
    "     3번째 토픽에 연관되는 수치 값을 가진다. (일종의 해당 word가 해당 토픽에 열마나 연관있는지에 대한 점수라 볼 수 있음)\n",
    "   * lda_model.components_ 값만으로는 각 토픽별 word 연관도를 보기 어렵다. <br>\n",
    "     display_topics() 함수를 정의해서 각 토픽별로 연관도가 높은 순으로 word를 나열해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.97655679e+01, 6.77813814e+01, 5.12264658e+00, ...,\n",
       "        2.00000000e-02, 6.06076574e-01, 1.34933645e+01],\n",
       "       [2.00000000e-02, 2.00000000e-02, 2.00000000e-02, ...,\n",
       "        2.00000000e-02, 2.00000000e-02, 2.00000000e-02],\n",
       "       [2.00000000e-02, 2.00000000e-02, 2.00000000e-02, ...,\n",
       "        4.52327875e+00, 2.00000000e-02, 2.00000000e-02],\n",
       "       ...,\n",
       "       [1.13438745e+00, 1.37674013e+01, 2.00000000e-02, ...,\n",
       "        2.00000000e-02, 2.22180080e+02, 6.93756191e+00],\n",
       "       [2.00000000e-02, 2.34927520e+01, 2.00000000e-02, ...,\n",
       "        2.00000000e-02, 6.40363130e-01, 1.07243758e+00],\n",
       "       [2.00000000e-02, 2.00000000e-02, 2.00000000e-02, ...,\n",
       "        5.37015233e-01, 2.00000000e-02, 3.05567918e+00]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lda.components_.shape)\n",
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic # 0\n",
      "year 10 game medical health team 12 20 disease cancer 1993 games years patients good\n",
      "Topic # 1\n",
      "don just like know people said think time ve didn right going say ll way\n",
      "Topic # 2\n",
      "image file jpeg program gif images output format files color entry 00 use bit 03\n",
      "Topic # 3\n",
      "like know don think use does just good time book read information people used post\n",
      "Topic # 4\n",
      "armenian israel armenians jews turkish people israeli jewish government war dos dos turkey arab armenia 000\n",
      "Topic # 5\n",
      "edu com available graphics ftp data pub motif mail widget software mit information version sun\n",
      "Topic # 6\n",
      "god people jesus church believe christ does christian say think christians bible faith sin life\n",
      "Topic # 7\n",
      "use dos thanks windows using window does display help like problem server need know run\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        print('Topic #',topic_index)\n",
    "\n",
    "        # components_ array에서 가장 값이 큰 순으로 정렬했을 때, 그 값의 array index를 반환. \n",
    "        topic_word_indexes = topic.argsort()[::-1]\n",
    "        top_indexes=topic_word_indexes[:no_top_words]\n",
    "        \n",
    "        # top_indexes대상인 index별로 feature_names에 해당하는 word feature 추출 후 join으로 concat\n",
    "        feature_concat = ' '.join([feature_names[i] for i in top_indexes])                \n",
    "        print(feature_concat)\n",
    "\n",
    "# CountVectorizer객체내의 전체 word들의 명칭을 get_features_names( )를 통해 추출\n",
    "feature_names = count_vect.get_feature_names()\n",
    "\n",
    "# Topic별 가장 연관도가 높은 word를 15개만 추출\n",
    "display_topics(lda, feature_names, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='8.7.'/>\n",
    "\n",
    "## 8.7. 문서 군집화 실습 - Opinion Review\n",
    "\n",
    "* UCI 머신러닝 레포지토리 - Opinion Revew 데이터셋\n",
    "* https://archive.ics.uci.edu/ml/datasets/Opinosis+Opinion+%26frasl%3B+Review\n",
    "* 51개의 텍스트 파일. 각 파일은 호텔, 자동차, 전자제품 사이트에서 가져온 리뷰 문서이다.\n",
    "* 각 문서는 약 100개 정도의 문장을 가진다.\n",
    "* 원래 토픽 모델링 논문으로 사용된 데이터이지만 여기서는 문서 군집화를 이용해 각 리뷰를 분류해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>short battery life  I moved up from a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Ride seems comfortable and gas mileage fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>We arrived at 23,30 hours and they could n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Great location for tube and we crammed in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Staff are friendly and hel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "1  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "2  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "3  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "4  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "\n",
       "                                        opinion_text  \n",
       "0           short battery life  I moved up from a...  \n",
       "1       Ride seems comfortable and gas mileage fa...  \n",
       "2      We arrived at 23,30 hours and they could n...  \n",
       "3       Great location for tube and we crammed in...  \n",
       "4                      Staff are friendly and hel...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob ,os\n",
    "\n",
    "# 아래는 제 컴퓨터에서 압축 파일을 풀어 놓은 디렉토리이니, 여러분의 디렉토리를 설정해 주십시요  \n",
    "path = r'/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1.0/topics'                     \n",
    "# path로 지정한 디렉토리 밑에 있는 모든 .data 파일들의 파일명을 리스트로 취합\n",
    "all_files = glob.glob(os.path.join(path, \"*.data\"))    \n",
    "filename_list = []\n",
    "opinion_text = []\n",
    "\n",
    "# 개별 파일들의 파일명은 filename_list 리스트로 취합, \n",
    "# 개별 파일들의 파일내용은 DataFrame로딩 후 다시 string으로 변환하여 opinion_text 리스트로 취합 \n",
    "for file_ in all_files:\n",
    "    # 개별 파일을 읽어서 DataFrame으로 생성 \n",
    "    df = pd.read_table(file_,index_col=None, header=0,encoding='latin1')\n",
    "    \n",
    "    # 절대경로로 주어진 file 명을 가공. 만일 Linux에서 수행시에는 아래 \\\\를 / 변경. 맨 마지막 .data 확장자도 제거\n",
    "    filename_ = file_.split('\\\\')[-1]\n",
    "    filename = filename_.split('.')[0]\n",
    "\n",
    "    #파일명 리스트와 파일내용 리스트에 파일명과 파일 내용을 추가. \n",
    "    filename_list.append(filename)\n",
    "    opinion_text.append(df.to_string())\n",
    "\n",
    "# 파일명 리스트와 파일내용 리스트를  DataFrame으로 생성\n",
    "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
    "document_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문서에 tf-idf 형태로 피처 벡터화 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "lemmar = WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmar.lemmatize(token) for token in tokens]\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english' , \\\n",
    "                             ngram_range=(1,2), min_df=0.05, max_df=0.85 )\n",
    "\n",
    "#opinion_text 컬럼값으로 feature vectorization 수행\n",
    "feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* K-평균 군집화 실시 (5개 클러스터로 일단 실시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 5개 집합으로 군집화 수행. 예제를 위해 동일한 클러스터링 결과 도출용 random_state=0 \n",
    "km_cluster = KMeans(n_clusters=5, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label = km_cluster.labels_\n",
    "cluster_centers = km_cluster.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>short battery life  I moved up from a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Ride seems comfortable and gas mileage fa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>We arrived at 23,30 hours and they could n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Great location for tube and we crammed in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Staff are friendly and hel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "1  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "2  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "3  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "4  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "\n",
       "                                        opinion_text  cluster_label  \n",
       "0           short battery life  I moved up from a...              4  \n",
       "1       Ride seems comfortable and gas mileage fa...              3  \n",
       "2      We arrived at 23,30 hours and they could n...              1  \n",
       "3       Great location for tube and we crammed in...              1  \n",
       "4                      Staff are friendly and hel...              1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df['cluster_label'] = cluster_label\n",
    "document_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Mediocre room and service for a very extr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Both of us having worked in tourism for o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The room was packed to capacity with queu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>not customer, oriented hotelvery low servi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The food for our event was deli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename  \\\n",
       "13  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "16  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "17  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "27  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "32  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "13       Mediocre room and service for a very extr...              0  \n",
       "16       Both of us having worked in tourism for o...              0  \n",
       "17       The room was packed to capacity with queu...              0  \n",
       "27      not customer, oriented hotelvery low servi...              0  \n",
       "32                 The food for our event was deli...              0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==0].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>We arrived at 23,30 hours and they could n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Great location for tube and we crammed in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Staff are friendly and hel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The staff at Swissotel were not particula...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>All in all, a normal chain hotel on a nice...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The Swissotel is one of our favorite hotel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The room was not overly big, but clean and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Good Value good location ,  ideal ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Great Location ,  Nice   Rooms ,  Helpless...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The wine reception is a great idea as it i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Parking was expensive but I think this is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename  \\\n",
       "2   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "3   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "4   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "20  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "28  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "30  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "31  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "39  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "46  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "49  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "50  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "2       We arrived at 23,30 hours and they could n...              1  \n",
       "3        Great location for tube and we crammed in...              1  \n",
       "4                       Staff are friendly and hel...              1  \n",
       "20       The staff at Swissotel were not particula...              1  \n",
       "28      All in all, a normal chain hotel on a nice...              1  \n",
       "30      The Swissotel is one of our favorite hotel...              1  \n",
       "31      The room was not overly big, but clean and...              1  \n",
       "39              Good Value good location ,  ideal ...              1  \n",
       "46      Great Location ,  Nice   Rooms ,  Helpless...              1  \n",
       "49      The wine reception is a great idea as it i...              1  \n",
       "50      Parking was expensive but I think this is ...              1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==1].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The voice prompts and maps are wonderful ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>If a case was included, as with the Kindle...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Windows 7 is quite simply faster, more sta...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>In fact, the entire navigation structure h...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Keep in mind that once you get in a room ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>It feels as easy to read as the K1 but doe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>You also get upscale features like spoken ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>I thought it would be fitting to christen ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>As always, the video screen is sharp and b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>I had to uninstall anti, virus and selecte...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Another thing to consider was that I paid $...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>,  I think the new keyboard rivals the gre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>It's fast to acquire satel...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>It is easy to read and when touching the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>A few other things I'd like to point out i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Another feature on the 255w is a display of...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Being able to change the font sizes is aw...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>3 quot  widescreen display was a ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename  \\\n",
       "5   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "41  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "40  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "38  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "37  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "36  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "34  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "26  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "25  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "21  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "19  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "12  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "10  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "8   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "7   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "6   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "44  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "48  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "5        The voice prompts and maps are wonderful ...              2  \n",
       "41      If a case was included, as with the Kindle...              2  \n",
       "40      Windows 7 is quite simply faster, more sta...              2  \n",
       "38      In fact, the entire navigation structure h...              2  \n",
       "37       Keep in mind that once you get in a room ...              2  \n",
       "36      It feels as easy to read as the K1 but doe...              2  \n",
       "34      You also get upscale features like spoken ...              2  \n",
       "26      I thought it would be fitting to christen ...              2  \n",
       "25      As always, the video screen is sharp and b...              2  \n",
       "21      I had to uninstall anti, virus and selecte...              2  \n",
       "19     Another thing to consider was that I paid $...              2  \n",
       "12      ,  I think the new keyboard rivals the gre...              2  \n",
       "10                      It's fast to acquire satel...              2  \n",
       "8         It is easy to read and when touching the...              2  \n",
       "7       A few other things I'd like to point out i...              2  \n",
       "6      Another feature on the 255w is a display of...              2  \n",
       "44       Being able to change the font sizes is aw...              2  \n",
       "48               3 quot  widescreen display was a ...              2  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==2].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Ride seems comfortable and gas mileage fa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Drivers seat not comfortable, the car its...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>First of all, the interior has way too ma...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>After slowing down, transmission has to b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Front seats are very uncomfor...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>It's quiet, get good gas mileage and look...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>I previously owned a Toyota 4Runner which ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Ride seems comfortable and gas mileage fa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>I love the new body style and the interior...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Very happy with my 08 Accord, performance i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename  \\\n",
       "1   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "18  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "22  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "23  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "29  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "35  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "42  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "43  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "45  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "47  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "1        Ride seems comfortable and gas mileage fa...              3  \n",
       "18       Drivers seat not comfortable, the car its...              3  \n",
       "22       First of all, the interior has way too ma...              3  \n",
       "23       After slowing down, transmission has to b...              3  \n",
       "29                   Front seats are very uncomfor...              3  \n",
       "35       It's quiet, get good gas mileage and look...              3  \n",
       "42      I previously owned a Toyota 4Runner which ...              3  \n",
       "43       Ride seems comfortable and gas mileage fa...              3  \n",
       "45      I love the new body style and the interior...              3  \n",
       "47     Very happy with my 08 Accord, performance i...              3  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==3].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>short battery life  I moved up from a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>After I plugged it in to my USB hub on my ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>6GHz 533FSB cpu, glossy display, 3, Cell 2...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>I bought the 8, gig Ipod Nano that has the...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The Eee Super Hybrid Engine utility lets u...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>headphone jack i got a clear case for it a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>, and is very, very acc...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename  \\\n",
       "0   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "9   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "11  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "14  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "15  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "24  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "33  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "0            short battery life  I moved up from a...              4  \n",
       "9       After I plugged it in to my USB hub on my ...              4  \n",
       "11      6GHz 533FSB cpu, glossy display, 3, Cell 2...              4  \n",
       "14      I bought the 8, gig Ipod Nano that has the...              4  \n",
       "15      The Eee Super Hybrid Engine utility lets u...              4  \n",
       "24      headphone jack i got a clear case for it a...              4  \n",
       "33                         , and is very, very acc...              4  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_df[document_df['cluster_label']==4].sort_values(by='filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* K-평균 재실시 (3개로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opinion_text</th>\n",
       "      <th>cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>I love the new body style and the interior...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>First of all, the interior has way too ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>After slowing down, transmission has to b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>I previously owned a Toyota 4Runner which ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Ride seems comfortable and gas mileage fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>It's quiet, get good gas mileage and look...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Drivers seat not comfortable, the car its...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Front seats are very uncomfor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Ride seems comfortable and gas mileage fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Very happy with my 08 Accord, performance i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>not customer, oriented hotelvery low servi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The staff at Swissotel were not particula...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>All in all, a normal chain hotel on a nice...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The Swissotel is one of our favorite hotel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The wine reception is a great idea as it i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The room was not overly big, but clean and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Parking was expensive but I think this is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Both of us having worked in tourism for o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The food for our event was deli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Good Value good location ,  ideal ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Mediocre room and service for a very extr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Great Location ,  Nice   Rooms ,  Helpless...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Staff are friendly and hel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Great location for tube and we crammed in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>We arrived at 23,30 hours and they could n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The room was packed to capacity with queu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>In fact, the entire navigation structure h...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Keep in mind that once you get in a room ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Windows 7 is quite simply faster, more sta...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>It feels as easy to read as the K1 but doe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>If a case was included, as with the Kindle...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Being able to change the font sizes is aw...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>3 quot  widescreen display was a ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>You also get upscale features like spoken ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>short battery life  I moved up from a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>I thought it would be fitting to christen ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>headphone jack i got a clear case for it a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>I had to uninstall anti, virus and selecte...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Another thing to consider was that I paid $...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The Eee Super Hybrid Engine utility lets u...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>I bought the 8, gig Ipod Nano that has the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>,  I think the new keyboard rivals the gre...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>6GHz 533FSB cpu, glossy display, 3, Cell 2...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>It's fast to acquire satel...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>After I plugged it in to my USB hub on my ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>It is easy to read and when touching the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>A few other things I'd like to point out i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>Another feature on the 255w is a display of...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>The voice prompts and maps are wonderful ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>, and is very, very acc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>/Users/gritmind/Dropbox/book/code/pymldg_rev/8...</td>\n",
       "      <td>As always, the video screen is sharp and b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename  \\\n",
       "45  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "22  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "23  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "42  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "43  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "35  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "18  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "29  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "1   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "47  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "27  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "20  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "28  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "30  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "49  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "31  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "50  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "16  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "32  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "39  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "13  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "46  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "4   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "3   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "2   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "17  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "38  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "37  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "40  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "36  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "41  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "44  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "48  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "34  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "0   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "26  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "24  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "21  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "19  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "15  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "14  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "12  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "11  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "10  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "9   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "8   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "7   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "6   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "5   /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "33  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "25  /Users/gritmind/Dropbox/book/code/pymldg_rev/8...   \n",
       "\n",
       "                                         opinion_text  cluster_label  \n",
       "45      I love the new body style and the interior...              0  \n",
       "22       First of all, the interior has way too ma...              0  \n",
       "23       After slowing down, transmission has to b...              0  \n",
       "42      I previously owned a Toyota 4Runner which ...              0  \n",
       "43       Ride seems comfortable and gas mileage fa...              0  \n",
       "35       It's quiet, get good gas mileage and look...              0  \n",
       "18       Drivers seat not comfortable, the car its...              0  \n",
       "29                   Front seats are very uncomfor...              0  \n",
       "1        Ride seems comfortable and gas mileage fa...              0  \n",
       "47     Very happy with my 08 Accord, performance i...              0  \n",
       "27      not customer, oriented hotelvery low servi...              1  \n",
       "20       The staff at Swissotel were not particula...              1  \n",
       "28      All in all, a normal chain hotel on a nice...              1  \n",
       "30      The Swissotel is one of our favorite hotel...              1  \n",
       "49      The wine reception is a great idea as it i...              1  \n",
       "31      The room was not overly big, but clean and...              1  \n",
       "50      Parking was expensive but I think this is ...              1  \n",
       "16       Both of us having worked in tourism for o...              1  \n",
       "32                 The food for our event was deli...              1  \n",
       "39              Good Value good location ,  ideal ...              1  \n",
       "13       Mediocre room and service for a very extr...              1  \n",
       "46      Great Location ,  Nice   Rooms ,  Helpless...              1  \n",
       "4                       Staff are friendly and hel...              1  \n",
       "3        Great location for tube and we crammed in...              1  \n",
       "2       We arrived at 23,30 hours and they could n...              1  \n",
       "17       The room was packed to capacity with queu...              1  \n",
       "38      In fact, the entire navigation structure h...              2  \n",
       "37       Keep in mind that once you get in a room ...              2  \n",
       "40      Windows 7 is quite simply faster, more sta...              2  \n",
       "36      It feels as easy to read as the K1 but doe...              2  \n",
       "41      If a case was included, as with the Kindle...              2  \n",
       "44       Being able to change the font sizes is aw...              2  \n",
       "48               3 quot  widescreen display was a ...              2  \n",
       "34      You also get upscale features like spoken ...              2  \n",
       "0            short battery life  I moved up from a...              2  \n",
       "26      I thought it would be fitting to christen ...              2  \n",
       "24      headphone jack i got a clear case for it a...              2  \n",
       "21      I had to uninstall anti, virus and selecte...              2  \n",
       "19     Another thing to consider was that I paid $...              2  \n",
       "15      The Eee Super Hybrid Engine utility lets u...              2  \n",
       "14      I bought the 8, gig Ipod Nano that has the...              2  \n",
       "12      ,  I think the new keyboard rivals the gre...              2  \n",
       "11      6GHz 533FSB cpu, glossy display, 3, Cell 2...              2  \n",
       "10                      It's fast to acquire satel...              2  \n",
       "9       After I plugged it in to my USB hub on my ...              2  \n",
       "8         It is easy to read and when touching the...              2  \n",
       "7       A few other things I'd like to point out i...              2  \n",
       "6      Another feature on the 255w is a display of...              2  \n",
       "5        The voice prompts and maps are wonderful ...              2  \n",
       "33                         , and is very, very acc...              2  \n",
       "25      As always, the video screen is sharp and b...              2  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 3개의 집합으로 군집화 \n",
    "km_cluster = KMeans(n_clusters=3, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label = km_cluster.labels_\n",
    "\n",
    "\n",
    "# 소속 클러스터를 cluster_label 컬럼으로 할당하고 cluster_label 값으로 정렬\n",
    "document_df['cluster_label'] = cluster_label\n",
    "document_df.sort_values(by='cluster_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 군집별 핵심 단어 추출하기\n",
    "\n",
    "* 각 군집에 속한 문서는 핵심 단어를 주축으로 군집회되어 있을 것이다.\n",
    "* KMeans 객체는 각 군집을 구성하는 단어 피처가 군집의 중심(centroid)을 기준으로 얼마나 가깝게 위치해 있는지 clusters_centers_ 라는 속성으로 제공한다.\n",
    "   * cluster_centers_는 배열로 행은 개별 군집을 열은 개별 피처를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_centers shape : (3, 2409)\n",
      "[[0.         0.00137309 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00170335 0.0025537  ... 0.0032582  0.00349413 0.        ]\n",
      " [0.01819865 0.         0.         ... 0.         0.         0.00471073]]\n"
     ]
    }
   ],
   "source": [
    "cluster_centers = km_cluster.cluster_centers_\n",
    "print('cluster_centers shape :',cluster_centers.shape)\n",
    "print(cluster_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `ndarray의 argsort()[::-1]`를 이용하면 clsuter_centers 배열 내 값이 큰 순으로 정렬된 위치 인덱스 값을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 군집별 top n 핵심단어, 그 단어의 중심 위치 상대값, 대상 파일명들을 반환함. \n",
    "def get_cluster_details(cluster_model, cluster_data, feature_names, clusters_num, top_n_features=10):\n",
    "    cluster_details = {}\n",
    "    \n",
    "    # cluster_centers array 의 값이 큰 순으로 정렬된 index 값을 반환\n",
    "    # 군집 중심점(centroid)별 할당된 word 피처들의 거리값이 큰 순으로 값을 구하기 위함.  \n",
    "    centroid_feature_ordered_ind = cluster_model.cluster_centers_.argsort()[:,::-1]\n",
    "    \n",
    "    #개별 군집별로 iteration하면서 핵심단어, 그 단어의 중심 위치 상대값, 대상 파일명 입력\n",
    "    for cluster_num in range(clusters_num):\n",
    "        # 개별 군집별 정보를 담을 데이터 초기화. \n",
    "        cluster_details[cluster_num] = {}\n",
    "        cluster_details[cluster_num]['cluster'] = cluster_num\n",
    "        \n",
    "        # cluster_centers_.argsort()[:,::-1] 로 구한 index 를 이용하여 top n 피처 단어를 구함. \n",
    "        top_feature_indexes = centroid_feature_ordered_ind[cluster_num, :top_n_features]\n",
    "        top_features = [ feature_names[ind] for ind in top_feature_indexes ]\n",
    "        \n",
    "        # top_feature_indexes를 이용해 해당 피처 단어의 중심 위치 상댓값 구함 \n",
    "        top_feature_values = cluster_model.cluster_centers_[cluster_num, top_feature_indexes].tolist()\n",
    "        \n",
    "        # cluster_details 딕셔너리 객체에 개별 군집별 핵심 단어와 중심위치 상대값, 그리고 해당 파일명 입력\n",
    "        cluster_details[cluster_num]['top_features'] = top_features\n",
    "        cluster_details[cluster_num]['top_features_value'] = top_feature_values\n",
    "        filenames = cluster_data[cluster_data['cluster_label'] == cluster_num]['filename']\n",
    "        filenames = filenames.values.tolist()\n",
    "        cluster_details[cluster_num]['filenames'] = filenames\n",
    "        \n",
    "    return cluster_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster_details(cluster_details):\n",
    "    for cluster_num, cluster_detail in cluster_details.items():\n",
    "        print('####### Cluster {0}'.format(cluster_num))\n",
    "        print('Top features:', cluster_detail['top_features'])\n",
    "        print('Reviews 파일명 :',cluster_detail['filenames'][:7])\n",
    "        print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Cluster 0\n",
      "Top features: ['interior', 'seat', 'mileage', 'comfortable', 'car', 'gas', 'transmission', 'gas mileage', 'ride', 'comfort']\n",
      "Reviews 파일명 : ['/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1']\n",
      "==================================================\n",
      "####### Cluster 1\n",
      "Top features: ['room', 'hotel', 'service', 'location', 'staff', 'food', 'clean', 'bathroom', 'parking', 'room wa']\n",
      "Reviews 파일명 : ['/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1']\n",
      "==================================================\n",
      "####### Cluster 2\n",
      "Top features: ['screen', 'battery', 'life', 'battery life', 'keyboard', 'kindle', 'size', 'button', 'easy', 'voice']\n",
      "Reviews 파일명 : ['/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1', '/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf_vect.get_feature_names()\n",
    "\n",
    "cluster_details = get_cluster_details(cluster_model=km_cluster, cluster_data=document_df,\\\n",
    "                                  feature_names=feature_names, clusters_num=3, top_n_features=10 )\n",
    "print_cluster_details(cluster_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='8.8.'/>\n",
    "\n",
    "## 8.8. 문서 유사도\n",
    "\n",
    "* 문서와 문서 간의 유사도 비교는 일반적으로 코사인 유사도(cosine similarity)를 사용한다.\n",
    "* 코사인 유사도는 벡터와 벡터 간의 유사도를 비교할 때 벡터의 크기보다는 벡터의 상호 방향성이 얼마나 유사한지에 기반한다.\n",
    "\n",
    "<img src=\"./images/pic_8_3.png\" width=\"60%\" height=\"60%\">\n",
    "\n",
    "* 코사인 유사도가 문서의 유사도 비교에 가장 많이 사용되는 이유는?\n",
    "   * 문서를 피처 벡터화하면 차원이 매우 많은 희소 행렬이 된다.\n",
    "   * 이러한 희소 행렬 기반에서 문서와 문서 벡터 간의 크기에 기반한 유사도 지표(ex. 유클리디안 거리)는 정확도가 떨어지기 쉽다.\n",
    "   * 또한, 문서가 매우 긴 경우 단어의 빈도수도 더 많을텐데 이러한 빈도수에만 기반해서는 공정한 비교를 할 수 없다.\n",
    "   * 그런데 사실, 0-1 로 정규화를 실시한다면 유클리디안 거리를 사용해도 상관없지 않나?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cos_similarity(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    l2_norm = (np.sqrt(sum(np.square(v1))) * np.sqrt(sum(np.square(v2))))\n",
    "    similarity = dot_product / l2_norm     \n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 18)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "doc_list = ['if you take the blue pill, the story ends' ,\n",
    "            'if you take the red pill, you stay in Wonderland',\n",
    "            'if you take the red pill, I show you how deep the rabbit hole goes']\n",
    "\n",
    "tfidf_vect_simple = TfidfVectorizer()\n",
    "feature_vect_simple = tfidf_vect_simple.fit_transform(doc_list)\n",
    "print(feature_vect_simple.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 1, 문장 2 Cosine 유사도: 0.402\n"
     ]
    }
   ],
   "source": [
    "# TFidfVectorizer로 transform()한 결과는 Sparse Matrix이므로 Dense Matrix로 변환. \n",
    "feature_vect_dense = feature_vect_simple.todense()\n",
    "\n",
    "#첫번째 문장과 두번째 문장의 feature vector  추출\n",
    "vect1 = np.array(feature_vect_dense[0]).reshape(-1,)\n",
    "vect2 = np.array(feature_vect_dense[1]).reshape(-1,)\n",
    "\n",
    "#첫번째 문장과 두번째 문장의 feature vector로 두개 문장의 Cosine 유사도 추출\n",
    "similarity_simple = cos_similarity(vect1, vect2 )\n",
    "print('문장 1, 문장 2 Cosine 유사도: {0:.3f}'.format(similarity_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 1, 문장 3 Cosine 유사도: 0.404\n",
      "문장 2, 문장 3 Cosine 유사도: 0.456\n"
     ]
    }
   ],
   "source": [
    "vect1 = np.array(feature_vect_dense[0]).reshape(-1,)\n",
    "vect3 = np.array(feature_vect_dense[2]).reshape(-1,)\n",
    "similarity_simple = cos_similarity(vect1, vect3 )\n",
    "print('문장 1, 문장 3 Cosine 유사도: {0:.3f}'.format(similarity_simple))\n",
    "\n",
    "vect2 = np.array(feature_vect_dense[1]).reshape(-1,)\n",
    "vect3 = np.array(feature_vect_dense[2]).reshape(-1,)\n",
    "similarity_simple = cos_similarity(vect2, vect3 )\n",
    "print('문장 2, 문장 3 Cosine 유사도: {0:.3f}'.format(similarity_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 사이킷런은 코사인 유사도를 측정하기 위해 sklearn.metrics.pairwise.cosine_similarity API를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.40207758 0.40425045]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_simple_pair = cosine_similarity(feature_vect_simple[0] , feature_vect_simple)\n",
    "print(similarity_simple_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.40207758 0.40425045]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_simple_pair = cosine_similarity(feature_vect_simple[0] , feature_vect_simple[1:])\n",
    "print(similarity_simple_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.40207758 0.40425045]\n",
      " [0.40207758 1.         0.45647296]\n",
      " [0.40425045 0.45647296 1.        ]]\n",
      "shape: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "similarity_simple_pair = cosine_similarity(feature_vect_simple , feature_vect_simple)\n",
    "print(similarity_simple_pair)\n",
    "print('shape:',similarity_simple_pair.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opinion Revew 데이터셋을 이용한 문서 유사도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "lemmar = WordNetLemmatizer()\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    return [lemmar.lemmatize(token) for token in tokens]\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tf-idf 벡터화 & K-평균 군집화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob ,os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "path = r'/Users/gritmind/Dropbox/book/code/pymldg_rev/8장/OpinosisDataset1.0/topics'\n",
    "all_files = glob.glob(os.path.join(path, \"*.data\"))     \n",
    "filename_list = []\n",
    "opinion_text = []\n",
    "\n",
    "for file_ in all_files:\n",
    "    df = pd.read_table(file_,index_col=None, header=0,encoding='latin1')\n",
    "    filename_ = file_.split('/')[-1]\n",
    "    filename = filename_.split('.')[0]\n",
    "    filename_list.append(filename)\n",
    "    opinion_text.append(df.to_string())\n",
    "\n",
    "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english' , \\\n",
    "                             ngram_range=(1,2), min_df=0.05, max_df=0.85 )\n",
    "feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])\n",
    "\n",
    "km_cluster = KMeans(n_clusters=3, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label = km_cluster.labels_\n",
    "cluster_centers = km_cluster.cluster_centers_\n",
    "document_df['cluster_label'] = cluster_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 호텔 군집화 라벨 필터링 & 문서마다 코사인 유사도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호텔로 클러스터링 된 문서들의 DataFrame Index: Int64Index([2, 3, 4, 13, 16, 17, 20, 27, 28, 30, 31, 32, 39, 46, 49, 50], dtype='int64')\n",
      "##### 비교 기준 문서명  room_holiday_inn_london  와 타 문서 유사도######\n",
      "[[1.         0.11953564 0.11947927 0.33260345 0.22157908 0.13280487\n",
      "  0.13191696 0.28864675 0.23102858 0.76564916 0.57253197 0.12728441\n",
      "  0.12431247 0.80339226 0.07076636 0.08047641]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# cluster_label=1인 데이터는 호텔로 클러스터링된 데이터임. DataFrame에서 해당 Index를 추출\n",
    "hotel_indexes = document_df[document_df['cluster_label']==1].index\n",
    "print('호텔로 클러스터링 된 문서들의 DataFrame Index:', hotel_indexes)\n",
    "\n",
    "# 호텔로 클러스터링된 데이터 중 첫번째 문서를 추출하여 파일명 표시.  \n",
    "comparison_docname = document_df.iloc[hotel_indexes[0]]['filename']\n",
    "print('##### 비교 기준 문서명 ',comparison_docname,' 와 타 문서 유사도######')\n",
    "\n",
    "''' document_df에서 추출한 Index 객체를 feature_vect로 입력하여 호텔 클러스터링된 feature_vect 추출 \n",
    "이를 이용하여 호텔로 클러스터링된 문서 중 첫번째 문서와 다른 문서간의 코사인 유사도 측정.'''\n",
    "similarity_pair = cosine_similarity(feature_vect[hotel_indexes[0]] , feature_vect[hotel_indexes])\n",
    "print(similarity_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 문서 간에 유사도가 높은 순으로 정렬 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'room_holiday_inn_london')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# argsort()를 이용하여 앞예제의 첫번째 문서와 타 문서간 유사도가 큰 순으로 정렬한 인덱스 반환하되 자기 자신은 제외. \n",
    "sorted_index = similarity_pair.argsort()[:,::-1]\n",
    "sorted_index = sorted_index[:, 1:]\n",
    "\n",
    "# 유사도가 큰 순으로 hotel_indexes를 추출하여 재 정렬. \n",
    "hotel_sorted_indexes = hotel_indexes[sorted_index.reshape(-1)]\n",
    "\n",
    "# 유사도가 큰 순으로 유사도 값을 재정렬하되 자기 자신은 제외\n",
    "hotel_1_sim_value = np.sort(similarity_pair.reshape(-1))[::-1]\n",
    "hotel_1_sim_value = hotel_1_sim_value[1:]\n",
    "\n",
    "# 유사도가 큰 순으로 정렬된 Index와 유사도값을 이용하여 파일명과 유사도값을 Seaborn 막대 그래프로 시각화\n",
    "hotel_1_sim_df = pd.DataFrame()\n",
    "hotel_1_sim_df['filename'] = document_df.iloc[hotel_sorted_indexes]['filename']\n",
    "hotel_1_sim_df['similarity'] = hotel_1_sim_value\n",
    "\n",
    "sns.barplot(x='similarity', y='filename', data=hotel_1_sim_df)\n",
    "plt.title(comparison_docname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='8.9.'/>\n",
    "\n",
    "## 8.9. 한글 텍스트 처리 - 네이버 영화 평점 감성 분석\n",
    "\n",
    "* 한글 NLP 처리의 어려움\n",
    "   * 띄어쓰기\n",
    "   * 다양한 조사\n",
    "   \n",
    "   \n",
    "* 네이버 영화 평점 데이터\n",
    "   * https://github.com/e9t/nsmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5403919</td>\n",
       "      <td>막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7797314</td>\n",
       "      <td>원작의 긴장감을 제대로 살려내지못했다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9443947</td>\n",
       "      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7156791</td>\n",
       "      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5912145</td>\n",
       "      <td>왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "5   5403919      막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.      0\n",
       "6   7797314                              원작의 긴장감을 제대로 살려내지못했다.      0\n",
       "7   9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...      0\n",
       "8   7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1\n",
       "9   5912145      왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?      1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('nsmc-master/ratings_train.txt', sep='\\t')\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75173\n",
       "1    74827\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 숫자/null은 공백으로 치환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "train_df = train_df.fillna(' ')\n",
    "# 정규 표현식을 이용하여 숫자를 공백으로 변경(정규 표현식으로 \\d 는 숫자를 의미함.) \n",
    "train_df['document'] = train_df['document'].apply( lambda x : re.sub(r\"\\d+\", \" \", x) )\n",
    "\n",
    "# 테스트 데이터 셋을 로딩하고 동일하게 Null 및 숫자를 공백으로 변환\n",
    "test_df = pd.read_csv('nsmc-master/ratings_test.txt', sep='\\t')\n",
    "test_df = test_df.fillna(' ')\n",
    "test_df['document'] = test_df['document'].apply( lambda x : re.sub(r\"\\d+\", \" \", x) )\n",
    "\n",
    "# 개정판 소스 코드 변경(2019.12.24)\n",
    "train_df.drop('id', axis=1, inplace=True) \n",
    "test_df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Twitter 한국어 형태소 분석기 - SNS 분석에 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Twitter\n",
    "\n",
    "twitter = Twitter()\n",
    "def tw_tokenizer(text):\n",
    "    # 입력 인자로 들어온 text 를 형태소 단어로 토큰화 하여 list 객체 반환\n",
    "    tokens_ko = twitter.morphs(text)\n",
    "    return tokens_ko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TFIDF 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Twitter 객체의 morphs( ) 객체를 이용한 tokenizer를 사용. ngram_range는 (1,2) \n",
    "tfidf_vect = TfidfVectorizer(tokenizer=tw_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)\n",
    "tfidf_vect.fit(train_df['document'])\n",
    "tfidf_matrix_train = tfidf_vect.transform(train_df['document'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistic Regression & GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression 을 이용하여 감성 분석 Classification 수행. \n",
    "lg_clf = LogisticRegression(random_state=0)\n",
    "\n",
    "# Parameter C 최적화를 위해 GridSearchCV 를 이용. \n",
    "params = { 'C': [1 ,3.5, 4.5, 5.5, 10 ] }\n",
    "grid_cv = GridSearchCV(lg_clf , param_grid=params , cv=3 ,scoring='accuracy', verbose=1 )\n",
    "grid_cv.fit(tfidf_matrix_train , train_df['label'] )\n",
    "print(grid_cv.best_params_ , round(grid_cv.best_score_,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 테스트 데이터에 학습 데이터로 학습한 tfidf 모델을 적용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 학습 데이터를 적용한 TfidfVectorizer를 이용하여 테스트 데이터를 TF-IDF 값으로 Feature 변환함. \n",
    "tfidf_matrix_test = tfidf_vect.transform(test_df['document'])\n",
    "\n",
    "# classifier 는 GridSearchCV에서 최적 파라미터로 학습된 classifier를 그대로 이용\n",
    "best_estimator = grid_cv.best_estimator_\n",
    "preds = best_estimator.predict(tfidf_matrix_test)\n",
    "\n",
    "print('Logistic Regression 정확도: ',accuracy_score(test_df['label'],preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='8.10.'/>\n",
    "\n",
    "## 8.10. 텍스트 분석 실습 - 캐글 Mercari Price Suggestion Challenge\n",
    "\n",
    "* Mercari Price Suggestion Challenge, 일본의 대형 온라인 쇼핑몰인 Mercari사의 제품에 대해 가격을 예측하는 과제\n",
    "* 제공되는 데이터셋은 제품에 대한 여러 속성 및 제품 설명 등의 텍스트 데이터로 구성\n",
    "* Mercari사는 이러한 데이터를 기반으로 제품 예상 가격을 판매자들에게 제공하고자 함\n",
    "* https://www.kaggle.com/c/mercari-price-suggestion-challenge/data\n",
    "\n",
    "\n",
    "* 제공되는 데이터셋의 속성은 다음과 같다.\n",
    "   * train_id: 데이터 아이디\n",
    "   * name: 제품명\n",
    "   * item_condition_id: 판매자가 제공하는 제품 상태\n",
    "   * category_name: 카테고리 명\n",
    "   * brand_name: 브랜드 이름\n",
    "   * price: 제품 가격. 예측을 위한 타깃 속성\n",
    "   * shipping: 배송비 무료 여부. 1이면 무료(판매자가 지불), 0이면 유료(구매자가 지불)\n",
    "   * item_description: 제품에 대한 설명\n",
    "   \n",
    "   \n",
    "* 회귀로 피처를 학습한 후에 price를 예측하는 문제이다.\n",
    "* Mercari Price Suggestion은 기존 회귀 예제와 다른 점은 item_description과 같은 텍스트 형태의 비정형 데이터와 다른 정형 속성을 같이 적용해 회귀를 수행한다는 점이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482535, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN   35.0   \n",
       "4                            Women/Jewelry/Necklaces        NaN   44.0   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...  \n",
       "4         0          Complete with certificate of authenticity  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge , LogisticRegression\n",
    "from sklearn.model_selection import train_test_split , cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "#mercari_df= pd.read_csv('mercari_train.tsv',sep='\\t')\n",
    "mercari_df= pd.read_csv('mercari-price-suggestion-challenge/train.tsv',sep='\\t')\n",
    "print(mercari_df.shape)\n",
    "mercari_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* brand_name 칼럼이 매우 많은 null 값을 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1482535 entries, 0 to 1482534\n",
      "Data columns (total 8 columns):\n",
      "train_id             1482535 non-null int64\n",
      "name                 1482535 non-null object\n",
      "item_condition_id    1482535 non-null int64\n",
      "category_name        1476208 non-null object\n",
      "brand_name           849853 non-null object\n",
      "price                1482535 non-null float64\n",
      "shipping             1482535 non-null int64\n",
      "item_description     1482531 non-null object\n",
      "dtypes: float64(1), int64(3), object(4)\n",
      "memory usage: 90.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(mercari_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 회귀에서 target 값의 정규 분포도는 매우 중요하다. 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbd612dca50>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "y_train_df = mercari_df['price']\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.distplot(y_train_df,kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 왜곡된 target 분포도에 로그 변환을 시켜주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbc59846350>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_train_df = np.log1p(y_train_df)\n",
    "sns.distplot(y_train_df,kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.397895\n",
       "1    3.970292\n",
       "2    2.397895\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mercari_df['price'] = np.log1p(mercari_df['price'])\n",
    "mercari_df['price'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 피처들의 분포도 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shipping 값 유형:\n",
      " 0    819435\n",
      "1    663100\n",
      "Name: shipping, dtype: int64\n",
      "item_condition_id 값 유형:\n",
      " 1    640549\n",
      "3    432161\n",
      "2    375479\n",
      "4     31962\n",
      "5      2384\n",
      "Name: item_condition_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Shipping 값 유형:\\n',mercari_df['shipping'].value_counts())\n",
    "print('item_condition_id 값 유형:\\n',mercari_df['item_condition_id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* item_decsription은 문자열이므로 null은 다양한 형태로 나타날 수 있다.\n",
    "* null 처리를 하기 전에 null 정규화 작업이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82489"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_cond= mercari_df['item_description']=='No description yet'\n",
    "mercari_df[boolean_cond]['item_description'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 카테고리 명은 대,중,소를 분할하자. (ex. 남자/상의/티셔츠 -> 대분류:남자, 중분류:상의, 소분류:티셔츠)\n",
    "* 아래 apply lambda는 리스트를 반환한다. 리스트의 엘리먼트 하나하나를 변수에 할당하고 싶으면 zip과 `*`를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대분류 유형 :\n",
      " Women                     664385\n",
      "Beauty                    207828\n",
      "Kids                      171689\n",
      "Electronics               122690\n",
      "Men                        93680\n",
      "Home                       67871\n",
      "Vintage & Collectibles     46530\n",
      "Other                      45351\n",
      "Handmade                   30842\n",
      "Sports & Outdoors          25342\n",
      "Other_Null                  6327\n",
      "Name: cat_dae, dtype: int64\n",
      "중분류 갯수 : 114\n",
      "소분류 갯수 : 871\n"
     ]
    }
   ],
   "source": [
    "# apply lambda에서 호출되는 대,중,소 분할 함수 생성, 대,중,소 값을 리스트 반환\n",
    "def split_cat(category_name):\n",
    "    try:\n",
    "        return category_name.split('/')\n",
    "    except: \n",
    "        # category_name이 null인 경우 예외를 발생시킴.\n",
    "        return ['Other_Null' , 'Other_Null' , 'Other_Null']\n",
    "\n",
    "# 위의 split_cat( )을 apply lambda에서 호출하여 대,중,소 컬럼을 mercari_df에 생성. \n",
    "mercari_df['cat_dae'], mercari_df['cat_jung'], mercari_df['cat_so'] = \\\n",
    "                        zip( *mercari_df['category_name'].apply(lambda x : split_cat(x)) )\n",
    "\n",
    "# 대분류만 값의 유형과 건수를 살펴보고, 중분류, 소분류는 값의 유형이 많으므로 분류 갯수만 추출\n",
    "print('대분류 유형 :\\n', mercari_df['cat_dae'].value_counts())\n",
    "print('중분류 갯수 :', mercari_df['cat_jung'].nunique())\n",
    "print('소분류 갯수 :', mercari_df['cat_so'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* null 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_id             0\n",
       "name                 0\n",
       "item_condition_id    0\n",
       "category_name        0\n",
       "brand_name           0\n",
       "price                0\n",
       "shipping             0\n",
       "item_description     0\n",
       "cat_dae              0\n",
       "cat_jung             0\n",
       "cat_so               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mercari_df['brand_name'] = mercari_df['brand_name'].fillna(value='Other_Null')\n",
    "mercari_df['category_name'] = mercari_df['category_name'].fillna(value='Other_Null')\n",
    "mercari_df['item_description'] = mercari_df['item_description'].fillna(value='Other_Null')\n",
    "\n",
    "# 각 컬럼별로 Null값 건수 확인. 모두 0가 나와야 합니다.\n",
    "mercari_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 피처 인코딩과 피처 벡터화\n",
    "\n",
    "* Mercari Price Suggestion에 이용되는 데이터셋은 문자열 칼럼이 많다.\n",
    "* 이 문자열 칼럼 중 레이블 또는 원-핫 인코딩을 수행하거나 피처 벡터화로 변환할 칼럼을 선별해야 한다.\n",
    "* 선형 회귀의 경우 원-핫 인코딩 적용이 훨씬 선호된다. 따라서, 인코딩할 피처는 모두 원-핫 인코딩으로 한다.\n",
    "* 피처 벡터화의 경우\n",
    "   * 비교적 짧은 텍스트의 경우는 Count 기반의 벡터화를\n",
    "   * 비교적 긴 텍스트의 경우는 TF-IDF 기반의 벡터화를 적용하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 브랜드명 원-핫 인코딩 변환 (4810건 정도는 괜찮다. 브랜드명이 매우 많으면 다른 인코딩을 고려해야 한다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brand name 의 유형 건수 : 4810\n",
      "brand name sample 5건 : \n",
      " Other_Null           632682\n",
      "PINK                  54088\n",
      "Nike                  54043\n",
      "Victoria's Secret     48036\n",
      "LuLaRoe               31024\n",
      "Name: brand_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('brand name 의 유형 건수 :', mercari_df['brand_name'].nunique())\n",
    "print('brand name sample 5건 : \\n', mercari_df['brand_name'].value_counts()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전체 중 고유한 상품명은 `1225273/1482535` 이기에 거의 고유한 상품명을 가진다고 볼 수 있다.\n",
    "* Name 속성은 유형이 매우 많고, 적은 단어 위주의 텍스트이므로 Count 기반으로 피처 벡터화를 실시한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 의 종류 갯수 : 1225273\n",
      "name sample 7건 : \n",
      " 0    MLB Cincinnati Reds T Shirt Size XL\n",
      "1       Razer BlackWidow Chroma Keyboard\n",
      "2                         AVA-VIV Blouse\n",
      "3                  Leather Horse Statues\n",
      "4                   24K GOLD plated rose\n",
      "5       Bundled items requested for Ruie\n",
      "6     Acacia pacific tides santorini top\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('name 의 종류 갯수 :', mercari_df['name'].nunique())\n",
    "print('name sample 7건 : \\n', mercari_df['name'][:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* item_description 컬럼의 평균 문자열 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_description 평균 문자열 개수: 145.7113889385411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                              No description yet\n",
       "1    This keyboard is in great condition and works like it came out of the box. All of the ports are tested and work perfectly. The lights are customizable via the Razer Synapse app on your PC.\n",
       "2                                                                    Adorable top with a hint of lace and a key hole in the back! The pale pink is a 1X, and I also have a 3X available in white!\n",
       "Name: item_description, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 200)\n",
    "\n",
    "# item_description의 평균 문자열 개수\n",
    "print('item_description 평균 문자열 개수:',mercari_df['item_description'].str.len().mean())\n",
    "\n",
    "mercari_df['item_description'][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* name 칼럼은 CountVectorizer로, item_description 칼럼은 TfidfVectorizer로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name vectorization shape: (1482535, 105757)\n",
      "item_description vectorization shape: (1482535, 50000)\n"
     ]
    }
   ],
   "source": [
    "# name 속성에 대한 feature vectorization 변환\n",
    "cnt_vec = CountVectorizer()\n",
    "X_name = cnt_vec.fit_transform(mercari_df.name)\n",
    "\n",
    "# item_description 에 대한 feature vectorization 변환 \n",
    "tfidf_descp = TfidfVectorizer(max_features = 50000, ngram_range= (1,3) , stop_words='english')\n",
    "X_descp = tfidf_descp.fit_transform(mercari_df['item_description'])\n",
    "\n",
    "print('name vectorization shape:',X_name.shape)\n",
    "print('item_description vectorization shape:',X_descp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* category_name 칼럼인 대,중,소분류 세 개의 칼럼 모두 원-핫 인코딩 변환\n",
    "* shipping 칼럼 원-핫 인코딩 변환\n",
    "* item_condition 칼럼 원-핫 인코딩 변환\n",
    "\n",
    "\n",
    "* 희소 행렬을 기준으로 피처들을 hstack 함수를 사용해서 결합하자.\n",
    "   * CountVectorizer와 TfidfVectorizer는 원래 희소 행렬로 출력한다.\n",
    "   * LabelBinarizer는 희소 행렬 출력 옵션을 제공한다.\n",
    "   \n",
    "<img src=\"./images/pic_8_4.png\" width=\"80%\" height=\"80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# brand_name, item_condition_id, shipping 각 피처들을 희소 행렬 원-핫 인코딩 변환\n",
    "lb_brand_name= LabelBinarizer(sparse_output=True)\n",
    "X_brand = lb_brand_name.fit_transform(mercari_df['brand_name'])\n",
    "\n",
    "lb_item_cond_id = LabelBinarizer(sparse_output=True)\n",
    "X_item_cond_id = lb_item_cond_id.fit_transform(mercari_df['item_condition_id'])\n",
    "\n",
    "lb_shipping= LabelBinarizer(sparse_output=True)\n",
    "X_shipping = lb_shipping.fit_transform(mercari_df['shipping'])\n",
    "\n",
    "# cat_dae, cat_jung, cat_so 각 피처들을 희소 행렬 원-핫 인코딩 변환\n",
    "lb_cat_dae = LabelBinarizer(sparse_output=True)\n",
    "X_cat_dae= lb_cat_dae.fit_transform(mercari_df['cat_dae'])\n",
    "\n",
    "lb_cat_jung = LabelBinarizer(sparse_output=True)\n",
    "X_cat_jung = lb_cat_jung.fit_transform(mercari_df['cat_jung'])\n",
    "\n",
    "lb_cat_so = LabelBinarizer(sparse_output=True)\n",
    "X_cat_so = lb_cat_so.fit_transform(mercari_df['cat_so'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 인코딩 변환된 데이터셋은 CSR 형태인 csr_matrix 타입이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> <class 'scipy.sparse.csr.csr_matrix'> <class 'scipy.sparse.csr.csr_matrix'>\n",
      "X_brand_shape:(1482535, 4810), X_item_cond_id shape:(1482535, 5)\n",
      "X_shipping shape:(1482535, 1), X_cat_dae shape:(1482535, 11)\n",
      "X_cat_jung shape:(1482535, 114), X_cat_so shape:(1482535, 871)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_brand), type(X_item_cond_id), type(X_shipping))\n",
    "print('X_brand_shape:{0}, X_item_cond_id shape:{1}'.format(X_brand.shape, X_item_cond_id.shape))\n",
    "print('X_shipping shape:{0}, X_cat_dae shape:{1}'.format(X_shipping.shape, X_cat_dae.shape))\n",
    "print('X_cat_jung shape:{0}, X_cat_so shape:{1}'.format(X_cat_jung.shape, X_cat_so.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 여기서는 결합한 데이터의 타입과 크기만 확인하고 메모리에서 삭제한다.\n",
    "* 추후에 다양한 모델을 적용할 때마다 다시 결합해 해당 데이터셋을 이용하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> (1482535, 161569)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  scipy.sparse import hstack\n",
    "import gc\n",
    "\n",
    "sparse_matrix_list = (X_name, X_descp, X_brand, X_item_cond_id,\n",
    "            X_shipping, X_cat_dae, X_cat_jung, X_cat_so)\n",
    "\n",
    "# 사이파이 sparse 모듈의 hstack 함수를 이용하여 앞에서 인코딩과 Vectorization을 수행한 데이터 셋을 모두 결합. \n",
    "X_features_sparse= hstack(sparse_matrix_list).tocsr()\n",
    "print(type(X_features_sparse), X_features_sparse.shape)\n",
    "\n",
    "# 데이터 셋이 메모리를 많이 차지하므로 사용 용도가 끝났으면 바로 메모리에서 삭제. \n",
    "del X_features_sparse\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 릿지 회귀 모델 구축 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RMSLE(Root Mean Sqaure Logarithmic Error)를 따로 정의\n",
    "   * RMSLE는 RMSE와 유사하나 오류 값에 로그를 취한다.\n",
    "   * 낮은 가격보다 높은 가격에서 오류가 발생할 경우 오류 값이 더 커지는 것을 억제하기 위해서 이 방식을 도입\n",
    "* 데이터 전처리에서 왜곡된 타겟 데이터 분포를 보정하기 위해서 로그 변환을 실시하였다. Exponential 변환을 수행해 원복해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y , y_pred):\n",
    "    # underflow, overflow를 막기 위해 log가 아닌 log1p로 rmsle 계산 \n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y) - np.log1p(y_pred), 2)))\n",
    "\n",
    "def evaluate_org_price(y_test , preds): \n",
    "    \n",
    "    # 원본 데이터는 log1p로 변환되었으므로 exmpm1으로 원복 필요. \n",
    "    preds_exmpm = np.expm1(preds)\n",
    "    y_test_exmpm = np.expm1(y_test)\n",
    "    \n",
    "    # rmsle로 RMSLE 값 추출\n",
    "    rmsle_result = rmsle(y_test_exmpm, preds_exmpm)\n",
    "    return rmsle_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hstack 함수로 자질 벡터들을 모두 하나로 결합한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "from  scipy.sparse import hstack\n",
    "\n",
    "def model_train_predict(model,matrix_list):\n",
    "    # scipy.sparse 모듈의 hstack 을 이용하여 sparse matrix 결합\n",
    "    X= hstack(matrix_list).tocsr()     \n",
    "    \n",
    "    X_train, X_test, y_train, y_test=train_test_split(X, mercari_df['price'], \n",
    "                                                      test_size=0.2, random_state=156)\n",
    "    \n",
    "    # 모델 학습 및 예측\n",
    "    model.fit(X_train , y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    del X , X_train , X_test , y_train \n",
    "    gc.collect()\n",
    "    \n",
    "    return preds , y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Item Description을 제외하니까 RMSLE 값이 감소했다. Item Description 영향이 중요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item Description을 제외했을 때 rmsle 값: 0.502163564527728\n",
      "Item Description을 포함한 rmsle 값: 0.47122038109338743\n"
     ]
    }
   ],
   "source": [
    "linear_model = Ridge(solver = \"lsqr\", fit_intercept=False)\n",
    "\n",
    "sparse_matrix_list = (X_name, X_brand, X_item_cond_id,\n",
    "                      X_shipping, X_cat_dae, X_cat_jung, X_cat_so)\n",
    "linear_preds , y_test = model_train_predict(model=linear_model ,matrix_list=sparse_matrix_list)\n",
    "print('Item Description을 제외했을 때 rmsle 값:', evaluate_org_price(y_test , linear_preds))\n",
    "\n",
    "sparse_matrix_list = (X_descp, X_name, X_brand, X_item_cond_id,\n",
    "                      X_shipping, X_cat_dae, X_cat_jung, X_cat_so)\n",
    "linear_preds , y_test = model_train_predict(model=linear_model , matrix_list=sparse_matrix_list)\n",
    "print('Item Description을 포함한 rmsle 값:',  evaluate_org_price(y_test ,linear_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM 회귀 모델 구축과 앙상블을 이용한 최종 예측 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 병렬 지원이 되면 n_estimators를 1000 이상 증가시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM rmsle 값: 0.4571726269143959\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "sparse_matrix_list = (X_descp, X_name, X_brand, X_item_cond_id,\n",
    "                      X_shipping, X_cat_dae, X_cat_jung, X_cat_so)\n",
    "\n",
    "lgbm_model = LGBMRegressor(n_estimators=200, learning_rate=0.5, num_leaves=125, random_state=156)\n",
    "lgbm_preds , y_test = model_train_predict(model = lgbm_model , matrix_list=sparse_matrix_list)\n",
    "print('LightGBM rmsle 값:',  evaluate_org_price(y_test , lgbm_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 릿지와 LightGBM을 심플하게 앙상블해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM과 Ridge를 ensemble한 최종 rmsle 값: 0.4504771916413783\n"
     ]
    }
   ],
   "source": [
    "preds = lgbm_preds * 0.45 + linear_preds * 0.55\n",
    "print('LightGBM과 Ridge를 ensemble한 최종 rmsle 값:',  evaluate_org_price(y_test , preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
