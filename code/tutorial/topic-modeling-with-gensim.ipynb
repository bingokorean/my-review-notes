{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with Gensim\n",
    "\n",
    "Reference: [Machine Learning Plus Blog](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#9createbigramandtrigrammodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the hidden topics from large text corpus, Latent Dirichlet Allocation(LDA) is a popular algorithm. \n",
    "However, **the problem is how to extract good quality of topics that are clear, segregated and meaningful**. This depends heavily on.. \n",
    "   - the quality of text preprocessing\n",
    "   - the strategy of finding the optimal number of topics\n",
    "   \n",
    "### Setting\n",
    " - **Dataset**:20 Newsgroups\n",
    " - **LDA algorithm**: Gensim & Mallet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# # Plotting tools\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA’s approach to topic modeling is it considers each document as a collection of topics in a certain proportion. And each topic as a collection of keywords, again, in a certain proportion. A topic is nothing but a collection of dominant keywords that are typical representatives. Just by looking at the keywords, you can identify what the topic is all about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are key factors to obtaining good segregation topics:\n",
    "\n",
    " - The quality of text processing.\n",
    " - The variety of topics the text talks about.\n",
    " - The choice of topic modeling algorithm.\n",
    " - The number of topics fed to the algorithm.\n",
    " - The algorithms tuning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.autos' 'comp.sys.mac.hardware' 'rec.motorcycles' 'misc.forsale'\n",
      " 'comp.os.ms-windows.misc' 'alt.atheism' 'comp.graphics'\n",
      " 'rec.sport.baseball' 'rec.sport.hockey' 'sci.electronics' 'sci.space'\n",
      " 'talk.politics.misc' 'sci.med' 'talk.politics.mideast'\n",
      " 'soc.religion.christian' 'comp.windows.x' 'comp.sys.ibm.pc.hardware'\n",
      " 'talk.politics.guns' 'talk.religion.misc' 'sci.crypt']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>From: tchen@magnus.acs.ohio-state.edu (Tsung-K...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  target  \\\n",
       "0     From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1     From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "10    From: irwin@cmptrc.lonestar.org (Irwin Arnstei...       8   \n",
       "100   From: tchen@magnus.acs.ohio-state.edu (Tsung-K...       6   \n",
       "1000  From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...       2   \n",
       "\n",
       "                 target_names  \n",
       "0                   rec.autos  \n",
       "1       comp.sys.mac.hardware  \n",
       "10            rec.motorcycles  \n",
       "100              misc.forsale  \n",
       "1000  comp.os.ms-windows.misc  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "\n",
    "# Import Dataset\n",
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "print(df.target_names.unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Remove emails and newline characters\n",
    "\n",
    "As you can see there are many emails, newline and extra spaces that is quite distracting. Let’s get rid of them using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From: (wheres my thing) Subject: WHAT car is this!? Nntp-Posting-Host: '\n",
      " 'rac3.wam.umd.edu Organization: University of Maryland, College Park Lines: '\n",
      " '15 I was wondering if anyone out there could enlighten me on this car I saw '\n",
      " 'the other day. It was a 2-door sports car, looked to be from the late 60s/ '\n",
      " 'early 70s. It was called a Bricklin. The doors were really small. In '\n",
      " 'addition, the front bumper was separate from the rest of the body. This is '\n",
      " 'all I know. If anyone can tellme a model name, engine specs, years of '\n",
      " 'production, where this car is made, history, or whatever info you have on '\n",
      " 'this funky looking car, please e-mail. Thanks, - IL ---- brought to you by '\n",
      " 'your neighborhood Lerxst ---- ']\n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "data = df.content.values.tolist()\n",
    "\n",
    "# Remove Emails\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Tokenize words and Clean-up text\n",
    "\n",
    "Let’s tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether. -> `simple_preprocess()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Create Bi-gram and Tri-gram Models\n",
    "\n",
    "Gensim’s Phrases model can build and implement the bigrams, trigrams, quadgrams and more. The two important arguments to Phrases are min_count and threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\master\\Anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py:316: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp_posting_host', 'rac_wam_umd_edu', 'organization', 'university', 'of', 'maryland_college_park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front_bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Remove Stopwords, Make Bigrams and Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['wheres', 'thing', 'car', 'nntp_posting', 'host', 'rac_wam', 'umd', 'organization', 'university', 'maryland_college', 'park', 'lines', 'wondering', 'anyone', 'could', 'enlighten', 'car', 'saw', 'day', 'door', 'sports', 'car', 'looked', 'late', 'early', 'called', 'bricklin', 'doors', 'really', 'small', 'addition', 'front_bumper', 'separate', 'rest', 'body', 'know', 'anyone', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'production', 'car', 'made', 'history', 'whatever', 'info', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'neighborhood', 'lerxst']]\n"
     ]
    }
   ],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "#nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "#data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "data_lemmatized = data_words_bigrams[:]\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LDA Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Create the Dictionary and Corpus needed for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 5), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wheres'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('wheres', 1),\n",
       "  ('thing', 1),\n",
       "  ('car', 5),\n",
       "  ('nntp_posting', 1),\n",
       "  ('host', 1),\n",
       "  ('rac_wam', 1),\n",
       "  ('umd', 1),\n",
       "  ('organization', 1),\n",
       "  ('university', 1),\n",
       "  ('maryland_college', 1),\n",
       "  ('park', 1),\n",
       "  ('lines', 1),\n",
       "  ('wondering', 1),\n",
       "  ('anyone', 2),\n",
       "  ('could', 1),\n",
       "  ('enlighten', 1),\n",
       "  ('saw', 1),\n",
       "  ('day', 1),\n",
       "  ('door', 1),\n",
       "  ('sports', 1),\n",
       "  ('looked', 1),\n",
       "  ('late', 1),\n",
       "  ('early', 1),\n",
       "  ('called', 1),\n",
       "  ('bricklin', 1),\n",
       "  ('doors', 1),\n",
       "  ('really', 1),\n",
       "  ('small', 1),\n",
       "  ('addition', 1),\n",
       "  ('front_bumper', 1),\n",
       "  ('separate', 1),\n",
       "  ('rest', 1),\n",
       "  ('body', 1),\n",
       "  ('know', 1),\n",
       "  ('tellme', 1),\n",
       "  ('model', 1),\n",
       "  ('name', 1),\n",
       "  ('engine', 1),\n",
       "  ('specs', 1),\n",
       "  ('years', 1),\n",
       "  ('production', 1),\n",
       "  ('made', 1),\n",
       "  ('history', 1),\n",
       "  ('whatever', 1),\n",
       "  ('info', 1),\n",
       "  ('funky', 1),\n",
       "  ('looking', 1),\n",
       "  ('please', 1),\n",
       "  ('mail', 1),\n",
       "  ('thanks', 1),\n",
       "  ('il', 1),\n",
       "  ('brought', 1),\n",
       "  ('neighborhood', 1),\n",
       "  ('lerxst', 1)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Building the Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.019*\"la\" + 0.014*\"pts_pt\" + 0.012*\"case_western\" + 0.012*\"gd\" + '\n",
      "  '0.012*\"reserve_university\" + 0.012*\"illinois\" + 0.010*\"sj\" + 0.009*\"doug\" + '\n",
      "  '0.009*\"la_vs\" + 0.009*\"que\"'),\n",
      " (1,\n",
      "  '0.775*\"ax\" + 0.003*\"printer\" + 0.002*\"compatible\" + 0.002*\"carnegie_mellon\" '\n",
      "  '+ 0.002*\"summer\" + 0.002*\"pa\" + 0.002*\"items\" + 0.002*\"qax\" + 0.002*\"mf\" + '\n",
      "  '0.002*\"ei\"'),\n",
      " (2,\n",
      "  '0.024*\"car\" + 0.013*\"death\" + 0.011*\"power\" + 0.009*\"house\" + 0.009*\"oil\" + '\n",
      "  '0.007*\"international\" + 0.007*\"health\" + 0.007*\"boston\" + 0.007*\"engine\" + '\n",
      "  '0.007*\"water\"'),\n",
      " (3,\n",
      "  '0.021*\"mr_stephanopoulos\" + 0.014*\"israel\" + 0.014*\"president\" + '\n",
      "  '0.012*\"armenians\" + 0.010*\"armenian\" + 0.008*\"said\" + 0.007*\"people\" + '\n",
      "  '0.007*\"jews\" + 0.007*\"israeli\" + 0.007*\"war\"'),\n",
      " (4,\n",
      "  '0.017*\"window\" + 0.013*\"jewish\" + 0.010*\"genocide\" + 0.010*\"nd\" + '\n",
      "  '0.009*\"germany\" + 0.009*\"hockey_league\" + 0.009*\"user\" + 0.007*\"false\" + '\n",
      "  '0.007*\"marriage\" + 0.007*\"deity\"'),\n",
      " (5,\n",
      "  '0.020*\"information\" + 0.013*\"data\" + 0.012*\"sale\" + 0.012*\"program\" + '\n",
      "  '0.012*\"software\" + 0.011*\"mail\" + 0.010*\"standard\" + 0.010*\"ca\" + '\n",
      "  '0.010*\"systems\" + 0.010*\"available\"'),\n",
      " (6,\n",
      "  '0.022*\"team\" + 0.019*\"game\" + 0.015*\"games\" + 0.014*\"year\" + 0.013*\"win\" + '\n",
      "  '0.013*\"nhl\" + 0.012*\"season\" + 0.012*\"players\" + 0.010*\"play\" + '\n",
      "  '0.010*\"teams\"'),\n",
      " (7,\n",
      "  '0.014*\"gun\" + 0.013*\"guns\" + 0.012*\"mark\" + 0.011*\"memory\" + 0.010*\"hd\" + '\n",
      "  '0.008*\"package\" + 0.008*\"specifically\" + 0.007*\"jim\" + 0.007*\"rate\" + '\n",
      "  '0.007*\"cover\"'),\n",
      " (8,\n",
      "  '0.020*\"file\" + 0.016*\"graphics\" + 0.013*\"version\" + 0.013*\"server\" + '\n",
      "  '0.012*\"windows\" + 0.012*\"peter\" + 0.012*\"available\" + 0.011*\"faq\" + '\n",
      "  '0.011*\"works\" + 0.009*\"code\"'),\n",
      " (9,\n",
      "  '0.038*\"god\" + 0.038*\"jesus\" + 0.019*\"christian\" + 0.012*\"bible\" + '\n",
      "  '0.011*\"christians\" + 0.010*\"believe\" + 0.010*\"religion\" + 0.010*\"john\" + '\n",
      "  '0.009*\"faith\" + 0.009*\"life\"'),\n",
      " (10,\n",
      "  '0.049*\"drive\" + 0.024*\"board\" + 0.016*\"monitor\" + 0.014*\"pl\" + 0.014*\"van\" '\n",
      "  '+ 0.013*\"bus\" + 0.010*\"moon\" + 0.008*\"tape\" + 0.008*\"audio\" + '\n",
      "  '0.008*\"drives\"'),\n",
      " (11,\n",
      "  '0.012*\"saw\" + 0.012*\"paul\" + 0.010*\"brian\" + 0.008*\"chicago\" + '\n",
      "  '0.008*\"ground\" + 0.008*\"took\" + 0.008*\"homeopathy\" + 0.007*\"white\" + '\n",
      "  '0.007*\"couldnt\" + 0.007*\"city\"'),\n",
      " (12,\n",
      "  '0.023*\"key\" + 0.017*\"chip\" + 0.012*\"technology\" + 0.012*\"encryption\" + '\n",
      "  '0.010*\"keys\" + 0.010*\"wiretaps\" + 0.009*\"chips\" + 0.008*\"system\" + '\n",
      "  '0.008*\"cal\" + 0.008*\"clipper\"'),\n",
      " (13,\n",
      "  '0.009*\"bike\" + 0.008*\"mine\" + 0.008*\"service\" + 0.007*\"wire\" + '\n",
      "  '0.006*\"normal\" + 0.006*\"wiring\" + 0.006*\"disk\" + 0.005*\"cause\" + '\n",
      "  '0.005*\"medical\" + 0.005*\"san_jose\"'),\n",
      " (14,\n",
      "  '0.009*\"one\" + 0.007*\"book\" + 0.006*\"claim\" + 0.006*\"word\" + 0.006*\"true\" + '\n",
      "  '0.006*\"may\" + 0.006*\"evidence\" + 0.006*\"truth\" + 0.005*\"exist\" + '\n",
      "  '0.005*\"fact\"'),\n",
      " (15,\n",
      "  '0.025*\"space\" + 0.012*\"year\" + 0.009*\"first\" + 0.005*\"cars\" + '\n",
      "  '0.005*\"period\" + 0.005*\"baseball\" + 0.005*\"league\" + 0.004*\"three\" + '\n",
      "  '0.004*\"mcgill\" + 0.004*\"series\"'),\n",
      " (16,\n",
      "  '0.050*\"lines\" + 0.048*\"organization\" + 0.022*\"university\" + 0.021*\"article\" '\n",
      "  '+ 0.020*\"nntp_posting\" + 0.018*\"writes\" + 0.018*\"host\" + 0.012*\"anyone\" + '\n",
      "  '0.010*\"reply\" + 0.009*\"like\"'),\n",
      " (17,\n",
      "  '0.023*\"would\" + 0.018*\"dont\" + 0.017*\"one\" + 0.012*\"think\" + 0.012*\"know\" + '\n",
      "  '0.011*\"like\" + 0.010*\"people\" + 0.010*\"writes\" + 0.010*\"time\" + '\n",
      "  '0.010*\"well\"'),\n",
      " (18,\n",
      "  '0.010*\"law\" + 0.008*\"government\" + 0.007*\"state\" + 0.006*\"national\" + '\n",
      "  '0.006*\"public\" + 0.005*\"new\" + 0.005*\"also\" + 0.005*\"may\" + 0.005*\"us\" + '\n",
      "  '0.005*\"system\"'),\n",
      " (19,\n",
      "  '0.052*\"max\" + 0.014*\"card\" + 0.012*\"windows\" + 0.012*\"system\" + 0.010*\"bit\" '\n",
      "  '+ 0.009*\"cards\" + 0.008*\"problem\" + 0.007*\"color\" + 0.007*\"mb\" + '\n",
      "  '0.007*\"using\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Compute Model Perplexity and Coherence Score\n",
    "\n",
    "Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is. In my experience, topic coherence score, in particular, has been more helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -9.33715881722557\n",
      "\n",
      "Coherence Score:  0.489323634137474\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Visualize the topics-keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyLDAvis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-5a7d0ed8dcbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize the topics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mvis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pyLDAvis' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant. <br>\n",
    "Given our prior knowledge of the number of natural topics in the document, finding the best model was fairly straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Building LDA Mallet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "#mallet_path = 'path/to/mallet-2.0.8/bin/mallet' # update this path\n",
    "mallet_path = 'C:/Users/master/Desktop/mallet-2.0.8/bin/mallet'\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by changing the LDA algorithm, we increased the coherence score from .53 to .63. Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Find the optimal number of topics for LDA\n",
    "\n",
    "We need to pick the number of topics, k, that gives the highest coherence value. <br>\n",
    "Choosing a ‘k’ that marks the end of a rapid growth of topic coherence usually offers meaningful and interpretable topics. Picking an even higher value can sometimes provide more granular sub-topics. <br>\n",
    "If you see the same keywords being repeated in multiple topics, it’s probably a sign that the ‘k’ is too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        #model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl4VPX1+PH3SUgIOwTCGiAJe0DW\ngOwqblApWlHcEWWz31JarVpt1bZYW+tW7U+rbC5gq2xWwQ1QUUBBCUhAwhbCkghCSNgDhCTn98fc\n6BgDGWAmd2ZyXs8zD7l37nIYZU4+937uOaKqGGOMMWcS4XYAxhhjgp8lC2OMMeWyZGGMMaZcliyM\nMcaUy5KFMcaYclmyMMYYUy5LFsYYY8plycIYY0y5LFkYY4wpVxW3A/CXBg0aaEJCgtthGGNMSFm9\nevV+VY0rb7uwSRYJCQmkpqa6HYYxxoQUEdnpy3Z2GcoYY0y5LFkYY4wplyULY4wx5QqbexbGGOOm\nU6dOkZ2dzYkTJ9wOpUwxMTHEx8cTFRV1TvtbsjDGGD/Izs6mVq1aJCQkICJuh/Mjqkpubi7Z2dkk\nJiae0zHsMpQxxvjBiRMnqF+/ftAlCgARoX79+uc16rFkYYwxfhKMiaLE+cZmySKM5Bw5yaxVuygs\nKnY7FGNMmLF7FmEi+0A+t077kh25+eQcOcmEQW3cDskYE0ZsZBEGtu8/xoiXVpB7rIDeSbE89/FW\nNuw+5HZYxpgwYskixG3cc5jrX1rBicJi3hjbmxdv6UHd6tHcMyuNk4VFbodnjKlAM2bMoHPnznTp\n0oXbbrvNr8e2y1AhbG3WQW5/+SuqRUXy+pjetG5YE4AnhnfmjldX8cziLTw4pIPLURpT+fxlwQbS\ndx/26zGTm9bmTz/veNr3N2zYwGOPPcbnn39OgwYNyMvL8+v5bWQRolZm5nLL1JXUrlaFOXf1+T5R\nAFzSviE39mzOlKWZpO7w7/8wxpjg9Mknn3DdddfRoEEDAGJjY/16fBtZhKAlm/Zx1+uraR5bnddH\nX0jjOjE/2eahocksz9jP7+ak8f7EAdSoav+pjakoZxoBBIqqBnTqro0sQsx76/YwbmYqrRvWZNa4\n3mUmCoCaVavw1PVd2JWXz98/2FjBURpjKtqll17K7Nmzyc3NBbDLUJXZnNQsfv3GGrrE1+WNcb2p\nX7PqGbfvnVSf0f0SeX3lLj7bklNBURpj3NCxY0f++Mc/ctFFF9GlSxfuuecevx7fkkWIePXz7dw3\ndx19WzVgxuhe1I7xrRjYvVe2o3XDmtw/N41D+acCHKUxxk23334733zzDWlpabz66qt+PXZAk4WI\nDBaRzSKSISIPlPH+KBHJEZG1zmuM13tPiMgGEdkoIv+SYH6OPsBeWJLBnxekc3lyI6bdnkL1aN/v\nP8RERfLMiC7sP1rAn+Z/E8AojTHhLGDJQkQigReAIUAycJOIJJex6SxV7eq8pjn79gX6AZ2BTkBP\n4KJAxRqsVJV/fLiJJxdu5pquTfn3Ld2JiYo86+N0jq/LhEta8/ba3Xywfk8AIjXGhLtAjix6ARmq\nmqmqBcCbwNU+7qtADBANVAWigL0BiTJIFRcrj7yzgRc/3cbNF7bgmRFdiYo89/9cEwa15oJmdfjD\n/9aTc+SkHyM1xpRQVbdDOK3zjS2QyaIZkOW1nO2sK224iKwTkbki0hxAVVcAS4A9zmuhqv5kSo+I\njBORVBFJzckJnxu4hUXF3Ds3jZkrdzJuYBKPXdOJiIjzuwoXFRnBMyO6cKygiAffWhfU/1MbE4pi\nYmLIzc0Nyn9bJf0sYmLKnj3pi0BOvi/r2630p7gAeENVT4rIXcBrwCARaQ10AOKd7RaLyEBVXfqj\ng6lOAaYApKSkBN9/oXNwsrCI37yxlg83fMc9l7fl14Na+23udJtGtbj/ynb89b2NzFmdzYiU5n45\nrjEG4uPjyc7OJlh/cS3plHeuApkssgHvb6N4YLf3Bqqa67U4FfiH8/MvgJWqehRARD4AegM/Shbh\n5nhBEeNfX83SLTk8PDSZ0f3PraPVmdzZL5FF6XuZtCCdvq3qE1+vut/PYUxlFBUVdc5d6EJBIC9D\nrQLaiEiiiEQDNwLzvTcQkSZei8OAkktNu4CLRKSKiEThubkd1k+WHTlxittf/oplW3N4/NoLApIo\nACIihKev74Kqct+cdRQXh8WAzBgTYAFLFqpaCEwAFuL5op+tqhtEZJKIDHM2m+hMj00DJgKjnPVz\ngW3AeiANSFPVBYGK1W0HjhVwy7QvWbPrAP+6sRs39moR0PM1j63OQ0OTWZGZy2srdgT0XMaY8CDB\neDPmXKSkpGhqaqrbYZy1fYdPcOt0T9Oif9/cncuSG1XIeVWVO19dxRfbcnn/NwNoFVez/J2MMWFH\nRFarakp529kT3C7KPpDPiMkryD5wnFdH9aywRAGefrz/GN6ZatGR3DM7zVqxGmPOyJKFSzJzjnL9\nSyvIO1bA62MupG/rBhUeQ8PaMTx6dSfSsg7y4qfbKvz8xpjQYcnCBRv3HGbE5BUUFBbzxrjedG9R\nz7VYft6lKUM7N+G5j7fyzbfWitUYUzZLFhXs610HuGHyCqIiI5g1vg8dm9ZxOyQevboT9WpE87vZ\n1orVGFM2SxYV6Itt+7ll2pfUrR7N7PE/7m7npno1onlieGc27z3CM4u3uB2OMSYIWbKoIJ9s2ssd\nr6yiWd1qzLmrD81jg+thuEvaN+SmXp5WrKusFasxphRLFhXg3XW7GTdjNW0b1WLW+D40qn3u9VkC\n6Y9XJRNfrxq/m53GsZOFbodjjAkiliwCbPaqLCa+8TXdWtTlP2MvJLZGtNshnVbNqlV46rouZB3I\n52/vh/UD88aYs2TJIoBe+Xw7989bR7/WDXjtTt+727npQqcV63++tFasxpgfWLIIAFXl+U+28pcF\n6VzZ8ey727nt3ivb0cZasRpjvFiy8DNV5fEPN/HUoi1c260ZL9zcnapVzr67nZs8rVi7kmutWI0x\nDksWflRcrDz8zjdM/iyTWy5swVPXd6HKeXS3c9MF8XWYMMjTivV9a8VqTKUXmt9kQaiwqJh756Tx\n+spdjL8oib/6obud2351iacV6x//t559R064HY4xxkWWLPzgZGERv/rvGt76+lvuvaItDwxu77fu\ndm7ybsX6h7fWB2W7SGNMxbBkcZ6OFxQx5rVUFm7YyyNDk5kwqE1YJIoSJa1YP9q4jzmrs90Oxxjj\nEksW5+HwiVOMfPlLPs/YzxPDO3NngLrbue3OfolcmBjLpAXpZB/IdzscY4wLLFmco7xjBdwy9Uu+\n3nWQf93UjRE9m5e/U4iKiBCeclqx3jsnzVqxGlMJWbI4B/sOn+CGySvYvPcIU0b2YGjnpm6HFHDN\nY6vz8NBkVmbm8eoXO9wOxxhTwQKaLERksIhsFpEMEXmgjPdHiUiOiKx1XmOc9Zd4rVsrIidE5JpA\nxuqrrLx8rp+8gt0Hj/PqHT0Z1L7iutu57YaezRnUviH/+HATGfuOuh2OMaYCBSxZiEgk8AIwBEgG\nbhKR5DI2naWqXZ3XNABVXVKyDhgE5AOLAhWrr7blHGXE5BUcKOlu16riu9u5SUR4/NoLqBYdye/m\nWCtWYyqTQI4segEZqpqpqgXAm8DV53Cc64APVNXVO6vpuw8z4qUVnCoqZtb4PnRzsbudmxrWjuGv\n11grVmMqm0Ami2ZAltdytrOutOEisk5E5opIWXeJbwTeKOsEIjJORFJFJDUnJ3BF79bsOsCNU1YQ\nXcXT3a5Dk9oBO1coGNq5KT/v0tRasRpTiQQyWZT1sEHpaTQLgARV7Qx8BLz2owOINAEuABaWdQJV\nnaKqKaqaEhcX54eQf+qLjP3cOu1L6tWIZs5dfWgVFxzd7dz26NUdia0RzT2z13LilLViNSbcBTJZ\nZAPeI4V4YLf3Bqqaq6onncWpQI9SxxgB/E9VXSl9+vHGvYx6dRXx9aoxZ3wf4usFV3c7N9WtHs0/\nhndmy96j/NNasRoT9gKZLFYBbUQkUUSi8VxOmu+9gTNyKDEMKN1x5yZOcwkq0Bak7Wb8zNW0b1yL\nWeP60DBIu9u5ydOKtQVTllkrVmPCXcCShaoWAhPwXELaCMxW1Q0iMklEhjmbTRSRDSKSBkwERpXs\nLyIJeEYmnwUqxtOZtWoXE9/8mu4t6vGfMRdSL4i727ntj1d1sFasxlQCEi7F4VJSUjQ1NfW8jzN9\n+XYefTedgW3jmHxrD6pFh1YvCjd8tT2PG6as4KZeLfjbLy5wOxxjzFkQkdWqmlLedvYEt0NV+dfH\nW3n03XSGdGrM1JGWKHzVKzGWMf0T+e+Xu/h08z63wzHGBIAlCzyJ4u8fbOKZxVu4tnsz/t9N3UKu\nu53bfneFpxXr7+ets1asxoShSp8siouVP779DVOWZnJb75Y8dV3odrdzk3cr1kesFasxYafSfyvu\nyD3GO19/yy8vbsWkqzuGfHc7N10QX4dfD2rDO2t38946a8VqTDip4nYAbkuKq8nCuwfaMxR+8n+X\ntOLjTXt56O319EysR8NaNuXYmHBQ6UcWgCUKP/JuxfrgPGvFaky4sGRh/K51Q08r1o837WNOauVt\nxaqqrN6Zx/1z05i2LJMiaxplQlilvwxlAuPOfoksTt/LpHfT6dOqPs1jK8/o7VRRMR988x3Tl28n\nLesgVatEcLKwmPfW7+Gp67tYfTETkmxkYQLCuxXrfXMrRyvWQ/mnePHTbQx8YgkT3/iaw8dPMenq\njqx5+HKeu7ErmTnH+Nlzy5i+fHul+DxMeLEnuE1AzVq1i9/PW8/DQ5MZ3T/R7XACIjPnKK98voO5\nq7M5fqqIvq3qM7p/Ipe0a/ij2XX7Dp/gwbfW8/GmffRKiOXJ6zvTsn4NFyM3xvcnuC1ZmIBSVUa/\nlsrnGft5b+IAWjcMj0swqsqKbblMX76dTzbvIyoigmFdm3Jnv0SSm56+34mqMm/Nt/xlwQaKipUH\nh7Tnlgtb2pRt4xpLFiZo7Dt8giueXUrL2OrM+2XfkH7o8WRhEe+s3c3Ly7ez6bsj1K8RzS29W3Jr\n7xZnNU14z6Hj3D93Hcu27qdf6/o8cV0XmtWtFsDIjSmbJQsTVN5dt5sJ//2aey5vy8RL27gdzlnb\nf/Qkr6/cyesrd7L/aAHtGtVidP9EhnVtSkzUuZWGUVXe+CqLx95LR0R4eGgHRqQ0R8RGGabi+Jos\nfJoNJSLVgBaquvm8IzOV0tDOTVm0YS//+ngrg9o3pFOzOm6H5JNN3x3m5eXbeXvtbgoKi7mkXRyj\n+yfRr3X98/5SFxFuvrAFA9o04L65afx+3no+/OY7/n5tZxrXsYcZTXApd2QhIj8HngKiVTVRRLoC\nk1R12Bl3rGA2sgh+B/MLuOKfS6lbPYr5E/qf82/kgVZcrHy2JYfpy7ezPGM/MVERDO8ezx39EgN2\nz6W4WJmxYgePf7iJ6MgI/jysI7/o1sxGGSbg/HYZSkRWA4OAT1W1m7NundM3O2hYsggNSzbv445X\nVjFuYBJ/+FkHt8P5kfyCQuat+ZZXPt9OZs4xGtWuyu19E7ipZ4sKa4C1ff8x7p2TxuqdB7g8uRF/\n+8UFxNWqWiHnNpWTPy9DFarqIfsNx/jDJe08rVinLsvksg6N6JUY63ZIfHfoBK+t2MF/v9zFoeOn\n6Bxfh+du7MrPLmhCVAXfjE9sUIPZ4/vw8vLtPLloM1f88zMevaYTQzs3rdA4jCnNl5HFdOBj4AFg\nOJ72p1Gqelfgw/OdjSxCx9GThQx5bimC8MFvBlCjqjuFBNZlH2T68u28t24PxapckdyY0QMSSWlZ\nLygu/2TsO8LvZqeRln2Iqzo34dGrOxFrLX6Nn/mzU96vgY7ASeC/wCHgtz4GMVhENotIhog8UMb7\no0QkR0TWOq8xXu+1EJFFIrJRRNKdntwmDNSsWoWnr+9K1oF8Hnt/Y4Weu6hY+WD9Hq578QuGPf85\nH2/cx8g+CXx23yW8dFsPeibEBkWiAE+NrXm/7Mt9V7Zj0YbvuOKfn7Fow3duh2UqqTOOLEQkEnhc\nVe876wN79t0CXA5kA6uAm1Q13WubUUCKqk4oY/9PgcdUdbGI1ASKVTX/dOezkUXo+dv7G5myNJNX\n7ujJJe0aBvRcR06cYtaqLF79YgfZB47TPLYao/omMiIlnloxUQE9tz9s+u4wv5udxobdh7m2WzP+\n9POO1Kke/HGb4OeXexaqWiQiPc4xhl5AhqpmOgG9CVwNpJ9xL8+2yUAVVV3sxHH0HGMwQeyey9vy\n6eZ9/H7uOhbdPZC61f1/iSUrL59XPt/B7NQsjp4spGdCPR66qgOXJzcmMoSemm7fuDZv/6ofz3+S\nwQtLMvh8234eH9454EnWmBK+XIb6WkTmi8htInJtycuH/ZoBWV7L2c660oaLyDoRmSsizZ11bYGD\nIvKWiHwtIk86IxUTRkpaseYdK+CRdzb47biqyqodedw1czUXPbmEGSt2cGmHhsyf0I85d/VlcKcm\nIZUoSkRFRnD35W15+1f9qFMtijteWcXv567jyAnreW4Cz5c7i7FALp7psyUUeKuc/cr611j6mtcC\n4A1VPSkidwGvOeepAgwAugG7gFnAKGD6j04gMg4YB9CiRQsf/iom2HRq5mnF+s+PtnBlx8Zc1bnJ\nOR+roLCY99fv4eXPt7Mu+xB1q0dx10WtGNknIawecuvUrA4Lft2fZz/ayuTPtrE8Yz9PXNeZfq0b\nuB2aCWMBK/chIn2AP6vqlc7ygwCq+vfTbB8J5KlqHRHpjedeycXOe7cBvVX1V6c7n92zCF2nioq5\n7sUv2JWXz8K7B551K9aD+QX858tdzFixg72HT5IUV4M7+yUyvHs81aLDe0C6ZtcB7p2TRmbOMW7t\n3YIHh3RwbXaZCU1+mw0lIvEi8j8R2Scie0VknojE+xDDKqCNiCSKSDRwIzC/1LG9f40cBmz02ree\niMQ5y4Pw4V6HCU1RkRE8PaIr+WfZijVj31H++L/19P77xzy5cDNtGtbilVE9+ejui7i1d8uwTxQA\n3VvU4/2JAxjdP5H/fLmLIc8t48vMXLfDMmHIl19BXsEzZfZ6Z/lWZ93lZ9pJVQtFZAKwEIgEXlbV\nDSIyCUhV1fnARBEZBhQCeXguNZXcWL8X+Fg88xhXA1PP9i9nQkfrhjW5f3B7Hn03ndmpWdzQs+zL\niqrK8oz9TF++nU835xBdJYJrujblzv6JtG98+tLg4SwmKpKHhyZzZcfG3DsnjRunruSOvoncP7hd\n0JZUMaHHl4fy1qpq1/LWuc0uQ4W+4mLl5mkrWZ99iA9/O/BHrVhPnCrinbXf8vLyHWzee4QGNaO5\nrXcCt/RuQYOaVg6jRH5BIY9/sIkZK3aS1KAGT43oQvcW9dwOywQxf9aG+gh4FXjDWXUTcIeqXnq+\nQfqTJYvwkJWXz5DnltGxaW3eGNub3GMFzFy5k/+s3EnusQLaN/6hNHjVKvZb8+l8nrGf++euY8+h\n44wdmMTdl7W1UYYpkz+TRQvgeaAPntlMXwC/UdWd/gjUXyxZhI/Zq7K4f946eiXEsjbrIAVFxVza\nviGj+yfSp9X5lwavLI6cOMVj723kzVVZtGlYk2dGdOWC+NAoDW8qjjU/MiFLVRk/czXLtu7n+pR4\nRvVNICkuPNqxumHJ5n08MG8d+48W8KuLWzFhUBuiq4Rut0LjX/4cWbyGZyRx0FmuBzytqnf6JVI/\nsWQRXgqLiiksVrt04ieH8k/xl3c38Naab0luUpunR3ShQ5PKOSHA/Jg/Cwl2LkkUAKp6AM/DcsYE\nTJXICEsUflSnehTPjOjKlNt6sO/ISYY9v5znP9lKYVGx26GZEOFLsohwRhMAiEgsPrZjNcYElys6\nNmbR3QO5smNjnlq0heEvfkHGviNuh2VCgC/J4mngCxF5VEQexXOD+4nAhmWMCZTYGtE8f3N3Xri5\nO7vy8vnZv5Yz+bNtFBWHx/1LExjlJgtVnYGn6dFeYB9wrarODHRgxpjAuqpzExbdfREXt43j7x9s\nYsTkFWzff8ztsEyQ8qXcRytgm6o+D6wHLhORugGPzBgTcHG1qjL5th48e0NXtu49wpDnlvLK59sp\ntlGGKcWXy1DzgCIRaQ1MAxLxlP8wxoQBEeGabs1YfM9F9Emqz18WpHPT1JVk5Z2215iphHxJFsWq\nWghcCzynqncD515H2hgTlBrVjuHlUT15YnhnNuw+zJXPLuX1lTt9LuxowpsvyeKUiNwEjATeddZZ\nP0djwpCIMKJncxbePZDuLerx0NvfMPLlr9h98LjboRmX+ZIs7sBT6uMxVd0uIonA64ENyxjjpmZ1\nqzFzdC8evaYTq3ce4Mp/LmV2apaNMioxK/dhjDmjXbn53Ds3ja+25zGofUOevbErtWPs4kK48OcT\n3MaYSqxF/eq8ObY3jwxNZsnmfUxdmul2SMYFliyMMeWKiBDu7J/I5R0aMXPlTvILCt0OyVQwn5OF\niNQIZCDGmOA3bmASB/NPMSc12+1QTAXz5aG8viKSjtMfW0S6iMi/Ax6ZMSbo9GhZj24t6jJteaaV\nB6lkfBlZ/BO4EsgFUNU0YKAvBxeRwSKyWUQyROSBMt4fJSI5IrLWeY3xeq/Ia/183/46xphAEhHG\nD0wiK+84Czd853Y4pgL5VD1WVbNKdScrKm8fEYkEXgAuB7KBVSIyX1XTS206S1UnlHGI48HW59sY\nA5cnN6Zl/epMXprJkE6NrXNhJeHLyCJLRPoCKiLRInIvziWpcvQCMlQ1U1ULgDeBq88jVmNMEIiM\nEMb0TyQt6yCrdhxwOxxTQXxJFncBvwKa4RkhdHWWy9MMyPJaznbWlTZcRNaJyFwRae61PkZEUkVk\npYhc48P5jDEV5LoezalXPYopNo220vClRPl+Vb1FVRupakNVvVVVc304dllj09J3xBYACaraGfgI\neM3rvRbOgyI3A8861W9/fAKRcU5CSc3JyfEhJGOMP1SLjuS2Pgl8tHEvGfuOuh2OqQC+zIZ6zbsk\nuYjUE5GXfTh2NuA9UogHdntvoKq5qnrSWZwK9PB6b7fzZybwKWW0clXVKaqaoqopcXFxPoRkjPGX\nkX1aEl0lgunLbXRRGQSyB/cqoI2IJIpINHAj8KNZTSLiXb12GD9Mz60nIlWdnxsA/YDSN8aNMS5q\nULMqw7vHM2/Nt+QcOVn+DiakBawHt1PWfAKwEE8SmK2qG0RkkogMczabKCIbRCQNmAiMctZ3AFKd\n9UuAx8uYRWWMcdmYAYmcKipm5oodbodiAqzcQoIiMhJ4EJjrrLoeTwXaoGqtaoUEjXHH2BmprNqR\nxxcPDKJ6tE+z8U0Q8VshQacH93VYD25jTBlKSoDMXW0lQMKZr7WhNgFvAe8AR0WkReBCMsaEkpSS\nEiDLtlsJkDDmy2yoX+MZVSzG0ynvPX7omGeMqeREhHEDktiVl28lQMKYLxcYfwO08/HZCmNMJXRF\nx8a0iLUSIOHMp3IfwKFAB2KMCV2REcKYAZ4SIKk7rQRIOPIlWWQCn4rIgyJyT8kr0IEZY0LL9U4J\nkMmf2UN64ciXZLELz/2KaKCW18sYY75XLTqS23q35KONe9mWYyVAwo0vD9f9BTyd8lT1WOBDMsaE\nqtv6JPDS0kymLdvO36+9wO1wjB/5Mhuqj3XKM8b4Iq5WSQmQbPYftRIgFeGbbw+RlZcf8PP4chnq\nWc6xU54xpvIZMyCRgsJiZnyxw+1Qwl5RsXLvnDTueHUV5VXjOF8+PZSnqlmlVpXbKc8YUzm1iqvJ\nZR0aMWPlTo4X2FdFIM1alcWm745wz+VtAz5dOZCd8owxldT4i0pKgJT+PdP4y+ETp3h60WZ6JcQy\npFPjgJ8vkJ3yjDGVVErLenRtXpdpy60ESKC8sCSDvPwCHh6aXCEPQZ4xWYhIJHDbOXbKM8ZUUiLC\nuIFJ7MzNZ5GVAPG7Xbn5vLJ8B9d2i+eC+DoVcs4zJgtVLQKurpBIjDFh5UqvEiCBvvla2Tz+4UYi\nI4T7B7ersHP6chnqcxF5XkQGiEj3klfAIzPGhLSSEiBrsw6y2kqA+M1X2/N4f/133HVRKxrVjqmw\n8/pSSLCv8+ckr3UKDPJ/OMaYcHJdj3ieWbyFyUszSUmIdTuckFdcrDz6bjpN6sQwbmBShZ7blye4\nL6mIQIwx4ad6dBVu692S55dksC3nKK3iarodUkh76+tvWf/tIZ69oSvVoiMr9Ny+PMHdSESmi8gH\nznKyiIwOfGjGmHAwsk8CUZERTF++3e1QQlp+QSFPLtxEl+Z1GdalaYWf35d7Fq8CC4GS6LYAv/Xl\n4CIyWEQ2i0iGiDxQxvujRCRHRNY6rzGl3q8tIt+KyPO+nM8YE3w8JUCaMXe1lQA5Hy99lsnewyd5\nZGgHIiIqvl+IL8migarOBooBVLUQH57gdqbdvgAMAZKBm0QkuYxNZ6lqV+c1rdR7jwKf+RCjMSaI\nje6f5CkBsmKn26GEpN0HjzNl6TZ+3qUpPVq6c+/Hl2RxTETq47mpjYj0xrdmSL2ADFXNVNUC4E3O\nYhquiPQAGgGLfN3HGBOcWjf0lACZuWKHlQA5B098uAlV+H0FTpUtzZdkcQ8wH2glIp8DM4Bf+7Bf\nMzxd9kpkO+tKGy4i60Rkrog0BxCRCOBp4L4znUBExolIqoik5uTk+BCSMcYt4wYmccBKgJy1tVkH\neXvtbsYMSCS+XnXX4ig3WajqGuAiPFNoxwMdVXWdD8cu66Ja6SdzFgAJqtoZ+Ah4zVn/f8D7ZRQw\nLB3bFFVNUdWUuLg4H0IyxrilZ0I9ulgJkLOiqkxasIG4WlX55cWtXY3Fp6qzeC4pdQG647n3MNKH\nfbKB5l7L8cBu7w1UNVdVS+54TQV6OD/3ASaIyA7gKWCkiDzuY6zGmCAkIox3SoAsTrcSIL5YsG4P\na3Yd5L4r2lGzqi+PxQVOuWcXkZlAK2AtP9zYVjyXo85kFdBGRBKBb4EbgZtLHbuJqu5xFofhVLNV\n1Vu8thkFpKjqT2ZTGWNCy5UdG9M8thpTlmYyuFMTt8MJaidOFfGPDzaR3KQ2w3vEux2OT09wpwDJ\nepbFXVS1UEQm4Jl2Gwm8rKpv6QjHAAAVI0lEQVQbRGQSkKqq84GJIjIMKATygFFnFb0xJqRERghj\n+ifxp/kbSN2RZ091n8H05dv59uBxnrq+C5EuTJUtTcrLASIyB5joNQIISikpKZqamup2GMaYcuQX\nFNL38U/olRDLlJEpbocTlPYdOcElT35Kv9YNAv4ZichqVS33JKcdWYjIAjyXm2oB6SLyFfD9EzWq\nOswfgRpjKhfvEiCZOUdJshIgP/H0wi0UFBXzh591cDuU753pMtRTFRaFMaZSGdkngcmfZTJt+Xb+\n9osL3A4nqHzz7SFmr85iTP9EEhrUcDuc7512NpSqflbyAjbhGWHUAjY664wx5pzE1arKtd2bMc9K\ngPyIqvLX99KpVz2aCYPauB3Oj/hSSHAE8BVwPTAC+FJErgt0YMaY8DZmQBInC4uZaSVAvrcofS8r\nM/O4+7I21KkW5XY4P+LLcxZ/BHqq6u2qOhLPMxcPBzYsY0y485QAaciMFVYCBOBkYRF/e38jbRrW\n5KZeLdwO5yd8SRYRqrrPaznXx/2MMeaMxg5wSoCsyXY7FNfN+GInO3PzeWhoMlUig+8r1peIPhSR\nhU458VHAe8AHgQ3LGFMZ9EqMpUvzukxfllmpS4DkHj3Jvz7ZysXt4riobXCWLvKlNtR9wGSgM56S\nH1NU9f5AB2aMCX8iwrgBSezIzWdx+l63w3HNsx9tJb+giIeuCp6psqWdNlmISGsR6Qegqm+p6j2q\nejeQKyKtKixCY0xYu7JjI6cEyDa3Q3HFlr1H+O9Xu7jlwha0bljL7XBO60wji2eBI2Wsz3feM8aY\n81YlMoLR/RJZs+sgq3fmuR1OhfvrexupER3Jby9r63YoZ3SmZJFQVilyVU0FEgIWkTGm0hnRszl1\nqkUxZWmm26FUqCWb97F0Sw4TL21DbI1ot8M5ozMli5gzvFfN34EYYyqvkhIgi9L3kplz1O1wKsSp\nomIee28jiQ1qMLJPgtvhlOtMyWKViIwtvVJERgOrAxeSMaYyGtm3JVEREUxfvt3tUCrEG1/tImPf\nUR4c0p7oKsE3Vba0M9WG+i3wPxG5hR+SQwoQDfwi0IEZYyqXhrViuLZ7M+auzuaey9tSv2ZVt0MK\nmEP5p3hm8Rb6tqrP5cmN3A7HJ2eqDbVXVfsCfwF2OK+/qGofVbU2V8YYvxszIJGThcXMCPMSIP/6\nZCuHjp/ioauSEXG/V4Uvym1+pKpLgCUVEIsxppJr3bAWl7ZvyMyVO7nrolZUi450OyS/277/GDNW\n7OCGlOYkN63tdjg+C/4LZcaYSmXcwCTyjhUwL0xLgPzt/Y1ER0ZwzxXBPVW2NEsWxpig0isxli7x\ndZi+fHvYlQD5ImM/i9P38qtBrWlY60wTToNPQJOFiAwWkc0ikiEiD5Tx/igRyRGRtc5rjLO+pYis\ndtZtEJG7AhmnMSZ4iAhjByaxff+xsCoBUlSsTHo3nfh61bizX6Lb4Zy1gCULEYkEXgCGAMnATSKS\nXMams1S1q/Oa5qzbA/RV1a7AhcADItI0ULEaY4LL4I6Nia9XjanLwuchvTmpWWz67ggPDGlPTFTo\n3YsJ5MiiF5ChqpmqWgC8CVzty46qWqCqJe2zqmKXy4ypVKpERjCmfyKrdx4IixIgR08W8tSiLaS0\nrMdVFzRxO5xzEsgv4WZAltdytrOutOEisk5E5opI85KVItJcRNY5x/iHqu4OYKzGmCBzfUr4lAD5\n95IM9h89ycNDQ2eqbGmBTBZlfSKl71YtwFODqjPwEfDa9xuqZjnrWwO3i8hPnlwRkXEikioiqTk5\nOX4M3RjjthpVq3Br7xYsSt/L9v3H3A7nnGXl5TNt+Xau7daMLs3ruh3OOQtkssgGmnstxwM/Gh2o\naq7X5aapQI/SB3FGFBuAAWW8N0VVU1Q1JS4uOBuGGGPO3e19E5wSIKE7unj8w01ECNw3uJ3boZyX\nQCaLVUAbEUkUkWjgRmC+9wYi4n3xbhiw0VkfLyLVnJ/rAf2AzQGM1RgThBrWiuEX3ZoxJzWb3KMn\ny98hyKTuyOO9dXsYP7AVTeqEdv3VgCULVS0EJgAL8SSB2aq6QUQmicgwZ7OJztTYNGAiMMpZ3wH4\n0ln/GfCUqq4PVKzGmOA1dqCnBMjMlaFVAqS4WHn03XQa1a7K+IuS3A7nvJVb7uN8qOr7wPul1j3i\n9fODwINl7LcYTxtXY0wlV1ICZMYKTwmQUJl2+vbab0nLPsQzI7pQPTqgX7UVwqakGmOC3tgQKwGS\nX1DIEx9upnN8Ha7pWtYk0NBjycIYE/QuTIylc3wdpi0LjRIgU5Zm8t3hEzw8NJmIiNCcKluaJQtj\nTNATEcYO8JQA+WhjcJcA2XPoOJM/y+SqC5rQMyHW7XD8xpKFMSYkDOnklAAJ8of0nvxwM0WqPDCk\nvduh+JUlC2NMSKgSGcHo/omk7jzA6p0H3A6nTGlZB3nr628Z3T+R5rHV3Q7HryxZGGNCxginBEgw\nji5UPVNlG9SM5v8ubuV2OH5nycIYEzJKSoAsTP+OHUFWAuT99d+RuvMAv7uiHbViotwOx+8sWRhj\nQsrtfUpKgGx3O5TvnThVxN8/2Ej7xrUYkdK8/B1CkCULY0xIaVg7hmu6NWXO6izyjhW4HQ4AL3++\nnewDx3lkaDKRYTJVtjRLFsaYkDN2QBInThUzc4X7JUByjpzk30u2cVmHRvRt3cDtcALGkoUxJuS0\naVSLQe0bMmPFDk6cKnI1lmcWb+bEqSL+8LPwmipbmiULY0xIGjsgiVyXS4Ck7z7Mm6uyGNkngaS4\nmq7FUREsWRhjQlLvpFguaOYpAVLsQgkQVeWv76VTp1oUv7m0TYWfv6JZsjDGhCQRYdxA90qAfLRx\nH19sy+Xuy9pSp3r4TZUtzZKFMSZkDenUmGZ1q1V4n+6CwmL+9v5GWsXV4OYLW1Toud1iycIYE7Lc\nKgEyc+VOtu8/xkNXJRMVWTm+RivH39IYE7Zu6Nmc2jFVmLasYkYXB44V8NxHWxjYNo6L28VVyDmD\ngSULY0xI85QAacmHG75jZ27gS4A8+9EWjhUU8dBVHRAJzwfwyhLQZCEig0Vks4hkiMgDZbw/SkRy\nRGSt8xrjrO8qIiuc/tzrROSGQMZpjAlto/p6SoBMWxbYEiAZ+47w+pe7uKlXc9o2qhXQcwWbgCUL\nEYkEXgCGAMnATSKSXMams1S1q/Oa5qzLB0aqakdgMPCsiNQNVKzGmNBWUSVAHntvI9WjI7n7srYB\nO0ewCuTIoheQoaqZqloAvAlc7cuOqrpFVbc6P+8G9gGV5+KgMeasjXFKgLy+MjAlQD7bksOSzTlM\nHNSG+jWrBuQcwSyQyaIZkOW1nO2sK224c6lproj8pFyjiPQCooFtgQnTGBMO2jaqxSXt4njtC/+X\nACksKuav76bTsn51RvZt6ddjh4pAJouy7vyUfsxyAZCgqp2Bj4DXfnQAkSbATOAOVS3+yQlExolI\nqoik5uTk+ClsY0yoGjewFbnHCnhrzbd+Pe4bq7LYuu8oDw7pQNUqkX49dqgIZLLIBrxHCvHAbu8N\nVDVXVU86i1OBHiXviUht4D3gIVVdWdYJVHWKqqaoakpcnF2lMqay+6EESKbfSoAcOn6Kfy7ewoWJ\nsVzZsZFfjhmKApksVgFtRCRRRKKBG4H53hs4I4cSw4CNzvpo4H/ADFWdE8AYjTFhREQYOzCJTD+W\nAHn+k60cyC/g4aHJlWqqbGkBSxaqWghMABbiSQKzVXWDiEwSkWHOZhOd6bFpwERglLN+BDAQGOU1\nrbZroGI1xoSPnzklQKb64SG9HfuP8eoXO7i+RzydmtXxQ3Shq0ogD66q7wPvl1r3iNfPDwIPlrHf\n68DrgYzNGBOeSkqATHo3nTW7DtC9Rb1zPtbfP9hIVGQE917Rzo8RhiZ7gtsYE3ZG+KEEyIptuSzc\nsJf/u7gVDWvH+DG60GTJwhgTdmpWrcItvVvy4TfnVgKkqFh59N10mtWtxpgBSQGIMPRYsjDGhKU7\n+iYQGSFMX372JUDmrc4mfc9hfj+kPTFRlXOqbGmWLIwxYalh7Riu6dqM2alZHDiLEiBHTxby5KLN\ndG9Rl593blL+DpWEJQtjTNgaO9BTAmTmWZQAeenTbeQcOVnpp8qWZsnCGBO2zrYESPaBfKYsy+Tq\nrk3pdh6zqMKRJQtjTFgbOzCJ3GMF/O/r8kuA/OPDzUQI/H5w+wqILLRYsjDGhLU+SfXp1Kw2U8sp\nAbJ65wEWpO1m3IAkmtatVoERhgZLFsaYsCYijB2QRGbOMT7etK/MbYqdqbINa1Vl/EWtKjjC0GDJ\nwhgT9q66oImnBMjSsh/SW7BuN2uzDnLfle2oUTWghS1CliULY0zYqxIZwZ39E/lqRx5f7zrwo/eO\nFxTx+Aeb6NSsNsO7x7sUYfCzZGGMqRRu6NmcWjFVflJgcOqyTPYcOsEjQzsSEWFTZU/HkoUxplKo\nWbUKt5YqAbL38Ale/HQbQzo1pldirMsRBjdLFsaYSmOUUwLkZacEyJMLN1NUrDw4pIPLkQU/SxbG\nmEqjUe0Yru7ajNmp2SzdksPc1dnc0T+BFvWrux1a0LNkYYypVMYNTOL4qSLGzkilfo1oJlzS2u2Q\nQoIlC2NMpdK2US0ubhfHycJi7rmiLbViotwOKSTYhGJjTKXz4JAOtGtcixtSmrsdSsiwZGGMqXTa\nNa5lN7XPUkAvQ4nIYBHZLCIZIvJAGe+PEpEcEVnrvMZ4vfehiBwUkXcDGaMxxpjyBWxkISKRwAvA\n5UA2sEpE5qtqeqlNZ6nqhDIO8SRQHRgfqBiNMcb4JpAji15AhqpmqmoB8CZwta87q+rHwJFABWeM\nMcZ3gUwWzYAsr+VsZ11pw0VknYjMFZGzutskIuNEJFVEUnNycs4nVmOMMWcQyGRRVpGV0sXkFwAJ\nqtoZ+Ah47WxOoKpTVDVFVVPi4uLOMUxjjDHlCWSyyAa8RwrxwG7vDVQ1V1VPOotTgR4BjMcYY8w5\nCmSyWAW0EZFEEYkGbgTme28gIk28FocBGwMYjzHGmHMUsNlQqlooIhOAhUAk8LKqbhCRSUCqqs4H\nJorIMKAQyANGlewvIsuA9kBNEckGRqvqwkDFa4wx5vRE9fQ9aUOJiOQAO92OoxwNgP1uB+GDUIkT\nQidWi9O/QiVOCP5YW6pquTd9wyZZhAIRSVXVFLfjKE+oxAmhE6vF6V+hEieEVqxnYoUEjTHGlMuS\nhTHGmHJZsqhYU9wOwEehEieETqwWp3+FSpwQWrGelt2zMMYYUy4bWRhjjCmXJYsKIiI7RGS9U4o9\n1e14SojIyyKyT0S+8VoXKyKLRWSr82c9N2N0Yiorzj+LyLdeJe5/5maMTkzNRWSJiGwUkQ0i8htn\nfVB9pmeIMxg/0xgR+UpE0pxY/+KsTxSRL53PdJbz8G8wxvmqiGz3+ky7uhnnubLLUBVERHYAKaoa\nVPOtRWQgcBSYoaqdnHVPAHmq+rjTh6Seqv4+COP8M3BUVZ9yMzZvTlWCJqq6RkRqAauBa/A8cBo0\nn+kZ4hxB8H2mAtRQ1aMiEgUsB34D3AO8papvishLQJqqvhiEcd4FvKuqc92KzR9sZFHJqepSPE/P\ne7uaH4o6vobnS8RVp4kz6KjqHlVd4/x8BE8Jm2YE2Wd6hjiDjnocdRajnJcCg4CSL+Bg+ExPF2dY\nsGRRcRRYJCKrRWSc28GUo5Gq7gHPlwrQ0OV4zmSCU+L+Zbcv7ZQmIglAN+BLgvgzLRUnBOFnKiKR\nIrIW2AcsBrYBB1W10NnkdC0QKlTpOFW15DN9zPlM/ykiVV0M8ZxZsqg4/VS1OzAE+JVzWcWcnxeB\nVkBXYA/wtLvh/EBEagLzgN+q6mG34zmdMuIMys9UVYtUtSue6tW9gLIaaLv+W3zpOEWkE/Agnjp3\nPYFYwNVLuufKkkUFUdXdzp/7gP/h+R8+WO0tqQjs/LnP5XjKpKp7nX+cxXhK3AfFZ+pcr54H/EdV\n33JWB91nWlacwfqZllDVg8CnQG+groiUFEP9SQsEN3nFOdi55KdOO4ZXCLLP1FeWLCqAiNRwbiIi\nIjWAK4BvzryXq+YDtzs/3w6842Isp1WqxP0vCILP1LnJOR3YqKrPeL0VVJ/p6eIM0s80TkTqOj9X\nAy7Dc49lCXCds1kwfKZlxbnJ65cEwXNfxfXP9FzYbKgKICJJeEYT4CkL/19VfczFkL4nIm8AF+Op\njLkX+BPwNjAbaAHsAq5XVVdvLp8mzovxXC5RYAcwvuS+gFtEpD+wDFgPFDur/4DnfkDQfKZniPMm\ngu8z7YznBnYknl9wZ6vqJOff1Zt4Lu18Ddzq1UwtmOL8BIjD0z10LXCX143wkGHJwhhjTLnsMpQx\nxphyWbIwxhhTLksWxhhjymXJwhhjTLksWRhjjCmXJQtTKYmIisjTXsv3OoUJ/XmOO7wqjRbID1WH\nHz+HYzUXkVn+jM+Ys2FTZ02lJCIn8JSz6Kmq+0XkXqCmqv45QOfbQRBWHTbGVzayMJVVIZ52l3eX\nfsPpP3Cd1/JR58+LReQzEZktIltE5HERucXpYbBeRFr5enIRaSAi853icl84NYQQkb+KyGvi6TWx\nVUTudNa3dgrUISJVnIJ03zj7/5+z/kkRSXfW/eN8PhxjSqtS/ibGhK0XgHVO/w5fdcFTxC4PyASm\nqWov8TQP+jXwWx+P8yjwpaoOE5ErgFeBFOe9C4C+QG1gjYi8V2rfXwJNgS6qWiSexkqNgJ8BHVVV\nS8pOGOMvNrIwlZZTZXUGMPEsdlvlFIY7iadM9iJn/Xog4SyO0x+Y6cSxCGjq1A0DeFtVTzhFJ5fi\nqVbq7TLgJVUtcvbPw5O8ioGpIvIL4NhZxGJMuSxZmMruWWA0UMNrXSHOvw2n+Jt3u07v2kPFXsvF\nnN1IXc6wXPpGYullKb1OVU/hGZm8DQwHSo9GjDkvlixMpeb8Vj4bT8IosQPo4fx8NZ6OZ/62FLgF\nQEQuA7JVtWQ0cI2IVBWRBsAAoHTP9kXAL0Uk0tk/1qlqXFtV38VzH6ZbAGI2lZjdszDG0+Bngtfy\nVOAdEfkK+JjAXNJ5BHhFRNbh6S1+h9d7q4APgObAn1R1b0mJe8dkoA2e+y2FeBoWvQu85XRhi8DT\nn9oYv7Gps8YEERH5K7BfVZ91OxZjvNllKGOMMeWykYUxxphy2cjCGGNMuSxZGGOMKZclC2OMMeWy\nZGGMMaZcliyMMcaUy5KFMcaYcv1/iio+gkoySNUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17e23447f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.5668\n",
      "Num Topics = 8  has Coherence Value of 0.5844\n",
      "Num Topics = 14  has Coherence Value of 0.5572\n",
      "Num Topics = 20  has Coherence Value of 0.5654\n",
      "Num Topics = 26  has Coherence Value of 0.5529\n",
      "Num Topics = 32  has Coherence Value of 0.5119\n",
      "Num Topics = 38  has Coherence Value of 0.5447\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the coherence score seems to keep increasing, it may make better sense to pick the model that gave the highest CV before flattening out. This is exactly the case here. (여기선 8이 제일 좋음.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.010*\"writes\" + 0.010*\"organization\" + 0.010*\"lines\" + 0.009*\"article\" + '\n",
      "  '0.006*\"would\" + 0.006*\"dont\" + 0.005*\"university\" + 0.005*\"one\" + '\n",
      "  '0.004*\"like\" + 0.004*\"know\"'),\n",
      " (1,\n",
      "  '0.008*\"lines\" + 0.007*\"organization\" + 0.006*\"article\" + 0.006*\"writes\" + '\n",
      "  '0.004*\"one\" + 0.004*\"scsi\" + 0.004*\"like\" + 0.003*\"would\" + 0.003*\"get\" + '\n",
      "  '0.003*\"time\"'),\n",
      " (2,\n",
      "  '0.008*\"lines\" + 0.008*\"would\" + 0.008*\"organization\" + 0.007*\"writes\" + '\n",
      "  '0.006*\"article\" + 0.005*\"like\" + 0.005*\"one\" + 0.005*\"dont\" + 0.005*\"think\" '\n",
      "  '+ 0.004*\"know\"'),\n",
      " (3,\n",
      "  '0.007*\"lines\" + 0.006*\"organization\" + 0.004*\"one\" + 0.004*\"get\" + '\n",
      "  '0.004*\"car\" + 0.004*\"like\" + 0.003*\"file\" + 0.003*\"would\" + 0.003*\"new\" + '\n",
      "  '0.003*\"article\"'),\n",
      " (4,\n",
      "  '0.006*\"lines\" + 0.005*\"organization\" + 0.004*\"university\" + 0.004*\"games\" + '\n",
      "  '0.003*\"team\" + 0.003*\"la\" + 0.003*\"one\" + 0.003*\"pts_pt\" + 0.002*\"article\" '\n",
      "  '+ 0.002*\"game\"'),\n",
      " (5,\n",
      "  '0.640*\"ax\" + 0.046*\"max\" + 0.003*\"pl\" + 0.001*\"qax\" + 0.001*\"ei\" + '\n",
      "  '0.001*\"qq\" + 0.001*\"mr\" + 0.001*\"mf\" + 0.001*\"di_di\" + 0.001*\"wm\"'),\n",
      " (6,\n",
      "  '0.008*\"people\" + 0.007*\"one\" + 0.005*\"would\" + 0.004*\"said\" + 0.004*\"dont\" '\n",
      "  '+ 0.003*\"know\" + 0.003*\"think\" + 0.003*\"us\" + 0.003*\"even\" + 0.003*\"well\"'),\n",
      " (7,\n",
      "  '0.009*\"lines\" + 0.009*\"organization\" + 0.005*\"one\" + 0.005*\"would\" + '\n",
      "  '0.004*\"writes\" + 0.004*\"article\" + 0.004*\"nntp_posting\" + 0.004*\"also\" + '\n",
      "  '0.003*\"host\" + 0.003*\"system\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[1] # num topics = 8\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Application of LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Finding the dominant topic in each sentence\n",
    "\n",
    "One of the practical application of topic modeling is to determine what topic a given document is about. To find that, we find the topic number that has the highest percentage contribution in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6663</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>From: (wheres my thing) Subject: WHAT car is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6381</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>From: (Guy Kuo) Subject: SI Clock Poll - Final...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7988</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>From: (Irwin Arnstein) Subject: Re: Recommenda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6089</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>From: (Tsung-Kun Chen) Subject: ** Software fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>From: (Don A.B. Lindbergh) Subject: Diamond SS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9424</td>\n",
       "      <td>lines, organization, article, writes, one, scs...</td>\n",
       "      <td>From: (Robert Loper) Subject: Re: SHO and SC N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>From: (Kim Richard Man) Subject: SyQuest 44M c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6397</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>From: (Kirtley Wilson) Subject: Mirosoft Offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>Subject: Re: Dont more innocents die without t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4859</td>\n",
       "      <td>lines, would, organization, writes, article, l...</td>\n",
       "      <td>From: (Jon Livesey) Subject: Re: Genocide is C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             3.0              0.6663   \n",
       "1            1             3.0              0.6381   \n",
       "2            2             3.0              0.7988   \n",
       "3            3             0.0              0.6089   \n",
       "4            4             3.0              0.9775   \n",
       "5            5             1.0              0.9424   \n",
       "6            6             0.0              0.5050   \n",
       "7            7             0.0              0.6397   \n",
       "8            8             6.0              0.9875   \n",
       "9            9             2.0              0.4859   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  lines, organization, one, get, car, like, file...   \n",
       "1  lines, organization, one, get, car, like, file...   \n",
       "2  lines, organization, one, get, car, like, file...   \n",
       "3  writes, organization, lines, article, would, d...   \n",
       "4  lines, organization, one, get, car, like, file...   \n",
       "5  lines, organization, article, writes, one, scs...   \n",
       "6  writes, organization, lines, article, would, d...   \n",
       "7  writes, organization, lines, article, would, d...   \n",
       "8  people, one, would, said, dont, know, think, u...   \n",
       "9  lines, would, organization, writes, article, l...   \n",
       "\n",
       "                                                Text  \n",
       "0  From: (wheres my thing) Subject: WHAT car is t...  \n",
       "1  From: (Guy Kuo) Subject: SI Clock Poll - Final...  \n",
       "2  From: (Irwin Arnstein) Subject: Re: Recommenda...  \n",
       "3  From: (Tsung-Kun Chen) Subject: ** Software fo...  \n",
       "4  From: (Don A.B. Lindbergh) Subject: Diamond SS...  \n",
       "5  From: (Robert Loper) Subject: Re: SHO and SC N...  \n",
       "6  From: (Kim Richard Man) Subject: SyQuest 44M c...  \n",
       "7  From: (Kirtley Wilson) Subject: Mirosoft Offic...  \n",
       "8  Subject: Re: Dont more innocents die without t...  \n",
       "9  From: (Jon Livesey) Subject: Re: Genocide is C...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Find the most representative document for each topic\n",
    "\n",
    "Sometimes just the topic keywords may not be enough to make sense of what a topic is about. So, to help with understanding the topic, you can find the documents a given topic has contributed to the most and infer the topic by reading that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>From: (Foxvog Douglas) Subject: Re: Rewording ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>lines, organization, article, writes, one, scs...</td>\n",
       "      <td>From: (GRUBB) Subject: Re: IDE vs SCSI Organiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>lines, would, organization, writes, article, l...</td>\n",
       "      <td>From: (James David) Subject: Plus minus stat O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>From: (Landon C. Noll) Subject: 10th Internati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>lines, organization, university, games, team, ...</td>\n",
       "      <td>From: (Droopy) Subject: AHL final standings Or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.9952   \n",
       "1        1.0              0.9970   \n",
       "2        2.0              0.9976   \n",
       "3        3.0              0.9993   \n",
       "4        4.0              0.9901   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  writes, organization, lines, article, would, d...   \n",
       "1  lines, organization, article, writes, one, scs...   \n",
       "2  lines, would, organization, writes, article, l...   \n",
       "3  lines, organization, one, get, car, like, file...   \n",
       "4  lines, organization, university, games, team, ...   \n",
       "\n",
       "                                                Text  \n",
       "0  From: (Foxvog Douglas) Subject: Re: Rewording ...  \n",
       "1  From: (GRUBB) Subject: Re: IDE vs SCSI Organiz...  \n",
       "2  From: (James David) Subject: Plus minus stat O...  \n",
       "3  From: (Landon C. Noll) Subject: 10th Internati...  \n",
       "4  From: (Droopy) Subject: AHL final standings Or...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tabular output above actually has 20 rows, one each for a topic. It has the topic number, the keywords, and the most representative document. The Perc_Contribution column is nothing but the percentage contribution of the topic in the given document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Topic distribution across documents\n",
    "\n",
    "Finally, we want to understand the volume and distribution of topics in order to judge how widely it was discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>0.1523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>0.0983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>0.1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>0.1572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>408.0</td>\n",
       "      <td>0.0361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>lines, organization, article, writes, one, scs...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>0.1448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>2394.0</td>\n",
       "      <td>0.2116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>lines, would, organization, writes, article, l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.0</td>\n",
       "      <td>lines, organization, one, would, writes, artic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.0</td>\n",
       "      <td>lines, organization, one, would, writes, artic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>lines, would, organization, writes, article, l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>lines, would, organization, writes, article, l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>lines, would, organization, writes, article, l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0</td>\n",
       "      <td>lines, would, organization, writes, article, l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.0</td>\n",
       "      <td>lines, organization, one, would, writes, artic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>1.0</td>\n",
       "      <td>lines, organization, article, writes, one, scs...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11285</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11286</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11287</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11288</th>\n",
       "      <td>7.0</td>\n",
       "      <td>lines, organization, one, would, writes, artic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11289</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11290</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11291</th>\n",
       "      <td>7.0</td>\n",
       "      <td>lines, organization, one, would, writes, artic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11292</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11293</th>\n",
       "      <td>2.0</td>\n",
       "      <td>lines, would, organization, writes, article, l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11294</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11295</th>\n",
       "      <td>7.0</td>\n",
       "      <td>lines, organization, one, would, writes, artic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11296</th>\n",
       "      <td>7.0</td>\n",
       "      <td>lines, organization, one, would, writes, artic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11297</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11298</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11299</th>\n",
       "      <td>7.0</td>\n",
       "      <td>lines, organization, one, would, writes, artic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11300</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11301</th>\n",
       "      <td>2.0</td>\n",
       "      <td>lines, would, organization, writes, article, l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11302</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11303</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11304</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11305</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11306</th>\n",
       "      <td>7.0</td>\n",
       "      <td>lines, organization, one, would, writes, artic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11307</th>\n",
       "      <td>2.0</td>\n",
       "      <td>lines, would, organization, writes, article, l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11308</th>\n",
       "      <td>6.0</td>\n",
       "      <td>people, one, would, said, dont, know, think, u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>2.0</td>\n",
       "      <td>lines, would, organization, writes, article, l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>3.0</td>\n",
       "      <td>lines, organization, one, get, car, like, file...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>0.0</td>\n",
       "      <td>writes, organization, lines, article, would, d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dominant_Topic                                     Topic_Keywords  \\\n",
       "0                 3.0  lines, organization, one, get, car, like, file...   \n",
       "1                 3.0  lines, organization, one, get, car, like, file...   \n",
       "2                 3.0  lines, organization, one, get, car, like, file...   \n",
       "3                 0.0  writes, organization, lines, article, would, d...   \n",
       "4                 3.0  lines, organization, one, get, car, like, file...   \n",
       "5                 1.0  lines, organization, article, writes, one, scs...   \n",
       "6                 0.0  writes, organization, lines, article, would, d...   \n",
       "7                 0.0  writes, organization, lines, article, would, d...   \n",
       "8                 6.0  people, one, would, said, dont, know, think, u...   \n",
       "9                 2.0  lines, would, organization, writes, article, l...   \n",
       "10                7.0  lines, organization, one, would, writes, artic...   \n",
       "11                0.0  writes, organization, lines, article, would, d...   \n",
       "12                0.0  writes, organization, lines, article, would, d...   \n",
       "13                6.0  people, one, would, said, dont, know, think, u...   \n",
       "14                0.0  writes, organization, lines, article, would, d...   \n",
       "15                0.0  writes, organization, lines, article, would, d...   \n",
       "16                7.0  lines, organization, one, would, writes, artic...   \n",
       "17                0.0  writes, organization, lines, article, would, d...   \n",
       "18                0.0  writes, organization, lines, article, would, d...   \n",
       "19                2.0  lines, would, organization, writes, article, l...   \n",
       "20                2.0  lines, would, organization, writes, article, l...   \n",
       "21                2.0  lines, would, organization, writes, article, l...   \n",
       "22                0.0  writes, organization, lines, article, would, d...   \n",
       "23                6.0  people, one, would, said, dont, know, think, u...   \n",
       "24                2.0  lines, would, organization, writes, article, l...   \n",
       "25                6.0  people, one, would, said, dont, know, think, u...   \n",
       "26                6.0  people, one, would, said, dont, know, think, u...   \n",
       "27                6.0  people, one, would, said, dont, know, think, u...   \n",
       "28                7.0  lines, organization, one, would, writes, artic...   \n",
       "29                3.0  lines, organization, one, get, car, like, file...   \n",
       "...               ...                                                ...   \n",
       "11284             1.0  lines, organization, article, writes, one, scs...   \n",
       "11285             6.0  people, one, would, said, dont, know, think, u...   \n",
       "11286             6.0  people, one, would, said, dont, know, think, u...   \n",
       "11287             6.0  people, one, would, said, dont, know, think, u...   \n",
       "11288             7.0  lines, organization, one, would, writes, artic...   \n",
       "11289             6.0  people, one, would, said, dont, know, think, u...   \n",
       "11290             6.0  people, one, would, said, dont, know, think, u...   \n",
       "11291             7.0  lines, organization, one, would, writes, artic...   \n",
       "11292             0.0  writes, organization, lines, article, would, d...   \n",
       "11293             2.0  lines, would, organization, writes, article, l...   \n",
       "11294             0.0  writes, organization, lines, article, would, d...   \n",
       "11295             7.0  lines, organization, one, would, writes, artic...   \n",
       "11296             7.0  lines, organization, one, would, writes, artic...   \n",
       "11297             6.0  people, one, would, said, dont, know, think, u...   \n",
       "11298             6.0  people, one, would, said, dont, know, think, u...   \n",
       "11299             7.0  lines, organization, one, would, writes, artic...   \n",
       "11300             0.0  writes, organization, lines, article, would, d...   \n",
       "11301             2.0  lines, would, organization, writes, article, l...   \n",
       "11302             3.0  lines, organization, one, get, car, like, file...   \n",
       "11303             6.0  people, one, would, said, dont, know, think, u...   \n",
       "11304             3.0  lines, organization, one, get, car, like, file...   \n",
       "11305             3.0  lines, organization, one, get, car, like, file...   \n",
       "11306             7.0  lines, organization, one, would, writes, artic...   \n",
       "11307             2.0  lines, would, organization, writes, article, l...   \n",
       "11308             6.0  people, one, would, said, dont, know, think, u...   \n",
       "11309             3.0  lines, organization, one, get, car, like, file...   \n",
       "11310             0.0  writes, organization, lines, article, would, d...   \n",
       "11311             2.0  lines, would, organization, writes, article, l...   \n",
       "11312             3.0  lines, organization, one, get, car, like, file...   \n",
       "11313             0.0  writes, organization, lines, article, would, d...   \n",
       "\n",
       "       Num_Documents  Perc_Documents  \n",
       "0             1723.0          0.1523  \n",
       "1             1112.0          0.0983  \n",
       "2             2247.0          0.1986  \n",
       "3             1778.0          0.1572  \n",
       "4              408.0          0.0361  \n",
       "5               14.0          0.0012  \n",
       "6             1638.0          0.1448  \n",
       "7             2394.0          0.2116  \n",
       "8                NaN             NaN  \n",
       "9                NaN             NaN  \n",
       "10               NaN             NaN  \n",
       "11               NaN             NaN  \n",
       "12               NaN             NaN  \n",
       "13               NaN             NaN  \n",
       "14               NaN             NaN  \n",
       "15               NaN             NaN  \n",
       "16               NaN             NaN  \n",
       "17               NaN             NaN  \n",
       "18               NaN             NaN  \n",
       "19               NaN             NaN  \n",
       "20               NaN             NaN  \n",
       "21               NaN             NaN  \n",
       "22               NaN             NaN  \n",
       "23               NaN             NaN  \n",
       "24               NaN             NaN  \n",
       "25               NaN             NaN  \n",
       "26               NaN             NaN  \n",
       "27               NaN             NaN  \n",
       "28               NaN             NaN  \n",
       "29               NaN             NaN  \n",
       "...              ...             ...  \n",
       "11284            NaN             NaN  \n",
       "11285            NaN             NaN  \n",
       "11286            NaN             NaN  \n",
       "11287            NaN             NaN  \n",
       "11288            NaN             NaN  \n",
       "11289            NaN             NaN  \n",
       "11290            NaN             NaN  \n",
       "11291            NaN             NaN  \n",
       "11292            NaN             NaN  \n",
       "11293            NaN             NaN  \n",
       "11294            NaN             NaN  \n",
       "11295            NaN             NaN  \n",
       "11296            NaN             NaN  \n",
       "11297            NaN             NaN  \n",
       "11298            NaN             NaN  \n",
       "11299            NaN             NaN  \n",
       "11300            NaN             NaN  \n",
       "11301            NaN             NaN  \n",
       "11302            NaN             NaN  \n",
       "11303            NaN             NaN  \n",
       "11304            NaN             NaN  \n",
       "11305            NaN             NaN  \n",
       "11306            NaN             NaN  \n",
       "11307            NaN             NaN  \n",
       "11308            NaN             NaN  \n",
       "11309            NaN             NaN  \n",
       "11310            NaN             NaN  \n",
       "11311            NaN             NaN  \n",
       "11312            NaN             NaN  \n",
       "11313            NaN             NaN  \n",
       "\n",
       "[11314 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
