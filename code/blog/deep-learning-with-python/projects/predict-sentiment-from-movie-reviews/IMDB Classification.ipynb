{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "np.random.seed(1) # random seed for reproducibiltiy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "y = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000L,)\n",
      "(50000L,)\n",
      "[0 1]\n",
      "88585\n",
      "(234.75891999999999, 172.91149458735703)\n"
     ]
    }
   ],
   "source": [
    "## SUMMAIZATION\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(np.unique(y))\n",
    "print(len(np.unique(np.hstack(X))))\n",
    "result = map(len, X)\n",
    "print(np.mean(result), np.std(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAFkCAYAAACAUFlOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xed0e4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## PLOT\n",
    "pyplot.subplot(121)\n",
    "pyplot.boxplot(result)\n",
    "pyplot.subplot(122)\n",
    "pyplot.hist(result)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD DATASET with top-words\n",
    "top_words = 5000 # 5000번째 freq 단어들만 로드하겠다 (vocabulary size=5000)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words)\n",
    "\n",
    "## ZERO PADDING\n",
    "max_words = 500 # 하나의 문서는 500개의 단어들까지만 구성하겠다 그 이상은 짜르고 그 이하는 zero-패딩하겠다\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
       "         14,    9,    6,  227,  196,  241,  634,  891,  234,   21,   12,\n",
       "         69,    6,    6,  176,    7,    4,  804, 4658, 2999,  667,   11,\n",
       "         12,   11,   85,  715,    6,  176,    7, 1565,    8, 1108,   10,\n",
       "         10,   12,   16, 1844,    2,   33,  211,   21,   69,   49, 2009,\n",
       "        905,  388,   99,    2,  125,   34,    6,    2, 1274,   33,    4,\n",
       "        130,    7,    4,   22,   15,   16,    2,    8,  650, 1069,   14,\n",
       "         22,    9,   44, 4609,  153,  154,    4,  318,  302, 1051,   23,\n",
       "         14,   22,  122,    6, 2093,  292,   10,   10,  723,    2,    5,\n",
       "          2,    2,   71, 1344, 1576,  156,   11,   68,  251,    5,   36,\n",
       "         92, 4363,  133,  199,  743,  976,  354,    4,   64,  439,    9,\n",
       "       3059,   17,   32,    4,    2,   26,  256,   34,    2,    5,   49,\n",
       "          7,   98,   40, 2345,    2,   43,   92,  168,  147,  474,   40,\n",
       "          8,   67,    6,  796,   97,    7,   14,   20,   19,   32, 2188,\n",
       "        156,   24,   18,    2, 1007,   21,    8,  331,   97,    4,   65,\n",
       "        168,    5,  481,   53, 3084])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하나의 example을 살펴보자\n",
    "# 0이 있는 이유는 500길이로 zero-padding했기 때문이다.\n",
    "# 번호는 vocabulary의 index이다. 위에서 top_words=5000이기 때문에 우리의 voca size는 5000이다\n",
    "X_train[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 하나하나마다 voca size인 5000 dim이 주어지는게 아니고 그냥 numerical value로 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 500, 32)       160000      embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 16000)         0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 250)           4000250     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             251         dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# embedding layer 내부적으로 index numerical value를 voca size만큼의 one-hot encoding을 해주고 난 다음 word embedding을 해준다\n",
    "# Embedding()은 내부적으로 one-hot encoding 과정이 포함되어있다\n",
    "\n",
    "## DESIGN MODEL\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words)) # 32 x 500\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "24s - loss: 0.5366 - acc: 0.6864 - val_loss: 0.2966 - val_acc: 0.8758\n",
      "Epoch 2/2\n",
      "25s - loss: 0.2048 - acc: 0.9208 - val_loss: 0.2982 - val_acc: 0.8764\n",
      "Accuracy: 87.64%\n"
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=2, batch_size=128, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN은 image에서 position and orientation과 같은 spatial structure 패턴을 찾는데 강함. <br>\n",
    "이것을 똑같이 sequence에도 적용가능함. 이들의 성질인 invariance to the specific position of features를 사용해 image에서 object를 찾는 것과 같이 paragraph에서 word를 찾을 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_6 (Embedding)          (None, 500, 32)       160000      embedding_input_6[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 500, 32)       3104        embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 250, 32)       0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 8000)          0           maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 250)           2000250     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             251         dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2,163,605\n",
      "Trainable params: 2,163,605\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "## DESIGN MODEL\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Conv1D(nb_filter=32, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D Convolution이기 때문에 Convolution layer를 거쳤음에도 불구하고 data shape는 embedding layer와 같이 500 x 32로 바뀌지 않았다. Pooling layer에서 압축을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "62s - loss: 0.4378 - acc: 0.7702 - val_loss: 0.2818 - val_acc: 0.8822\n",
      "Epoch 2/2\n",
      "64s - loss: 0.2284 - acc: 0.9082 - val_loss: 0.2747 - val_acc: 0.8832\n",
      "Accuracy: 88.32%\n"
     ]
    }
   ],
   "source": [
    "# TRAIN MODEL\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=2, batch_size=128, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence classification 문제의 어려운 점\n",
    "* sequence들의 길이다 모두 상이하다\n",
    "* large vocabulary size를 가진다\n",
    "* long term context or dependencies를 요구한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_7 (Embedding)          (None, 500, 32)       160000      embedding_input_7[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 100)           53200       embedding_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1)             101         lstm_1[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "## DESIGN MODEL\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN MODEL\n",
    "model.fit(X_train, y_train, nb_epoch=2, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent neural networks like LSTM generally have the problem of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Layer-wise dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_10 (Embedding)         (None, 500, 32)       160000      embedding_input_10[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 500, 32)       0           embedding_10[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 100)           53200       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100)           0           lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 1)             101         dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "## DESIGN MODEL\n",
    "embedding_vecor_length = 32 \n",
    "model = Sequential() \n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_words, dropout=0.2)) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(LSTM(100)) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test, y_test, verbose=0) \n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropout을 적용하면 상대적으로 converge가 느리게 되는데 이전보다 epoch를 좀 더 늘릴 필요가 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) LSTM specific dropout\n",
    "Dropout is applied to input and recurrent connections of the memory units with the LSTM\n",
    "\n",
    "* *dropout_W*: for configuring the input dropout\n",
    "* *dropout_U*: for configuring the recurrent dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_11 (Embedding)         (None, 500, 32)       160000      embedding_input_11[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 100)           53200       embedding_11[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             101         lstm_4[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## DESIGN MODEL\n",
    "embedding_vecor_length = 32 \n",
    "model = Sequential() \n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_words, dropout=0.2)) \n",
    "model.add(LSTM(100, dropout_W=0.2, dropout_U=0.2)) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropout을 하는 방법은 (1), (2)으로 2가지 종류가 있는데, 모두 결과가 (당연히) 다르게 나온다. 똑같은 epoch으로 실험했을 때 (2)의 경우가 accuracy가 더 낮게 나온다 이는 (2)번이 dropout을 더 많이 주는 효과?가 있다고 볼 수 있다 (또는 overfitting을 더 잘 해결할 수도 있다고 해석할 수 있다)\n",
    "\n",
    "즉, LSTM specific dropout이 layer-wise dropout보다 좀 더 좋은 성능을 낼 수도 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM and CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN은 spatial structure를 잘 추출하는데, 2D가 아닌 1D Convolution을 이용하면 image뿐만 아니라 text의 spatial structure도 잘 추출할 수 있다. (text에서 spatial structure는 paragraph에서 특정 word들이라고 말할 수 있다)\n",
    "\n",
    "CNN may be able to pick out invariant features for good and bad sentiment from IMDB. <br>\n",
    "This learned spatial features may then be learned as sequences by an LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_8 (Embedding)          (None, 500, 32)       160000      embedding_input_8[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 500, 32)       3104        embedding_8[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_2 (MaxPooling1D)    (None, 250, 32)       0           convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 100)           53200       maxpooling1d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             101         lstm_2[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 216,405\n",
      "Trainable params: 216,405\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## DESIGN MODEL\n",
    "embedding_vecor_length = 32 \n",
    "model = Sequential() \n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_words)) \n",
    "model.add(Convolution1D(nb_filter=32, filter_length=3, border_mode='same', activation='relu')) \n",
    "model.add(MaxPooling1D(pool_length=2)) \n",
    "model.add(LSTM(100)) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, nb_epoch=3, batch_size=64) \n",
    "# Final evaluation of the model \n",
    "scores = model.evaluate(X_test, y_test, verbose=0) \n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding 다음에 곧바로 CNN Layer를 넣어줘서 학습시간은 좀 더 빠르게 할 수 있다 (simple LSTM모델 보다는 학습 시간이 좀 더 빠르다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
