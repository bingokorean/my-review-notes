# CS224n: Natural Language Processing with Deep Learning

* Stanford CS224N
* Winter 2019
* [Schedule](http://web.stanford.edu/class/cs224n/index.html#schedule)
* [Videos](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)

강의를 듣고 이해한 내용과 저의 생각을 slide의 주석으로 정리했습니다.


## Contents

1. Introduction and Word Vectors [[Annotated Slide](https://github.com/gritmind/review/blob/master/media/class/cs224n-nlp-with-dl/annotated_slides/cs224n-2019-lecture01-wordvecs1_gritmind.pdf)]
2. Word Vectors 2 and Word Senses [[Annotated Slide](https://github.com/gritmind/review/blob/master/media/class/cs224n-nlp-with-dl/annotated_slides/cs224n-2019-lecture02-wordvecs2_gritmind.pdf)]
3. Word Window Classification, Neural Networks, and Maxtrix Calculus [[Annotated Slide](https://github.com/gritmind/review/blob/master/media/class/cs224n-nlp-with-dl/cs224n-2019-lecture03-neuralnets_gritmind.pdf)]
4. Backpropagation and Computation Graphs [[Annotated Slide](https://github.com/gritmind/review/blob/master/media/class/cs224n-nlp-with-dl/cs224n-2019-lecture04-backprop_gritmind.pdf)]
5. Linguistic Structure: Dependency Parsing [[Annotated Slide](https://github.com/gritmind/review/blob/master/media/class/cs224n-nlp-with-dl/cs224n-2019-lecture05-dep-parsing_gritmind.pdf)]
6. The probability of a sentence? Recurrent Neural Networks and Language Models [[Annotated Slide](https://github.com/gritmind/review/blob/master/media/class/cs224n-nlp-with-dl/cs224n-2019-lecture06-rnnlm_grtimind.pdf)]
7. Vanishing Gradients and Fancy RNNs [[Annotated Slide](https://github.com/gritmind/review/blob/master/media/class/cs224n-nlp-with-dl/cs224n-2019-lecture07-fancy-rnn_gritmind.pdf)]
8. Machine Translation, Seq2Seq and Attention [[Annotated Slide](https://github.com/gritmind/review/blob/master/media/class/cs224n-nlp-with-dl/cs224n-2019-lecture08-nmt_gritmind.pdf)]
9. Practical Tips for Final Projects [[Annotated Slide](https://github.com/gritmind/review/blob/master/media/class/cs224n-nlp-with-dl/cs224n-2019-lecture09-final-projects_gritmind.pdf)]
10. Question Answering and the Default Final Project [[Annotated Slide](https://github.com/gritmind/review/blob/master/media/class/cs224n-nlp-with-dl/cs224n-2019-lecture10-QA_gritmind.pdf)]
11. ConvNets for NLP [[Annotated Slide](https://github.com/gritmind/review/blob/master/media/class/cs224n-nlp-with-dl/cs224n-2019-lecture11-convnets_gritmind.pdf)]
12. Information from parts of words: Subword Models
13. Modeling contexts of use: Contextual Representations and Pretraining
14. Transformers and Self-Attention For Generative Models
15. Natural Language Generation
16. Reference in Language and Coreference Resolution
17. Multitask Learning: A general model for NLP?
18. Constituency Parsing and Tree Recursive Neural Networks
19. Safety, Bias, and Fairness
20. Future of NLP + Deep Learning
