{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-014426afa53c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzoom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named tensorflow"
     ]
    }
   ],
   "source": [
    "# EE488C Special Topics in EE <Deep Learning and AlphaGo>, Fall 2016\n",
    "# Information Theory & Machine Learning Lab (http://itml.kaist.ac.kr), School of EE, KAIST\n",
    "# written by Jongmin Yoon \n",
    "# 2016/11/08 \n",
    "\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from scipy.ndimage import zoom\n",
    "import h5py\n",
    "from caffe_classes import class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax\tLabel\n",
      "0.60385\ttiger cat\n",
      "0.26037\ttabby, tabby cat\n",
      "0.09443\tEgyptian cat\n",
      "0.03329\tlynx, catamount\n",
      "0.00271\tPersian cat\n"
     ]
    }
   ],
   "source": [
    "# Open image\n",
    "im1 = Image.open('cat.jpg') # Load a test image 'cat.jpg' 256 x 256 \n",
    "if im1.mode != 'RGB':\n",
    "    im1 = im1.convert('RGB') # Convert it into an RGB image\n",
    "\n",
    "im1 = im1.resize((256, 256), Image.ANTIALIAS)\n",
    "im1 = np.asarray(im1, dtype='float32')\n",
    "im1 /= 255.\n",
    "\n",
    "# Cropping\n",
    "# We obtain 10 images o fsize 227 x 227 by shifting and cropping the image.\n",
    "crop_entry = [[0, 0], [0, 29], [29, 0], [29, 29], [14, 14]]\n",
    "im1_crop = np.empty((10, 227, 227, 3), dtype=np.float32)\n",
    "for k in range(5):\n",
    "    im1_crop[k, :, :, :] = im1[crop_entry[k][0]:crop_entry[k][0] + 227,\n",
    "                               crop_entry[k][1]:crop_entry[k][1] + 227, :]\n",
    "im1_crop[5:10, :, :, :] = im1_crop[0:5, :, ::-1, :]\n",
    "\n",
    "im1_crop = im1_crop[:, :, :, [2, 1, 0]]\n",
    "im1_crop = 255. * im1_crop\n",
    "\n",
    "# Subtract mean\n",
    "mean_file = np.load('ilsvrc_2012_mean.npy').mean(1).mean(1) # https://github.com/BVLC/caffe/blob/master/python/caffe/imagenet/ilsvrc_2012_mean.npy\n",
    "mean_file = np.expand_dims(mean_file, axis=0)\n",
    "mean_file = np.expand_dims(mean_file, axis=0)\n",
    "mean_file = np.expand_dims(mean_file, axis=0)\n",
    "mean_repeat = np.repeat(mean_file, 10, axis=0)\n",
    "mean_repeat = np.repeat(mean_repeat, 227, axis=1)\n",
    "mean_repeat = np.repeat(mean_repeat, 227, axis=2)\n",
    "im1_crop = im1_crop - mean_repeat\n",
    "\n",
    "np.save('im1_cropped.npy', im1_crop)\n",
    "\n",
    "# Constructing AlexNet\n",
    "net_data = np.load(\"bvlc_alexnet.npy\").item()\n",
    "for x in net_data:\n",
    "    exec (\"%s = %s\" % (str(x) + \"W\", \"tf.Variable(net_data[x][0])\"))\n",
    "    exec (\"%s = %s\" % (str(x) + \"b\", \"tf.Variable(net_data[x][1])\"))\n",
    "\n",
    "\n",
    "def conv(input,\n",
    "         kernel,\n",
    "         biases,\n",
    "         k_h,\n",
    "         k_w,\n",
    "         c_o,\n",
    "         s_h,\n",
    "         s_w,\n",
    "         padding=\"VALID\",\n",
    "         group=1):\n",
    "    input_groups, kernel_groups = tf.split(3, group, input), tf.split(3, group,\n",
    "                                                                      kernel)\n",
    "    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n",
    "    output_groups = [\n",
    "        convolve(i, k) for i, k in zip(input_groups, kernel_groups)\n",
    "    ]\n",
    "    conv = tf.concat(3, output_groups)\n",
    "    return tf.reshape(\n",
    "        tf.nn.bias_add(conv, biases), [-1] + conv.get_shape().as_list()[1:])\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 227, 227, 3))\n",
    "conv1 = tf.nn.relu(\n",
    "    conv(\n",
    "        x, conv1W, conv1b, 11, 11, 96, 4, 4, padding=\"VALID\", group=1))\n",
    "lrn1 = tf.nn.local_response_normalization(\n",
    "    conv1, depth_radius=2, alpha=2e-5, beta=0.75, bias=1.0)\n",
    "maxpool1 = tf.nn.max_pool(\n",
    "    lrn1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "conv2 = tf.nn.relu(\n",
    "    conv(\n",
    "        maxpool1, conv2W, conv2b, 5, 5, 256, 1, 1, padding=\"SAME\", group=2))\n",
    "lrn2 = tf.nn.local_response_normalization(\n",
    "    conv2, depth_radius=2, alpha=2e-5, beta=0.75, bias=1.0)\n",
    "maxpool2 = tf.nn.max_pool(\n",
    "    lrn2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "conv3 = tf.nn.relu(\n",
    "    conv(\n",
    "        maxpool2, conv3W, conv3b, 3, 3, 384, 1, 1, padding=\"SAME\", group=1))\n",
    "conv4 = tf.nn.relu(\n",
    "    conv(\n",
    "        conv3, conv4W, conv4b, 3, 3, 384, 1, 1, padding=\"SAME\", group=2))\n",
    "conv5 = tf.nn.relu(\n",
    "    conv(\n",
    "        conv4, conv5W, conv5b, 3, 3, 256, 1, 1, padding=\"SAME\", group=2))\n",
    "maxpool5 = tf.nn.max_pool(\n",
    "    conv5, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "fc6 = tf.nn.relu_layer(\n",
    "    tf.reshape(maxpool5, [-1, int(np.prod(maxpool5.get_shape()[1:]))]), fc6W,\n",
    "    fc6b)\n",
    "fc7 = tf.nn.relu_layer(fc6, fc7W, fc7b)\n",
    "fc8 = tf.nn.xw_plus_b(fc7, fc8W, fc8b)\n",
    "\n",
    "y_softmax = tf.nn.softmax(fc8)\n",
    "y_ = tf.reduce_mean(y_softmax, 0)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "output = sess.run(y_, feed_dict={x: im1_crop})\n",
    "\n",
    "top_5 = sess.run(tf.nn.top_k(y_, 5), feed_dict={x: im1_crop})\n",
    "print(\"Softmax\\tLabel\")\n",
    "for k in range(5):\n",
    "    print(\"%5.5f\\t%s\" % (top_5[0][k], class_names[top_5[1][k]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
