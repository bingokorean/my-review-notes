# 이미지와 Text정보들을 이용한 쇼핑 카테고리 분류 AI (대규모 분류 문제를 AI로 해결하기)

손경성 / NAVER / 쇼핑검색개발


### 1
많은 상품을 어떻게 효율적으로 검색?
네이버 쇼핑 = 검색 + 가격 비교
가격 비교는 상품 클러스터링. 동일한 상품을 하나의 카탈로그라는 원부로 묶어줌
과거에는 운영이라는 방식으로 사람이 직접 만들고 클러스터링했음
오늘날에는 자동화 처리
카테고리 자동 매칭은 자동화 처리의 기반이 되는 학습 데이터를 만드는 수단이 되기도 함

상품의 정확한 카테고리는 검색 품질의 기본
다양한 몰 카테고리를 하나의 네이버 카테고리로 매핑 필요
'갤럭시'에는 삼성전자 갤럭시 노트, 갤럭시 정장 세트, 아디다스 갤럭시 신발 등 다양한 상품이 존재

'갤럭시'로 검색을 하는 사용자들의 진짜 의도는 무엇일까?
CMP(Category matching probability)이 검색어에 가장 잘 맞는 카테고리는?

모든 상품이 알맞은 카테고리 정보를 가진다면, 
CMP를 적용했을 때 사용자의 질의를 좀 더 정확히 판단하는데 많은 도움이 됨

삼성전자 갤럭시 가격비교에서 
한 사이트를 클릭했는데, 장난감 '파워레인저 갤럭시포스'가 등장한다면...?
애초에 카테고리가 정확했다면...


### 2
Baseline Accuracy
12만개 샘플링하여 수작업으로 일일이 라벨링함
사람의 정확도 - 약75%
왜 사람의 정확도가 낮나?
유아의 원피스, 어린이 원피스 처럼 구분이 모호한 케이스가 있고, 사람들 마다 보는 관점이 다 다름(편향성).
최초의 자동화 baseline 모델 - 약62% (수년 전에 실시)


### 3
자질
브랜드 정보 그다지 큰 효력을 발생시키지 않음
데이터에 약 50% 미만으로 존재함
존재하더라도 중복이 많음
변별력이 그다지 많지 않음

가장 높은 정확도는 확실하게 값이 들어있는
상품명, 몰 카테고리가 있는 경우임

확실하게 값이 들어있는 필드가 있다면 
도움이 될 것임


### 4
상품명은 매우 단순 (특수성이 있음)
데이터에 맞게 워드임베딩을 학습 필요

vocabulary 크기
140만 vocab (0.45) vs. 2만 vocab (0.65)
2만개가 무려 20% 더 좋았음
vocab를 작게할수록 중요한 의미를 가지는 단어를 더 세밀하게 찾을 수 있음

임베딩을 했을 때와 하지 않았을 때
학습 데이터 스코어는 후자가 높았으나
테스트/개발 데이터 스코어는 후자가 더 낮았음 (오버피팅)
임베딩을 하기로 결정!


### 5
모델
layer 노드 수, activation 함수 종류, dropout rate 등은 AutoML을 이용하여 최적화

이미지 처리 백본: MobileNet v2
백본의 정확도가 다른 (무거운) 이미지 딥러닝 모델과 크게 다르지 않음
거기에 mobilenet은 매우 가벼운 모델임
그대로 쓰기엔 부적합
마지막에 fully-connected layer를 추가하여 fine-tuning을 실시

이미지 사이즈
224x224 가 적합했음
여기까지 했을 때의 점수 - 87점

### 6

하이퍼파라미터 튜닝
대체로 fcl_dim이 작고, 모델 parameter 수가 적은 편.
parameter 수가 가장 적은 모델이 안정적으로 학습 & 검증.


### 7

Data Imbalanced Problem
특정 카테고리에 상품이 몰려있음

### 8

Trend Problem
시간에 따라 상품 데이터 분포가 달라진다
계절성을 띄는 상품 데이터도 있다
학습된 모델은 최근 데이터만 잘 맞춘다
비시즌성 상품의 정확도는 떨어질 것이다

즉, 최신 데이터만 학습한다면 상거래 특성상 비 시즈널 데이터에 취약하다
1~12월을 고르게 상품을 가지기 위해서
히스토리 데이터를 관리하고 학습 데이터에 골고루 포함시키도록 하고 있음
이 부분을 보완하니 몇% 정도의 성능 향상을 얻을 수 있었음


### 9

학습 데이터는 완전 무결한가?
학습 데이터에는 노이즈 라벨이 많다 (사람의 편향, 실수 등)

Selfie (논문) - 불확실한 학습 데이터를 재구성
Selfie 연구를 적용해서 데이터를 정제를 해보았다.

Selfie란?
clean set과 unclean set을 준비
clean set은 학습에 사용하고
좀 고치면 될 것 같은 unclean set도 학습에 사용

Selfie를 활용해서
데이터 중 불량 라벨들을 걷어내고 좀 더 보정하니까..
모델 정확도가 90%를 넘게 되었음


### 10

이미지 데이터가 잘 학습되었는지 확인.
이미지 중 올바른 부분에 heatmap 농도가 높아지는지 체크!
다른 부분에 농도가 높아지면 - 해당 카테고리 이미지 데이터가 부족하다는 것을 의미.

SHAP - 딥러닝의 explainer 활용


### 11

텍스트 데이터가 잘 학습되었는지 확인.
어떠한 단어가 잘못 인식되었는지 확인할 수 있음
이것을 보고 다음 학습 데이터 구축에 insight를 줄 수 있고,
토크나이징 튜닝을 할 수도 있음


### 12

여러가지 방법을 했음에도 진짜 마지막까지 안되는 카테고리가 있음.
human과 비교해 error rate가 높은 카테고리를 직접 살펴봄

ex. 출산/육아 카테고리
이 카테고리 자체가 굉장히 모호하다
출산/육아 에는 장난감, 인부복, 커플티, 반팔티, 신발, 등 여러가지 다 있음
이들의 학습 데이터는 변별력이 상당히 약함

출산/육아 카테고리 학습 데이터를 정제할 때,
사전을 만들어서 특정 단어가 등장할 시 삭제하도록 실시
-> 일종의 토크나이저 튜닝

토크나이저의 튜닝은 학습 데이터에서 오매칭하기 쉬운 데이터들을 걸러 내는 것.

ex. 카테고리-제외 키워드 리스트
cat_remove_kwd_list = [
    ('여성', kids),
    ('여성', men),
    ('여성', pregnancy),
    ...
    ('남성', kids),
    ...
    ('유아동', beckenbauer),
    ('유아동', jeans),
    ('유아동', sports),
    ...
]
카테고리 중의성을 띄는 단어를 삭제하는 것과 비슷한 작업같다.


### 13
이렇게 하니
94% 성능을 얻음!


### 14
여기서 1% 올리는 일은
지금까지 했던 일보다 10배는 더 힘들 것이다


### 15
매칭이 안되는 6%는 무엇때문일까?

분류할 수 없는 분류의 문제 
기타 라는 카테고리가 존재
사람이 처음에 정의할 때, 애매하면 기타라고 정의함

이 부분은 네이버 쇼핑에서는 검색 로그를 기반으로
자동 카테고리 생성쪽으로 자동화하고 있음

두 번째 문제로 카테고리 자체에 모호성이 있음
출산육아>임부복>바지
출산육아>유아의류>바지
패션의류>남성의류>바지
패션의류>여성의류>바지
스포츠>등산의류>바지
스포츠>골프의류>바지
...
이는 사람도 맞추기가 매우 어려움
이러한 카테고리들은 정제할 필요가 있다. 좀 더 명확한 구분이 필요!

이런 카테고리를 찾아낼 때,
딥러닝 시각화를 사용하면 좋다.

세 번째 문제로,
몰 카테고리가 굉장히 중요한 정보인데... 여기에 노이즈가 있다면...??
넥타이인데, 몰 카테고리가 구두상품권, 카드상품권이 포함되어 있다면...?
학습할 때는 위와 같은 데이터를 많이 제거하겠지만
inference할 때는...

카테고리 자동 매칭 프로그램에 confidence threshold를 가지고 있다.
threshold를 못 넘으면... '예측하기 힘듬'이라고 표시한다.

이러한 케이스가 많은 몰들은 조금 더 관리를 타이트하게 할 필요가 있음.
해당 몰의 데이터에 몰 카테고리의 weight 비중을 인위적으로 낮춰줄 수도 있겠다.


### 16
최적의 운영 인퍼런스를 위한 노하우
실제 서비스

전처리 -> 모델 inference
처음에는 gpu를 사용. (비효율적)

cpu로 처리해야 되는 작업과 gpu로 처리해야 되는 작업을 구분.

카푸카를 가지고 전처리를 하고, 큐를 태움
gpu를 태워서 분류를 함.

카푸카와 gpu 사이의 성능 차이가 있기에 중간에 중개해주는 큐가 필요함

이렇게 병렬 카푸카 큐 처리로 10배의 성능 개선이 있었음


### 17
내년 도전 과제
OCR 적용하여 attribute를 추출


### 18
attribute extraction을 OCR이 아닌 방식으로
신경망으로... 


### 19
계층 구조를 활용한 모델과
flat 구조인 모델의 성능 차이는 거의 없었다.









