# DEVIEW 2019


## Contents

* 이미지와 Text정보들을 이용한 쇼핑 카테고리 분류 AI (손경성/NAVER/쇼핑검색개발) - [[annotated-slide](https://github.com/gritmind/review/tree/master/media/seminar/deview-2019/annotated_slides/category_map_gritmind.pdf)]
* 쿠팡 추천 시스템 2년간의 변천사 (오성민/Coupang/Recommendation) - [[annotated-slide](https://github.com/gritmind/review/tree/master/media/seminar/deview-2019/annotated_slides/coupang_recommend_gritmind.pdf)]
* Dialog-BERT: 100억 건의 메신저 대화로 일상대화 인공지능 서비스하기 (이주홍/스캐터랩) - [[annotated-slide](https://github.com/gritmind/review/tree/master/media/seminar/deview-2019/annotated_slides/scatterlab_gritmind.pdf)]


## Sumamry 


### 쿠팡 추천 시스템 2년간의 변천사 (오성민/Coupang/Recommendation)

* 이야기 주요 토픽.
   * 과거 2년전 상품 추천에서 오늘날 실시간 개인화를 어떻게 하게 되었는지에 대한 변천사 이야기
   * 과거 모델 위주의 플랫폼에서 겪었던 단점과 한계. 이를 극복하기 위해 플랫폼을 어떻게 바꿔왔는지?
   * 서비스와 모델을 분리하는 플랫폼의 중요성.


### 1. 쿠팡 추천 시스템의 변화

### 1.1. 쿠팡 추천 팀이 하는 일

* 기본적인 상품 추천
   * 함께 본 - 대체재 (ex. 다른 종류의 카메라)
   * 함께 산 - 보완재 (ex. 카메라와 같이 쓸 수 있는 액세서리)

* 이러한 상품 추천뿐만 아니라 다음과 같은 개인화 추천을 하고 싶었음.
   * 오늘의 쇼핑 제안
   * 요즘 인기 있는 상품 제안 (특가)
   * 요즘 인기 있는 카테고리 추천 (시간 기반 인기 상품)
   * 나를 위한 추천 상품
   * 나를 위한 할인 상품
   * 사용자가 특정 카테고리를 자주 보고 있으면 그 카테고리에서 사용자가 자주 구매한 상품. 그 카테고리에서 인기있는 상품. 
   * 카트에 담긴 모든 상품을 고려해서 지금 카트에 담긴 상품들과 같이 쓰면 좋은 상품을 추천

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/media/seminar/deview-2019/images/coupang_recm_1.PNG" width="60%" height="60%"></p>


* 특정 상품을 context로 하지 않고, 사용자를 context로, 카테고리를 context로, 시간을 context로 하는 추천을 하고 싶었음. 
* item과 item 사이의 관계만을 찾는 것이 아니라 item과 user간의 관계, item과 category와의 관계 item과 time간의 관계를 찾고 싶었음. 
* 때로는 여러가지 item들을 함께 고려해서 이 item들과 같이 살 수 있는 다른 상품들을 추천하고 싶었음.
* 필터도 자유롭게 설정 (좋지 않은 퀄리티의 상품은 필터링)
* 각 context에 weight를 주어서 모든 context들을 한 번에 고려함.
* 추천 영역의 확장 가능. 추천 영역의 랭킹이나 UI마저도 개인화를 하고 싶었음.
   * 할인 상품을 좋아하는 유저에게는 할인 상품 추천 영역을 먼저 보여줌.
   * 빨간색을 좋아하는 유저에게는 빨간색 theme을 입힌 추천 영역을 보여줌.
   
### 1.2. 과거, 추천 모델 중심의 플랫폼

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/media/seminar/deview-2019/images/coupang_recm_2.PNG" width="60%" height="60%"></p>

* relation와 model은 서로 강하게 연결되어 있었음 (단점)
   * 복잡하고 다양한 중간 단계의 테이블이 필요함.
   * 테이블이 그대로 서비스에 나가게 됨.

* 과거 플랫폼의 단점 및 한계
   * 모델 변경에 따라 길어지는 파이프라인 (필터, 부스팅, ...)
      * 서로 다른 카테고리 모델을 비교할 때 전체 데이터 파이프라인을 새로 만들어서 A/B 테스트를 실시해야 함.
   * 추가 요청사항을 처리하기 어려움.
   * 완성 전까지 결과를 알 수 없음.
   * 개발에 시간이 오래 걸림.
      * 어디에 문제가 발생하면 전체 파이프라인을 수정해야 함.
      * 테이블 결과를 보고나서야 서비스 결정유무를 선택함.
      * 새로운 서비스를 출시하려면 대략 1달 소요됨.
   * 점진적인 개선이 힘듦.
   * 모델의 재활용이 어려움. 새로운 context를 가질 때마다 전체 파이프라인도 새로 정의해야 함.

* 목표
   * 추천 모델과 서비스를 분리시킬 것
   * 상품 정보나 유저 정보를 서빙 타임에 접근 가능할 것
   * 필터, 부스팅 등의 변경이 쉽고 빠를 것

### 1.3. 현재, 서비스와 모델을 분리하는 플랫폼

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/media/seminar/deview-2019/images/coupang_recm_3.png" width="70%" height="70%"></p>

* 검색 엔진을 사용해서 서비스와 분리할 수 있는 플랫폼을 구축함
   * 쿼리 -> 후보 찾기 -> 랭킹
* 쿠팡의 검색팀과 추천팀은 상품에 대한 모든 정보를 한 군데로 모았음 (중앙화 된 상품 정보)
* 상품을 최대한 잘 표현할 수 있는 feature를 만드는 일이 가장 중요함 
   * 상품 하나를 표현하는 일 (ex. 카테고리, 상품평, 가격, 제목, ...)
   * 상품 간의 연관성 정보를 표현하는 일 (ex. 추천 모델 결과, 이미지 유사도, 카테고리 관련성, ...)
* 만들어지는 feature들을 주기적으로 HBase에 저장함
* 검색팀이 관리하는 정보와 추천팀이 관리하는 정보가 서로 별도의 다른 컬럼에 존재함.
   * protocol buffer의 mergeFrom을 활용해서 쉽게 합쳐서 인덱싱을 함.
* proto DB라는 작은 in-memory DB를 둬서, 인덱싱에는 사용하지 않지만 때에 따라 상품에 대한 정보를 serving time에 얻고 싶을 때 key-value 구조로 product 버퍼에 그대로 꺼낼 수 있도록 함.
* 이렇게 만든 doc과 proto 데이터는 search cluster에 올라감.
   * 컨텍스트와 관련된 상품을 찾고, 조건에 따라 필터링한 다음, 점수에 따라 정렬한다.
* Query Handler Cluster를 통해 컨텍스트를 정의. 즉, 서비스를 정의해서 search cluster에 넘겨준다.
   * 예시
      * 서비스 정의 - 냄비와 함께 살 할인 식품
      * 추가 정렬 (고기, 생선, 야채를 번갈아 보여주자)
   * 빠른 서비스 개발 가능
      * 피처 조합과 가중치에 따라 새로운 서비스
	  * 필터로 새로운 추천 서비스 만듦
	  * 검색 결과를 필요에 따라 새롭게 정렬

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/media/seminar/deview-2019/images/coupang_recm_4.PNG" width="70%" height="70%"></p>

* 위의 그림처럼 모델과 서비스를 분리. (하루만에 서비스 출시 가능)
   * 서비스 정의
      * 서비스에서는 피처들을 어떻게 쓸지만 고민
	  * 지속적인 쿼리 튜닝
   * 모델 개발, 피처 생성
      * 모델에서는 좋은 피처를 만들기 위해서 노력
	  * 새로 만들어진 피처는 다른 서비스에도 사용
	  * 만약 어떤 서비스가 망하더라도 만들어놓은 카테고리 모델, 가겨 모델은 다른 서비스를 위해 계속 사용 가능

* 변화
   * 빠른 서비스 개발 가능
   * 비지니스 상황에 대한 빠른 대처 가능
   * 개발된 피처를 다양한 방면으로 활용 가능

### 2. 더 나은 추천을 위해

* 쿼리 튜닝
   * feature는 개발할수록 더 늘어난다. 서비스에서는 각 feature마다 가중치를 매기고 사용해야 한다. 이 것을 manual하게 정하는 것은 비효율적이고 힘든일이다. 자동으로 할 수 없을까?


### 2.1. Learning to Rank

* Learning to Rank: 쿼리 튜닝을 모델에게 맡기자

* Inference
   * Search cluster 각 노드는 모델을 가지고 각자의 추천 후보 상품을 리랭킹
   * 모델 결과가 이상하면, 리뷰 / CTR 등으로 보정
      * 유저의 반응(사용자 로그)에 종속되므로 휴리스틱한 세밀한 보정이 필요
* Training
   * LTR 모델을 학습시키기 위해서는, 어떤 상품이 어떤 feature를 가지고 추천되었는지 알아야(추적) 한다. 즉, 로그가 필요하다.
   * 새로운 feature는 로깅이 없으므로 바로 LTR에 사용할 수 없다. 이를 위해 로그를 이용해 쿼리를 재현하고 작은 크롤링 cluster를 띄어서 feature를 빽필하고 있다.
   * 레이블은 유저의 반응을 사용한다. 이커머스에서 유저의 반응은 하루만에 일어나지 않는다. 몇일동안의 유저 반응을 빽필한다.
   * API 서버는 추천 상품을 내보낼 때마다 그 당시에 그 상품이 어떤 feature를 담고 있는지 로깅한다.

* 모델이 잘 사용할만한 좋은 피처를 만드는 것이 중요하다. 좋은 피처를 만들기 위해 실시간 피처, 개인화 피처 등을 만든다.


### 2.2. 실시간 개인화

* 실시간 사용자 피처
   * 실시간 로그 -> Redis
      * 암호화된 유저 ID -> 사용자 정보 (최근 본 상품, 최근 산 상품, 최근 검색한 쿼리, ...)
* 오프라인 사용자 피처
   * 사용자 분석 모델 (유저 한 명마다 feature들을 이렇게 가지고 있다)
      * 선호 카테고리, 선호 가격대, 선호 브랜드, 멤버십 가입 여부, ...
* 유저 상품 연관성
   * { 유저 x 상품 } 의 경우의 수는 너무 많다.
   * 세그먼트 상품 연관성 - 세그먼트라는 중간 단계를 두어 경우의 수를 확 줄인다.
   * 유저 세그먼트
      * 최근에 언제 들어오나? 얼마나 자주 들어오나? 얼마나 많이 구매하나? 디바이스는 무엇인가 등에 따라 세그먼트를 구분
	  * ex. 신선 식품의 경우 아이폰 보다 안드로이드 세그먼트에서 더 잘 팔리는 것으로 나온다.
	  * ex. 원피스 상품의 경우 남성 세그먼트에는 퍼포먼스가 좋지 않을 것이다.
* 실시간 상품 피처
   * 상품에 대한 대부분의 정보는 HBase에 있지만, 이들은 모두 offline에서 정의된다.
   * search cluster의 인덱싱도 실시간이 아니다.
   * 그렇다면, 상품에 실시간 정보를 어떻게 주입할까?
      * 카푸카를 이용해 특정 상품 id가 어떤 추천 영역에 얼마나 나갔고 얼마나 좋은 반응을 가졌는지 계산한다.
	  * 이것은 상품 feature처럼 redis를 바로 사용하기 어렵다. 각 샤드 위에 조그만한 인메모리 스토리지를 올려서 니어 리얼타임을 구성한다.
* 실시간 개인화
   * LTR 모델은 사용자 feature, 실시간 feature를 모두 가지고 학습하므로 실시간 개인화를 제공할 수 있다.
* 추천 영역 개인화
   * 추천 영역도 사용자마다 랭킹해줄 수 있다. 어떤 추천 영역을 먼저 보여줄지?
* Feature Selection
   * 모든 피처를 사용하면 성능이 더 좋아질 수 있으나..
   * feature의 개수는 최대한 적게 유지하려고 한다. feature가 어떤 영향을 주는 최대한 잘 이해하고 사용하려고 한다.
      * 중요한 feature를 알아야 한다. 
	  * 어떤 feature를 먼저 우선적으로 실시간으로 업데이트할 것인지 결정하는 척도가 된다.
	  * 서치 결과가 이상할 때 어떻게 디버깅할 지 가이드가 된다.
   * 좋은 feature는 모델이 중요하게 생각하는 feature가 무엇인지와 밀접한 관련이 있다.
      * feature 값이 커질 때 작아질 떄, 모델의 결과값은 어떠한가?
	  * feature 사이의 correlation이 강하다면 하나는 삭제하는 것이 좋다.
	  * feature의 범위가 골고루 잘 분포해있나 확인하는 것도 좋다.


### 3. 요약 & 팁

* raw feature를 사용하면 correlation이 높은 친구들이 많았다. 이를 줄이기 위해 processed feature로 바꿔나갔다.
* 추천 영역에서는 RNN과 같은 복잡한 모델보다는 Decision tree와 같은 단순한 모델을 사용한다.
   * 복잡한 모델로 정확도를 극대화하는 것은 추천 영역에서는 맞지 않다고 판단했다.
* Feature 개수는 최대한 적게 유지한다.
* 파라미터 튜닝보다는 피처 엔지니어링이 중요하다. 피처 엔지니어링은 그 다음 step에 도움이 되고, 피처를 더 깊이 이해하는 것이 중요했다.


