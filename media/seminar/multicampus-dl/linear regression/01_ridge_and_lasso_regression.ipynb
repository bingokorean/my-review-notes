{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보충 자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_linear_regression.ipynb의 주요 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv('data/bikeshare.csv')\n",
    "\n",
    "# Year와 Month를 추출\n",
    "datetime = pd.DatetimeIndex(data['datetime'])\n",
    "data['year'] = datetime.year\n",
    "data['month'] = datetime.month\n",
    "data['hour'] = datetime.hour\n",
    "\n",
    "# \"count\" is a method, so it's best to name that column something else\n",
    "data.rename(columns={'count':'total'}, inplace=True)\n",
    "\n",
    "# Handling 'season' variable\n",
    "season_dummies = pd.get_dummies(data.season, prefix='season')\n",
    "season_dummies.drop(season_dummies.columns[0], axis=1, inplace=True)\n",
    "data = pd.concat([data, season_dummies], axis=1)\n",
    "\n",
    "# Add derivative variable \"daytime\"\n",
    "data['daytime'] = ((data.hour > 6) & (data.hour < 21)).astype(int)\n",
    "\n",
    "# Handling 'hour' variable\n",
    "hour_dummies = pd.get_dummies(data.hour, prefix='hour')\n",
    "hour_dummies.drop(hour_dummies.columns[0], axis=1, inplace=True)\n",
    "data = pd.concat([data, hour_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형회귀모델을 학습하는 함수를 조금 수정하였습니다.\n",
    "다음을 포함하는 dictionary를 출력하는 함수로 변경하였습니다.\n",
    "- 각 변수에 대응하는 계수들(coefficients)과 intercept\n",
    "- Train set에서의 RMSE, R^2\n",
    "- Test set에서의 RMSE, R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that accepts a list of features and\n",
    "# returns coefficients, intercept, training RMSE/R^2 and testing RMSE/R^2\n",
    "def train_test_linreg(d, feature_cols):\n",
    "    X = d[feature_cols]\n",
    "    Y = d.total\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make series using selected features and corresponding coefficients\n",
    "    formula = pd.Series(model.coef_, index = feature_cols)\n",
    "    \n",
    "    # Save intercept\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Calculate training RMSE and testing RMSE\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "    \n",
    "    # Calculate training R-square and testing R-square\n",
    "    rsquared_train = model.score(X_train, Y_train)\n",
    "    rsquared_test = model.score(X_test, Y_test)\n",
    "    \n",
    "    # Make result dictionary\n",
    "    result={'formula':formula, 'intercept':intercept, 'rmse_train':rmse_train, 'rmse_test':rmse_test,\n",
    "           'rsquared_train':rsquared_train, 'rsquared_test':rsquared_test}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hour에 대한 binary dummy variable만 이용하여 선형회귀모델을 학습\n",
    "hour_cols = list(data.columns[data.columns.str.startswith('hour_')])\n",
    "result = train_test_linreg(data, hour_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': hour_1     -22.580917\n",
       " hour_2     -32.757474\n",
       " hour_3     -44.209704\n",
       " hour_4     -49.961957\n",
       " hour_5     -36.711049\n",
       " hour_6      16.801172\n",
       " hour_7     159.656510\n",
       " hour_8     309.943473\n",
       " hour_9     160.149618\n",
       " hour_10    121.193570\n",
       " hour_11    147.090587\n",
       " hour_12    202.425259\n",
       " hour_13    200.110370\n",
       " hour_14    195.261156\n",
       " hour_15    195.486156\n",
       " hour_16    266.890255\n",
       " hour_17    419.952457\n",
       " hour_18    379.068371\n",
       " hour_19    264.786324\n",
       " hour_20    173.622659\n",
       " hour_21    125.548656\n",
       " hour_22     77.631922\n",
       " hour_23     34.730308\n",
       " dtype: float64,\n",
       " 'intercept': 56.263843648209075,\n",
       " 'rmse_test': 128.47511657303033,\n",
       " 'rmse_train': 124.92842235488435,\n",
       " 'rsquared_test': 0.49192464950577053,\n",
       " 'rsquared_train': 0.52631453386835414}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check coefficients, intercept, training RMSE/R^2 and testing RMSE/R^2\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression & Lasso regression\n",
    "### 두 모델의 공통점\n",
    "- **Regularization**: 모델 계수가 커지는 것에 대한 penalty를 부여함으로써 모델의 overfitting(과적합)을 방지\n",
    "- 기본적인 multiple linear regression (다중선형회귀분석) 은 변수 간의 [다중공산성(multicollinearity)](https://ko.wikipedia.org/wiki/%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1)에 의해 성능이 하락하는데, 이 두 회귀모델은 이에 대해 대처할 수 있는 모델\n",
    "- 모델의 parameter(모수)가 존재: 계수 크기에 대한 penalty를 얼마나 줄 것인가 (**alpha**)\n",
    "- alpha가 0이면 단순 다중선형회귀모델과 일치한다.\n",
    "\n",
    "\n",
    "### Lasso regression의 강점\n",
    "- Lasso regression은 ridge regression과는 달리 특정 변수의 계수를 0으로 만들어줍니다. 특정 변수의 계수가 0이 아니라는 것은 **lasso regression 모델이 그 변수를 선택**했다고 볼 수 있습니다.\n",
    "- Lasso regression은 모든 변수가 선택되는 것이 아니라는 점에서 **sparse model** (희소모델)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 모델을 적용하기에 앞서 다음과 같은 데이터 전처리를 다시 실시하였습니다.\n",
    "- X에서 가능한 모든 변수를 사용하여, 모델의 성능이 어떻게 나오는지 파악\n",
    "- 제거한 변수: datetime (수치형 변수가 아니며, year/month/hour로 이미 분리됨),casual & registered (타겟변수인 'total'과 함께 움직이는 변수), total (타겟 변수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_test_ridge(data, alpha_value):\n",
    "    X = data.drop(['datetime','casual','registered','total'], axis = 1)\n",
    "    Y = data.total\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    model = Ridge(alpha = alpha_value)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make series using selected features and corresponding coefficients\n",
    "    formula = pd.Series(model.coef_, index = list(X.columns.values))\n",
    "    \n",
    "    # Save intercept\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Calculate training RMSE and testing RMSE\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "    \n",
    "    # Calculate training R-square and testing R-square\n",
    "    rsquared_train = model.score(X_train, Y_train)\n",
    "    rsquared_test = model.score(X_test, Y_test)\n",
    "    \n",
    "    # Make result dictionary\n",
    "    result={'formula':formula, 'intercept':intercept, 'rmse_train':rmse_train, 'rmse_test':rmse_test,\n",
    "           'rsquared_train':rsquared_train, 'rsquared_test':rsquared_test}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ridge regression 학습 및 테스트 (alpha = 0.1)\n",
    "result = train_test_ridge(data, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': season         -2.644511\n",
       " holiday        -0.187192\n",
       " workingday      3.602478\n",
       " weather       -24.457755\n",
       " temp            2.633739\n",
       " atemp           2.680801\n",
       " humidity       -0.717789\n",
       " windspeed      -0.548883\n",
       " year           86.747894\n",
       " month           8.384052\n",
       " hour            4.331612\n",
       " season_2       22.823900\n",
       " season_3      -11.585274\n",
       " season_4       -0.765954\n",
       " daytime       140.853699\n",
       " hour_1        -24.092058\n",
       " hour_2        -35.758448\n",
       " hour_3        -53.349607\n",
       " hour_4        -60.911974\n",
       " hour_5        -45.178525\n",
       " hour_6          5.419792\n",
       " hour_7         -2.819784\n",
       " hour_8        144.635743\n",
       " hour_9        -19.253897\n",
       " hour_10       -74.057873\n",
       " hour_11       -56.503838\n",
       " hour_12       -14.484937\n",
       " hour_13       -25.203273\n",
       " hour_14       -43.032744\n",
       " hour_15       -43.953162\n",
       " hour_16        19.865097\n",
       " hour_17       174.271810\n",
       " hour_18       131.144534\n",
       " hour_19        20.719563\n",
       " hour_20       -70.473541\n",
       " hour_21        17.001661\n",
       " hour_22       -25.495563\n",
       " hour_23       -67.961303\n",
       " dtype: float64,\n",
       " 'intercept': -174510.58752520583,\n",
       " 'rmse_test': 102.94491618458643,\n",
       " 'rmse_train': 100.40807187558703,\n",
       " 'rsquared_test': 0.67378802975228769,\n",
       " 'rsquared_train': 0.69401171221895019}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_lasso(data, alpha_value):\n",
    "    X = data.drop(['datetime','casual','registered','total'], axis = 1)\n",
    "    Y = data.total\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    model = Lasso(alpha = alpha_value)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make series using selected features and corresponding coefficients\n",
    "    formula = pd.Series(model.coef_, index = list(X.columns.values))\n",
    "    \n",
    "    # Save intercept\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Calculate training RMSE and testing RMSE\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "    \n",
    "    # Calculate training R-square and testing R-square\n",
    "    rsquared_train = model.score(X_train, Y_train)\n",
    "    rsquared_test = model.score(X_test, Y_test)\n",
    "    \n",
    "    # Make result dictionary\n",
    "    result={'formula':formula, 'intercept':intercept, 'rmse_train':rmse_train, 'rmse_test':rmse_test,\n",
    "           'rsquared_train':rsquared_train, 'rsquared_test':rsquared_test}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lasso regression 학습 및 테스트 (alpha = 0.1)\n",
    "result = train_test_lasso(data, 0.1) # lasso에서 alpha값이 커지면 0이되는 변수들이 많아진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': season         -1.118508\n",
       " holiday        -0.000000\n",
       " workingday      3.143370\n",
       " weather       -24.069284\n",
       " temp            2.647267\n",
       " atemp           2.660164\n",
       " humidity       -0.727897\n",
       " windspeed      -0.547569\n",
       " year           86.293023\n",
       " month           7.805339\n",
       " hour            3.530808\n",
       " season_2       22.837538\n",
       " season_3      -10.490398\n",
       " season_4        0.000000\n",
       " daytime       136.388611\n",
       " hour_1        -13.337234\n",
       " hour_2        -24.053905\n",
       " hour_3        -40.848064\n",
       " hour_4        -47.640757\n",
       " hour_5        -31.120189\n",
       " hour_6         15.524011\n",
       " hour_7         12.668550\n",
       " hour_8        160.830004\n",
       " hour_9         -0.000000\n",
       " hour_10       -51.624457\n",
       " hour_11       -33.323522\n",
       " hour_12         4.643776\n",
       " hour_13        -0.447771\n",
       " hour_14       -17.510896\n",
       " hour_15       -17.623873\n",
       " hour_16        42.110149\n",
       " hour_17       197.513982\n",
       " hour_18       155.005382\n",
       " hour_19        45.429748\n",
       " hour_20       -40.123880\n",
       " hour_21        39.051951\n",
       " hour_22        -0.000000\n",
       " hour_23       -39.726194\n",
       " dtype: float64,\n",
       " 'intercept': -173603.14206043587,\n",
       " 'rmse_test': 102.89861692776051,\n",
       " 'rmse_train': 100.44724420264046,\n",
       " 'rsquared_test': 0.67408139004622336,\n",
       " 'rsquared_train': 0.69377291445758593}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파악할 부분\n",
    "- Ridge regression과 Lasso regression의 결과와 단순선형회귀모델의 결과를 비교해보세요.\n",
    "- 위의 Ridge regression과 Lasso regression에서 alpha값을 변형해가면서 결과가 달라지는지 살펴보세요."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
