# 미래를 바꾼 아홉가지 알고리즘

존 캑코믹

책의 내용을 읽고 정리하였고, 저의 생각은 인용문 블럭(blockquotes) - 회색 글 에 정리하였습니다.

## Contents

<div id='contents'/>

1. [시작하며 - 컴퓨터를 움직이는 위대한 아이디어들](#1.)
2. [검색엔진 인덱싱 - 세상에서 가장 큰 건초 더미에서 바늘 찾기](#2.)
3. [페이지랭크 - 구글을 출범시킨 기술](#3.)
4. 공개 키 암호화 - 공개 엽서에 비밀을 적어 아무도 모르게 보내는 방법
5. 오류 정정 코드 - 데이터 오류를 스스로 찾아 고치는 마법
6. 패턴 인식과 인공지능 - 사람처럼 학습하고 생각하는 컴퓨터
7. 데이터 압축 - 책 한 권을 종이 한 장에 담기
8. 데이터베이스 - 일관성을 향한 여정
9. 디지털 서명 - 진짜 누가 이 소프트웨어를 작성했을까?
10. 계산 가능성과 결정 불가능성 - 컴퓨터로 모든 문제를 해결할 수 있을까?
11. 마치면서 - 미래의 알고리즘과 진화하는 컴퓨터

<br>
<br>

<div id='1.'/>

## 1. 시작하며 - 컴퓨터를 움직이는 위대한 아이디어들

컴퓨터과학자들은 자신들의 중요한 아이디어의 상당수를 알고리즘(algorithms)이라고 표현한다. 그렇다면 아이디어와 알고리즘 사이엔 어떤 차이가 있을까? 

알고리즘이란 문제를 푸는 데 필요한 단계의 순서를 명확히 명시하는 구체적인 계산법이다. 다음과 같이 두 개의 큰 수를 더하는 알고리즘을 보면 거의 기계적으로 이뤄지는 것을 알 수 있다. 각 단계는 절대적으로 정확해야 하며 어떤 인간적 직관이나 추측도 요하지 않는다. 이처럼 매우 기계적인 각 단계는 컴퓨터 프로그램으로 만들어낼 수 있다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/1_1.PNG" width="60%" height="60%"></p>

알고리즘의 또 다른 중요한 기능은 입력 내용에 상관없이(`일반성이 있음`) 늘 작동한다는 점이다. 예를 들어, 좀 시간이 걸리더라도, 이 알고리즘을 이용해 천 자리 수도 더할 수 있다. 다시 말해, 알고리즘의 기본 정의는 매우 구체적인 계산법과 같은 일상적인 언어로 표현된 것이다.

그런데, 알고리즘과 컴퓨터는 무슨 관련이 있나? 핵심은 컴퓨터가 매우 정확한 지시에 따라 프로그램돼야 한다는 사실이다.

컴퓨터를 시켜 특정 문제를 풀게 하기 전에 해당 문제를 풀 수 있는 알고리즘부터 개발해야 한다. (`중요한 문장! 패턴 인식이 어려운 이유와 같다`) 수학과 물리학 같은 일반 과학 분야에서 중요한 결과는 대개 하나의 공식으로 포착된다(ex. 피타고라스 정리 등). 이와는 대조적으로 컴퓨터과학에서 위대한 아이디어는 일반적으로 알고리즘을 이용해 문제를 푸는 방법을 기술한다.

컴퓨터과학에서 가장 아름다운 아이디어들은 상당수가 매우 추상적이며, 소프트웨어나 하드웨어 분야 어느 쪽에도 속하지 않는다. 이 책에서는 이론적인 알고리즘에 집중한다. 

[[go-to-contents](#contents)]

<br>

<div id='2.'/>

## 검색엔진 인덱싱 - 세상에서 가장 큰 건초 더미에서 바늘 찾기

### 매칭과 랭킹

검색엔진의 두 가지 주요 과제는 매칭(matching)과 랭킹(ranking)이다. 이렇게 두 가지 주요 단계가 있지만 실제로는 검색엔진의 효율성을 목적으로 매칭과 랭킹을 하나의 과정으로 조합한다. 그러나 두 단계는 개념적으로 분리되므로 매칭이 완료된 후 랭킹이 시작된다고 볼 수 있다. (`여기서 형태소 분석은 매칭 단계이다`)

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/2_1.PNG" width="60%" height="60%"></p>

좋은 검색엔진은 최선의 검색결과를 선별할 뿐 아니라 가장 유용한 순서에 따라 결과를 보여 준다. 치열한 검색엔진 시장에서 랭킹 시스템의 질에 따라 회사가 살거나 죽는다.

### 알타비스타 - 최초의 웹 규모 매칭 알고리즘

웹 검색 기법을 최초로 상용 도입한 기업은 1994년 출범한 일포시크(Infoseek)와 라이코스(Lycos), 1995년에 검색엔진을 출범시킨 알타비스타(AltaVista)였다. 최초의 검색엔진은 웹의 모든 페이지에 있는 모든 텍스트를 완전히 인덱싱했다.

### 오래된 평범한 인덱싱

인덱스(index)란 개념은 모든 검색엔진 이면에 있는 가장 근본적인 발상이다. 인덱싱이란 발상은 5,000년 전에 지어진 바빌론 신전 도서관에서도 주제에 따라 설형 문자판을 분류해 놓았던 것을 볼 수 있다.

오늘날 인덱스란 단어는 주로 책 끝에 있는 찾아보기 페이지를 뜻한다. 찾아볼 만한 모든 개념이 고정된 순서(주로 가나다, 알파벳 순)로 열거돼 있고 바로 옆엔 그 개념이 수록된 위치(주로 쪽 번호)가 있다. 예를 들어, '컴퓨터 124, 156' 같은 인덱스 항목이 있으면 컴퓨터라는 단어가 124쪽, 156쪽에 나온다는 뜻이다.

웹 검색엔진용 인덱스는 책의 인덱스와 같은 방식으로 작동한다. 이 책의 '페이지'는 이제 월드와이드웹상의 웹페이지고 검색엔진은 웹에 있는 모든 개별 웹페이지에 저마다 다른 페이지 번호를 할당한다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/2_2.PNG" width="60%" height="60%"></p>

컴퓨터는 우선 모든 페이지에 등장하는 모든 단어의 목록을 만들고 (여기서 형태소 분석기를 사용한다) 이 목록을 알파벳 순으로 정리해 세 개 웹페이지의 인덱스를 구축할 수 있다. 그 다음에 컴퓨터는 단어별로 페이지들을 빠르게 살펴본다. 단어 목록도 알파벳 순이므로 빠르게 검색할 수 있고, 검색하면 그 옆에 있는 페이지들만 가져오면 된다. 컴퓨터는 인덱스 항목만 살펴보면서 판단한다.

'cat'이란 쿼리에는 1, 3번 페이지를 결과로 보여준다. 'cat dog'라는 복수 단어는 어떻게 할까? 단순히 논리 연산으로 3번 페이지의 결과를 보여줄 수 있다. 단, 여기서 가정은 'cat'과 'dog'라는 두 단어를 위치와 순서에 상관없이 포함한 페이지를 찾는다는 것이다.

그러나, 구문 쿼리(phrase query)는 어떻게 해결할 수 있나? 구문 쿼리는 정확한 구문을 검색하는 쿼리이며 'dog cat'과 'cat dog'는 다른 쿼리이다. 위의 인덱싱 항목으로는 구문 쿼리를 검색할 수 없다. 두 단어가 1, 3 페이지에 출현한다는 사실을 알지만 두 단어가 적절한 순서로 붙어 있는지는 알 길이 없다. 1, 3 페이지로 찾아가서 해당 문구가 있는지 다시 검색해보는 것도 방법이긴 하지만 매우 비효율적이다. 무조건 인덱싱 항목에서 끝을 내야 한다 (`중요`).

### 단어 위치 트릭

구문 쿼리 문제는 페이지 번호뿐만 아니라 페이지 안의 위치도 저장해야 한다는 아이디어를 발생시켰다. 이러한 인덱스의 개발 방법을 '단어 위치 트릭'이라고 부르겠다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/2_3.PNG" width="60%" height="60%"></p>

위의 그림에 명시되어 있는 위치 정보를 통해 'cat sat' 이라는 구문 쿼리에 대해 1번 페이지를 출력할 수 있다. 'cat sat'이란 구문에 대한 검색결과를 원래 웹페이지가 아닌 인덱스 정보만 보고 찾았다는 사실에 주목하자. 실제 검색엔진에서 결과가 있을 수도 있는 페이지는 수백만 개에 달할지도 모른다. 따라서, 인덱스를 잘 구축하는 것이 굉장히 중요하다!.

구문 쿼리와 비슷하게 근접한 단어를 찾는 문제가 있다. 일부 검색엔진에서 쿼리에서 NEAR라는 키워드를 사용할 수 있다(알타비스타는 초기부터 이 기능을 제공해왔다). 예를 들어 'cat NEAR sat'이라는 쿼리는 'cat' 단어가 'dog'라는 단어로부터 다섯 단어 안에 있는 페이지를 찾아줘라고 말하는 것과 같다. 이 역시 단어 위치 트릭을 통해 쉽게 해결할 수 있다. 어떤 웹페이지의 실제 내용도 읽을 필요가 없다. 대신 인덱스에서 두 항목만 참고하면 된다.

사실, NEAR 쿼리가 검색엔진 이용자에게는 별로 중요하지 않다. 거의 아무도 NEAR 쿼리를 이용하지 않고 대부분 검색엔진은 이를 지원조차 하지 않는다. 그럼에도 NEAR 쿼리를 수행하는 능력은 실제 검색엔진에는 중요하다. 검색엔진 자체가 이면에서 (내부적으로) NEAR 쿼리를 끊임없이 수행하기 때문이다. 그 이유를 이해하려면 검색엔진의 랭킹 문제를 이해해야 한다.

> 매칭과 랭킹은 완전히 이질적인 것이 아니라 서로 연관성이 있다. 매칭의 범위를 형태소 분석기가 결정한다. 분석기를 튜닝하면서 매칭의 범위를 엄격하게 좁힐 수 있다. 이는 랭킹에 영향을 끼칠 것이다. 아주 엄격한 매칭은 랭킹이 포함된 매칭을 하는 것과 같다.


### 랭킹과 근접성

지금까지는 주어진 쿼리에 대한 모든 검색결과를 효율적으로 찾는 매칭 문제를 다뤘다. 두 번째 단계인 랭킹은 사용자에게 보여 줄 소수의 상위 검색결과를 선별하는 단계이다. 

랭킹이란 개념을 좀 더 주의깊게 살펴보자. 페이지의 순위(rank)는 실제로 무엇에 달려 있나? 진짜 질문은 "이 페이지가 쿼리에 **부합(match)**하는가?" 가 아니라 "이 페이지가 쿼리에 적합(relevant)하는가?" 이다. 컴퓨터과학자는 '**적합성(relevance)**'라는 용어를 주어진 페이지가 특정 쿼리에 적합하거나 유용한 정도를 기술하는 데 쓴다.

예를 들어, 'malaria cause'를 검색한다고 하자. 다음 그림에서 페이지 1이 더 적합한 것을 알 수 있다. 그러나, 컴퓨터는 어떻게 이를 판단할 수 있나?

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/2_4.PNG" width="60%" height="60%"></p>

이런 경우 순위를 바르게 매기는 간단한 방법이 있다. 쿼리 단어가 서로 가까이 있는 페이지가 그렇지 않은 페이지보다 더 적합할 가능성이 높다. 이 역시 단어 위치 트릭이 추가된 인덱스 항목만 보고 찾을 수 있다. 

요컨대 인간은 NEAR 쿼리를 많이 쓰지 않지만 검색엔진은 랭킹을 향상시키고자 (단어 위치 트릭 등을 이용해) 근접성에 관한 정보를 계속 이용한다. 

다음에서 소개될 메타워드 트릭 및 이와 연관된 다양한 아이디어를 정교하게 이용한 덕분에 알타비스타는 1990년대 말 검색 산업의 정상에 오를 수 있었다.


### 메타워드 트릭

지금까지 웹페이지를 일반적 단어 목록처럼 단순히 다뤘다. 실제로 대부분 웹페이지는 제목(title), 표제(heading), 링크(link), 이미지, 하이퍼링크 등 구조가 꽤 복잡하다. 이제 검색엔진이 웹페이지 구조를 고려하는 방법을 알아보자. 이러한 복잡한 구조는 메타워드라는 특수한 언어를 이용해 작성한다.

예를 단순화하기 위해서 페이지 최상단에 제목을, 그 다음 본문이 나오는 구조의 한 가지 측면만을 상정한다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/2_5.PNG" width="60%" height="60%"></p>

인덱스를 구축할 때 메타워드를 넣는 것은 어렵지 않다. 새로운 트릭을 쓸 필요 없이 보통 단어와 같은 방식으로 메타워드의 위치를 저장하기만 하면 된다. 보통 단어와 같은 방식으로 메타워드를 인덱싱하는 이 간단한 트릭을 '메타워드 트릭'이라 부른다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/2_6.PNG" width="60%" height="60%"></p>

검색엔진이 IN 이란 키워드를 이용한 특수 유형의 쿼리를 지원한다고 가정해 보자. 'boat in TITLE' 같은 쿼리는 웹페이지의 제목에 'boad'란 단어가 있는 페이지에 해당하는 검색결과만 출력한다. 실제로 구글에서 상세 검색이나 intitle: 이란 키워드를 통해 위와 같은 쿼리를 날릴 수 있다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/2_7.PNG" width="60%" height="60%"></p>

앞에서 논한 쿼리에섳터럼 검색엔진은 원래 웹페이지로 돌아가 검색할 필요 없이, 적은 수의 인덱스 항목만 참고해 쿼리에 답할 수 있다(있어야 한다). 또한, 각 인덱스 항목을 한 번만 검색해도 된다는 점도 중요하다.

제목 쿼리 및 웹페이지의 구조와 관련된 '구조 쿼리(structure quries)'는 사용자가 거의 이용하지 않지만 검색엔진은 내부적으로 이를 늘 이용한다는 점에서 앞서 논한 NEAR 쿼리와 비슷하다.

검색엔진의 성공여부를 판가름하는 이 랭킹은 웹페이지 구조를 얼마나 잘 활용하느냐에 따라 개선될 수 있다. 사용자가 '개'라는 단순한 쿼리를 입력할 때 (사용자가 명시적으로 요청하지 않더라도) 검색엔진은 내부적으로 '개 IN TITLE' 검색을 수행해서 우연히 개를 언급한 페이지가 아닌 개에 관해 다룰 가능성이 가장 큰 페이지를 찾는다.

> 거리 정보, 메타워드 정보 이러한 것들이 결국 기계학습에서 feature engineering을 하는 것과 같다. 문제를 학습 문제로 바꾸면 그대로 이들을 feature로 적용할 수 있다.

### 인덱싱과 매칭 트릭이 전부는 아니다

알타비스타가 성공한 이유는 메타워드 트릭 덕분이었다는 것을 1999년 알타비스타가 제출한 '인덱스 제한 검색(Constrained Searching of an Index)'라는 미국 특허에서 볼 수 있다.

효율적 매칭은 효과적 검색엔진이 되는 데 딱 절반 정도의 역할을 할 뿐이다. 나머지 과제는 적절하게 매칭된 페이지의 순위를 매기는 일, 즉 랭킹이다.

> 매칭과 랭킹 알고리즘을 구분할 수 있는 기준이 있을까? 매칭과 랭킹 알고리즘 모두 좋은 인덱스를 구축하는 목표는 동일하다. 인덱스 항목에 메타워드를 포함하여 최대한 많은 정보를 넣는 것이 좋다. 매칭 알고리즘은 binary (discrete)하고, 랭킹 알고리즘은 continuous 하다.


<br>

<div id='3.'/>

## 페이지랭크 - 구글을 출범시킨 기술

최초의 상업 검색엔진이 구글보다 4년 앞선 1994년에 출범했다. 구글이 어떻게 4년이라는 뒤늦은 출발을 극복하고 검색 품질 면에서 라이코스와 알타비스타를 뛰어 넘을 수 있었을까? 가장 중요한 요인 중 하나는 구글이 검색결과의 순위를 매기는 데 이용한 혁신적 알고리즘인 페이지랭크(PageRank)이다.

### 하이퍼링크 트릭 (Hyperlink Trick)

하이퍼링크(hyperlink)란 클릭했을 때 다른 웹페이지로 연결하는 웹페이지 구문이다. 하이퍼링크는 검색엔진이 랭킹을 수행하는 데 이용하는 가장 중요한 툴의 하나고 구글 페이지랭크 알고리즘의 근본이다. 

페이지랭크를 이해하는 첫 단계는 이 책에서 하이퍼링크 트릭(hyperlink trick)이라고 부르는 간단한 발상이다. 예를 들어, 스크램블 에그를 만드는 데 관심이 많아 이 주제에 관해 웹 검색을 한다고 하자. 다음과 같이 문제를 단순화하였다 (2개의 검색결과 출력). 버트(Bert)와 어니(Ernie) 중 어느 웹페이지가 더 높은 순위를 차지해야 할까?

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/3_1.PNG" width="60%" height="60%"></p>

사람이라면 두 레시피에 연결된 페이지를 읽고 판정을 쉽게 내릴 수 있다. 두 레시피 모두 그럴듯해 보이지만 사람들은 어니의 레시피보다 버트의 레시피에 훨씬 더 열광한다. 그러므로 다른 정보가 없다면 어니보다 버트에 더 높은 순위를 주는 편이 타당하다.

불행히도 컴퓨터는 웹페이지가 실제로 의미하는 바를 잘 이해하지 못한다. 그러므로 검색엔진이 검색결과에 연결된 네 페이지를 검토하고 각 레시피가 얼마나 강력히 추천받는지 평가하기란 쉽게 실현 가능한 작업이 아니다. 반면 컴퓨터는 숫자를 세는 데는 탁월하다. (`의미있는 행동을 숫자로 변환하자.`)

간단히 각 레시피에 연결된 페이지 수를 세어 각 페이지에 있는 인커밍 링크(incoming link)의 수에 따라 레시피 순위를 매겨보자. 물론 사람이 페이지 전체를 읽고 순위를 수동으로 결정하는 방법만큼 정확하지 않지만 유용한 기법이다. 다른 정보가 없다면 웹페이지의 인커밍 링크가 유용도나 '권위적인' 정도의 지표가 될 수 있다. 이 경우 점수는 버트가 3, 어니가 1이므로 검색엔진은 버트의 페이지를 더 높은 순위로 보여준다. 

한 가지 주의할 점은 링크가 좋은 페이지(추천)가 아닌 나쁜 페이지(혹평)를 지칭하는 데 이용된다는 점이다. 그러나 실제로 하이퍼링크를 사용하는 경우 혹평보다 추천이 훨씬 많고, 따라서 하이퍼링크 트릭은 명백한 결점이 있음에도 유용하다.

> 혹평보다 대부분 추천을 위한 페이지들이 있다라는 하이퍼링크 가정이 있다. 


### 권위 트릭 (Authority Trick)

페이지의 모든 인커밍 링크를 동등하게 처리해야 할까? 전문가의 추천은 일반인의 추천보다 분명히 더 가치가 있다. 스크램블 에그 예제를 다시 살펴보자. 다음 그림은 새로운 설정은 보여준다. 버트와 어니의 페이지에 같은 수(한 개)의 인커밍 링크가 있지만 어니의 인커밍 링크는 나의(컴퓨터과학자) 홈페이지에서 온 반면, 버트의 인커밍 링크는 유명한 요리사인 앨리스 워터스 홈페이지에서 온다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/3_2.PNG" width="60%" height="60%"></p>

당연히 사람들은 유명한 요리사의 인커밍 링크를 가지는 버트의 레시피를 선호할 것이다. 이 기본 원리를 권위 트릭이라고 부른다. 높은 '권위'가 있는 페이지에서 온 링크는 낮은 권위가 있는 페이지의 링크보다 더 높은 순위라는 결과를 가져야 한다.

그러면 앨리스 워터스가 나보다 스크램블 에그에 대해서 더 권위있다는 사실을 어떻게 컴퓨터가 자동으로 알아낼 수 있을까? 하이퍼링크 트릭과 권위 트릭을 결합하자. 모든 페이지는 1점의 권위 점수로 시작한다. 한 페이지에 인커밍 링크가 있다면 이를 지칭하는 모든 페이지의 권위를 추가해서 권위를 계산한다. 다음 그림을 보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/3_3.PNG" width="60%" height="60%"></p>

버트의 레시피에도 어니와 같이 하나의 인커밍 링크만 있지만 이는 100점짜리이다. 2점의 어니보다 훨씬 더 높다.


### 무작위 서퍼 트릭 (Random Sufer Trick)

컴퓨터가 실제로 페이지의 내용을 이해하지 않아도 실제로 효과가 있는 권위 점수의 자동 계산 전략에 의존해서만 검색결과를 얻을 수 있는 듯하다. 하지만 한 가지 큰 문제가 있다. 하이퍼링크는 사이클(cycle)을 형성할 가능성이 꽤 크다. 사이클은 하이퍼링크를 클릭하다가 출발점으로 되돌아오는 경우를 말한다. 다음 그림을 보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/3_4.PNG" width="60%" height="60%"></p>

A->B->E->A 로 반복되는 사이클을 볼 수 있다. 우리가 정의한 '권위 점수'(하이퍼링크 트릭과 권위 트릭의 결합)는 사이클이 있을 경우 큰 문제에 빠진다. 사이클이 돌면 돌수록 점수는 계속 증가하게 되고 영원히 사이클을 돈다면 무한대의 점수를 가질 것이다. 이런 식의 권위 점수 계산은 닭이 먼저냐 달걀이 먼저냐의 문제를 낳는다. A에 해당하는 진짜 권위 점수를 알면 B와 E에 해당하는 권위 점수를 알 수 있다. 그리고 B와 E에 해당하는 진짜 점수를 알면 A의 점수를 계산할 수 있다. 그러나 각 페이지는 서로 다른 페이지의 점수에 의존하므로 이는 불가능해 보인다.

다행히도 우리는 무작위 서퍼 트릭으로 닭과 달걀의 문제를 해결할 수 있다. 무작위로 인터넷을 서핑하는 사람을 상상해보자. 서퍼는 전체 월드와이드웹에서 무작위로 선택한 하나의 웹페이지에서 출발한다. 그 다음, 서퍼는 이 페이지에 있는 모든 하이퍼링크를 검토하고 이 중 하나를 무작위로 골라 클릭한다. 이 행위를 반복한다. 다음 그림을 보자.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/3_5.PNG" width="60%" height="60%"></p>

서퍼가 방문한 웹페이지는 어두운 색으로 칠했고, 서퍼가 클릭한 하이퍼링크는 검은 색이며 점선 화살표는 무작위 재출발을 의미한다. 위의 무작위 서퍼 모델에서 전환점(twist)이 있다. 페이지를 방문할 때마다 서퍼가 이용 가능한 하이퍼링크 중 하나를 클릭하지 않는 고정된 재출발 확률(restart probability)(이 예에선 15%)이 있다. 서퍼가 페이지 링크 결대로 읽다가 지루해져 새로운 링크로 점프할 가능성이 15%라고 생각하면 된다. 위에선 B에서 새로운 곳으로 점프했다. 

컴퓨터로 이 과정을 시뮬레이션하기엔 어렵지 않다. 서퍼가 1,000개 페이지를 방문할 때까지 돌려보았다. 결과는 다음 그림과 같다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/3_6.PNG" width="60%" height="60%"></p>

페이지 D의 방문 빈도가 144번으로 가장 높음을 알 수 있다. 여론 조사에서와 마찬가지로 무작위 표본의 수를 늘려 시뮬레이션의 정확도를 높일 수 있다. 같은 시뮬레이션으로 다시 돌려 이번엔 서퍼가 100만 페이지를 방문할 때까지 기다렸다. 이렇게 많은 횟수로 방문하는 경우 결과는 백분율로 표시하는 편이 낫다. 맨 아래 그림을 보자. 이번에도 페이지 D의 방문 횟수가 15%로 가장 높았다.

무작위 서퍼 모델과 웹페이지 랭킹에 쓰고 싶은 권위 트릭 사이엔 어떤 관계가 있을까? 무작위 서퍼 시뮬레이션에서 계산한 백분율은 정확히 페이지의 권위를 측정하는 데 필요한 수치다. 눈에 띄는 점은 서퍼 권위 점수는 웹페이지의 중요성 순위를 매기는 앞선 두 트릭을 모두 포함한다는 사실이다.

먼저 하이퍼링크 트릭이 있었다. 주요 개념은 많은 인커밍 링크가 있는 페이지가 더 높은 순위를 받아야 한다는 점이다. 이는 무작위 서퍼 모델에서도 똑같다. 많은 인커밍 링크를 가진 페이지를 많이 방문할 가능성이 크기 때문이다. 페이지 D의 경우 다섯 개의 인커밍 링크를 갖고 있고 결국 가장 높은 서퍼 권위 점수(15%)를 획득하게 됐다.

둘째로 권위 트릭이 있었다. 핵심 개념은 높은 권위를 가진 페이지로부터 인커밍 링크는 낮은 권위를 가진 페이지로부터의 인커밍 링크보다 페이지의 순위를 높인다는 내용이었다. 이번에도 무작위 서퍼 모델은 이를 감안한다. 인기 있는 페이지로부터의 인커밍 링크는 인기 없는 페이지로부터의 링크보다 더 따라갈 기회가 많기 때문이다. 페이지 A와 C를 비교해 보자. 각 페이지는 정확히 하나의 인커밍 링크를 가진다. 그러나 페이지 A에 있는 질 좋은 인커밍 링크 덕분에 A가 훨씬 더 높은 서퍼 권위 점수(13% vs. 2%)를 획득했다.

무작위 서퍼 모델이 하이퍼링크 트릭과 권위 트릭을 동시에 포괄한다는 사실, 즉 각 페이지에 있는 인커밍 링크의 질과 양을 모두 계산한다는 것에 주목하자.

무작위 서퍼 트릭은 권위 트릭과는 달리 하이퍼링크에 사이클이 있는지 여부와 관계 없이 완벽히 잘 작동한다. 앞선 스크램블 에그의 예에서도 이를 쉽게 적용할 수 있다.

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/3_7.PNG" width="60%" height="60%"></p>

권위 트릭을 이용한 이전 계산에서와 마찬가지로 각각 하나의 인커밍 링크만 갖고 있음에도 버트의 페이지가 어니보다 훨씬 더 높은 점수를 받았다. 

사이클 문제가 있었던 케이스를 보자. 권위 트릭을 적용하면 엄청난 문제를 초래한다. 무작위 서퍼 컴퓨터 시뮬레이션을 돌리면 다음과 같은 서퍼 권위 점수를 산출한다. 

<p align="center"><img src="https://github.com/gritmind/my-review-notes/blob/master/paper/book/nine-algorithm/images/3_8.PNG" width="60%" height="60%"></p>


### 실제 페이지랭크

구글의 두 공동 창업자는 1998년 컨퍼런스 논문인 "The Anatomy of a Large-scale Hypertextual Web Search Engine."에서 무작위 서퍼 트릭을 설명했다. 주요 검색엔진에서 많은 여타 기법을 조합해 이 트릭의 변형 버전을 아직도 이용하고 있다. 그러나 오늘날 검색엔진이 이용하는 실제 기법은 여기서 기술한 무작위 서퍼 트릭과 다소 다르고, 이에는 수많은 복잡한 요인이 있다.

그 요인 중 하나는 페이지랭크의 핵심을 공격한다. 하이퍼링크가 정당한 권위를 보여한다는 가정이 때론 의문시된다는 것이다. 사람들이 자기 웹페이지의 순위를 인위적으로 부풀리고자 하이퍼링크 트릭을 남용할 수 있다는 점이다. 자동화 기술을 이용해 특정 웹페이지의 링크를 가진 매우 많은 웹페이지들을 제작하기란 비교적 쉽다. 특정 웹페이지가 사업 홈페이지라면 더 높은 검색 순위에 더 많은 매출을 올릴 수 있다. 검색엔진은 이런 종류의 남용을 웹 스팸(web spam)이라고 부른다. (스팸 메일과 비슷하게 스팸 검색결과를 말한다)

다양한 유형의 웹 스팸을 탐지하고 제거하는 일은 모든 검색엔진이 지속적으로 해야 할 중요한 과제다. 검색엔진은 웹 스패머에 맞서 군비 경쟁(arms race)을 하게 되고 실질적인 순위를 출력하고자 알고리즘을 끊임없이 개선하려 한다. 페이지랭크를 개선하려는 열망은 페이지 순위를 매기는 데 웹 하이퍼링크 구조를 이용하는 여타 알고리즘에 대한 많은 학문 및 산업 연구를 낳았다. 이런 종류의 알고리즘을 대개 링크 기반 랭킹 알고리즘(link-based ranking algorithms)이라 부른다. 

또 다른 복잡한 요인은 페이지랭크 계산의 효율성과 연관된다. 이 책에서는 서퍼 권위 점수를 무작위 시뮬레이션을 돌려 계산했지만 전체 웹 대상으로 이렇게 시뮬레이션을 구동하는 것은 너무 오래 걸려 실제로 사용할 수 없을 것이다. 그래서 검색엔진은 무작위 서퍼를 시뮬레이션해 페이지랭크 값을 계산하지 않는다. 대신 무작위 서퍼 시뮬레이션과 같은 값을 제시하면서도 훨씬 적은 계산 비용이 드는 수학 기법을 이용한다. (`선형대수학`) 

상용 검색엔진이 페이지랭크 같은 링크 기반 랭킹 알고리즘 외에도 훨씬 더 많은 것을 이용해 순위를 결정한다는 점도 알아둘 필요가 있다. 1998년에 공개된 구글 설명에서조차 구글의 두 공동 창업자는 검색결과 랭킹에 기여하는 여러 다른 특징(feature)을 언급했다. 여기서 기술이 시작됐다. 이 글을 쓰고 있는 현재, 구글의 웹사이트에서는 페이지 중요도 평가에 '200개 이상의 신호를 이용'한다고 명시한다.

오늘날 검색엔진이 매우 복잡해지기는 했지만, '권위 이쓴ㄴ 페이지는 하이퍼링크를 통해 다른 페이지에 권위를 부여한다.'는 페이지랭크의 핵심 아이디어는 여전히 유효하다. 이는 불과 몇 년 사이에 소규모 회사였던 구글이 알타비스타를 밀어내고 검색왕 자리에 오르는 데 도움을 준 아이디어였다. 페이지랭크의 핵심 알고리즘이 없었다면 대부분 웹 검색 쿼리는 수천 개의 '부적합하지만 부적합한' 웹페이지의 바다에 빠졌을 것이다.



































 




























































