# Generative model vs. Discriminative Model

2015.10

## 1. Motivation

```
Example )  (1, 0), (1, 0), (2, 0), (2, 1)
Input data : x
Goal : to classify the data x into labels y

A generative model learns the joint probability distribution p(x, y)

   p(x, y)   y=0    y=1
     x=1     1/2     0
     x=2     1/4    1/4

sample size = the whole population
pdf of x and y

A discriminative model learns the conditional probability distribution p(y| x)

   p(y |x)   y=0    y=1
     x=1      1      0
     x=2     1/2    1/2

sample size = all cases of x=1 or x=2
pdf of y
```

## 2. Comparison

### 2.1 Generative Model

A generative model is a model for randomly generating observable-data values, typically given some hidden parameters. It specifies a joint probability distribution over observation and label sequences. Generative models are used in machine learning for either modeling data directly that is, modeling observations drawn from a probability density function, or as as intermediate step to forming a conditional probability density function. A conditional distribution can be formed from a generative model through Bayes' rule.

Generative models contrast with discriminative models, in that a generative model is a full probabilistic model of all variables, whereas a discriminative model provides a model only for the target variable conditional on the observed variables. Thus a generative model can be used to generate values of any variable in the model, whereas a discriminative model allows only sampling of the target variables conditional on the observed quantities.

To predict the label y from the training data x, you must evaluate:

`f(x) = argmax_y(p(x|y)p(y))`

which we had the joint probability distribution `p(x, y)` because `p(x, y) = p(x |y)*p(y)`, which explicitly models the actual distribution of each class.

Generative models model the distribution of individual classes.

There are a number of advantages generative models may offer, depending on the application. Say you are dealing with non-stationary distributions, where the online test data may be generated by more different underlying distributions than training data. It's typically more straightforward to detect distribution changes and update a generative model accordingly than do this for a decision boundary in an SVM, especially if the online updates need to be unsupervised. Discriminative models also don't generally function for outlier detection, though generative models generally do. What's best for a specific application should be evaluated based on the application.

Generative models are typically specified as probabilistic graphical models, which offer rich representations of the independence relations in the dataset.

A generative model is a model of how the data is actually generated. For example, Gaussian mixture models have a nice probabilistic model for how points are generated ( each data points are sampled from component's Gaussian distribution )

Generative algorithms have discriminative properties because you can get p(y |x) once you have p(x |y) and p(y) by Bayes' Theorem, though discriminative algorithms don't really have generative properties.

Generative algorithms make some kind of structure assumptions on your model, but discriminative algorithms make fewer assumptions. For example, Naive Bayes assumes conditional independence of your features, while logistic regression does not.

Naive Bayes is generative because it captures p(x |y) and p(y). For example, if we know that p(y=English)=0.7 and p(y=French)=0.3 along with English and French word distributions, then we can now generate a new document by first choosing the language of the document, p(y), and then generating words from its word distributions.

Generative model은 p(y)와 p(x |y)를 가지고 Bayes rule을 통해 p(y |x)로 돌아갈 수 있지만, Discriminative model은 오직 p(y |x)에 머무를수밖에 없다.

Generative models often outperform discriminative models on smaller datasets because their generative assumptions place some structure on your model that prevent overfitting. The Naive Bayes assumption is rarely satisfied, so logistic regression will tend to outperform Naive Bayes as your dataset grows because it can capture dependencies that Naive Bayes can't. But when you only have a small dataset, logistic regression might pick up on spurious patterns that don't really exist. Therefore, the Naive Bayes acts as a kind of regularizer on your model that prevents overfitting.

Generative models can actually learn the underlying structure of the data if you specify your model correctly and the model actually holds, but discriminative models can outperform in case that your generative assumptions are not satisfied because discriminative algorithms are less tied to a particular structure, and the real world is messy and assumptions are rarely perfectly satisfied anyways.


### 2.2 Discriminative Model

Discriminative model, also called conditional models, are a class of models used in machine learning for modeling the dependence of an unobserved variable y on an observed variable x.

Discriminative models, as opposed to generative models, do not allow one to generate samples from the joint distribution of x and y. However, for tasks such as classification and regression that don't require the joint distribution, discriminative models can yield superior performance. On the other hand, generative models are typically more flexible than discriminative models in expressing dependencies in complex learning tasks. In addition, most discriminative models are inherently supervised and can't easily be extended to unsupervised learning.

To predict the label y from the training data x, you must evaluate :

`f(x) = argmax_y(p(y|x))`

which merely chooses what is the most likely class considering x through the conditional probability distribution p(y |x). It's like we were trying to model the decision boundary between the classes. This behavior is very clear in neural networks, where the computed weights can be seen as a complex shaped curve isolating the elements of a class in the space.

Discriminative models learn the (hard or soft) boundary between classes.

Discriminative models do not offer such clear representations of relations between features and classes in the dataset. Instead of using resources to fully model each class, they focus on richly modeling the boundary between classes. Given the same amount of capacity ( bits in a computer program ), a dicriminative model may yield more complex representations of this boundary than a generative model.

A discriminative is a model simply providing classification splits and not necessarily in a probabilistic manner.

Dicriminative algorithms allow you to classify points without providing a model of how the points are actually generated.

## 추가

Generally there is a practice in machine learning community not to learn something that you don't want for the task. For example, consider a classification task where your goal is to assign labels to a given x input. If we use generative model, we have to model p(x) which is irreverent for the task in hand. `( p(x, y) = p(y |x)*p(x) ).` Practical limitations like data sparseness will force us to model p(x) with some weak independence assumptions. There for we intuitively use discriminative models for classification.

The Statistical Machine Learning Approach

1. Data Collection - Large sample of data of how humans perform the task
2. Model Selection - Settle on a parametric statistical model of the process
3. Parameter Estimation - Calculate parameter values by inspecting the data
4. Search - Find optimal solution to given problem

Generative and Discriminative Models : An analogy
* The task is to determine the language that someone is speaking
* Generative approach:
   * is to learn each language and determine as to which language the speech belongs to by using some knowledge
* Discriminative approach:
   * is to determine the linguistic differences without learning any language and then classify them - a much easier task!

Taxonomy of Machine Learning Models

* Generative Methods
    - Model class-conditional pdfs and prior probabilities
    - "Generative" since sampling can generate synthetic data points
    - Popular models
        - Gaussians, Naive Bayes, Mixtures of multinomials
        - Mixtures of Gaussians, Mixture of experts, Hidden Markov Models (HMM)
        - Sigmodal belief networks, Bayesian networks, Markov random fiels

* Discriminative Methods
    - Learn explicit boundaries between classes.
    - Directly estimate posterior probabilities
    - No attempt to model underlying probability distributions
    - Focus computational resources on given task - better performance
    - Popular models
        - Logistic regression, SVMs
        - Traditional neural networks, Nearest neighbor
        - Conditional Random Fields (CRF)

## Reference

* [StackOverflow - What is the difference between a Generative and Discriminative Algorithm?](http://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-discriminative-algorithm)
* [StackExchange - Generative vs. discriminative](http://stats.stackexchange.com/questions/12421/generative-vs-discriminative)
* [Machine Learning, Andrew Ng - Lecture Notes : Part IV Generative Learning algorithms](http://cs229.stanford.edu/notes/cs229-notes2.pdf)
* [Generative and Discriminative Models, Sarsur N. Srihari](http://www.cedar.buffalo.edu/~srihari/CSE574/Discriminative-Generative.pdf)
* [Wikipedia - Generative model](https://en.wikipedia.org/wiki/Generative_model)
* [Wikipedia - Discriminative model](https://en.wikipedia.org/wiki/Discriminative_model)
